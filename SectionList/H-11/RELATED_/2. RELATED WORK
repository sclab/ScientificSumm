Since our proposed algorithm is based on regression 
framework. The most related work is optimal experimental design
[1], including A-Optimal Design, D-Optimal Design, and 
EOptimal Design. In this Section, we give a brief description
of these approaches.
2.1 The Active Learning Problem
The generic problem of active learning is the following.
Given a set of points A = {x1, x2, · · · , xm} in Rd
, find a
subset B = {z1, z2, · · · , zk} ⊂ A which contains the most 
informative points. In other words, the points zi(i = 1, · · · , k)
can improve the classifier the most if they are labeled and
used as training points.
2.2 Optimal Experimental Design
We consider a linear regression model
y = wT
x + (1)
where y is the observation, x is the independent variable,
w is the weight vector and is an unknown error with zero
mean. Different observations have errors that are 
independent, but with equal variances σ2
. We define f(x) = wT
x
to be the learner"s output given input x and the weight
vector w. Suppose we have a set of labeled sample points
(z1, y1), · · · , (zk, yk), where yi is the label of zi. Thus, the
maximum likelihood estimate for the weight vector, ˆw, is
that which minimizes the sum squared error
Jsse(w) =
k
i=1
wT
zi − yi
2
(2)
The estimate ˆw gives us an estimate of the output at a novel
input: ˆy = ˆwT
x.
By Gauss-Markov theorem, we know that ˆw − w has a
zero mean and a covariance matrix given by σ2
H−1
sse, where
Hsse is the Hessian of Jsse(w)
Hsse =
∂2
Jsse
∂w2
=
k
i=1
zizT
i = ZZT
where Z = (z1, z2, · · · , zk).
The three most common scalar measures of the size of the
parameter covariance matrix in optimal experimental design
are:
• D-optimal design: determinant of Hsse.
• A-optimal design: trace of Hsse.
• E-optimal design: maximum eigenvalue of Hsse.
Since the computation of the determinant and eigenvalues
of a matrix is much more expensive than the computation
of matrix trace, A-optimal design is more efficient than the
other two. Some recent work on experimental design can be
found in [6], [16].
