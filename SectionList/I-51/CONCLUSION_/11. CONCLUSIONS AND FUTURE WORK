In this paper we have presented an argumentation-based 
framework for multi-agent learning. Specifically, we have presented
AMAL, a framework that allows a group of learning agents to 
argue about the solution of a given problem and we have shown how
the learning capabilities can be used to generate arguments and
counterarguments. The experimental evaluation shows that the 
increased amount of information provided to the agents by the 
argumentation process increases their predictive accuracy, and specially
when an adequate number of agents take part in the argumentation.
The main contributions of this work are: a) an argumentation
framework for learning agents; b) a case-based preference relation
over arguments, based on computing an overall confidence 
estimation of arguments; c) a case-based policy to generate 
counterarguments and select counterexamples; and d) an argumentation-based
approach for learning from communication.
Finally, in the experiments presented here a learning agent would
retain all counterexamples submitted by the other agent; however,
this is a very simple case retention policy, and we will like to 
experiment with more informed policies - with the goal that individual
learning agents could significantly improve using only a small set
of cases proposed by other agents. Finally, our approach is focused
on lazy learning, and future works aims at incorporating eager 
inductive learning inside the argumentative framework for learning
from communication.
