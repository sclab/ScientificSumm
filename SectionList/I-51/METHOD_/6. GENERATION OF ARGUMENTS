In our framework, arguments are generated by the agents from
cases, using learning methods. Any learning method able to 
provide a justified prediction can be used to generate arguments. For
instance, decision trees and LID [2] are suitable learning methods.
Specifically, in the experiments reported in this paper agents use
LID. Thus, when an agent wants to generate an argument 
endorsing that a specific solution class is the correct solution for a problem
P, it generates a justified prediction as explained in Section 3.1.
For instance, Figure 3 shows a real justification generated by
LID after solving a problem P in the domain of marine sponges
identification. In particular, Figure 3 shows how when an agent
receives a new problem to solve (in this case, a new sponge to
determine its order), the agent uses LID to generate an argument
(consisting on a justified prediction) using the cases in the case
base of the agent. The justification shown in Figure 3 can be 
interpreted saying that the predicted solution is hadromerida 
because the smooth form of the megascleres of the spiculate 
skeleton of the sponge is of type tylostyle, the spikulate skeleton of the
sponge has no uniform length, and there is no gemmules in the 
external features of the sponge. Thus, the argument generated will
be α = A1, P, hadromerida, D1 .
6.1 Generation of Counterarguments
As previously stated, agents may try to rebut arguments by 
generating counterargument or by finding counterexamples. Let us 
explain how they can be generated.
An agent Ai wants to generate a counterargument β to rebut an
argument α when α is in contradiction with the local case base of
Ai. Moreover, while generating such counterargument β, Ai 
expects that β is preferred over α. For that purpose, we will present
a specific policy to generate counterarguments based on the 
specificity criterion [10].
The specificity criterion is widely used in deductive frameworks
for argumentation, and states that between two conflicting 
arguments, the most specific should be preferred since it is, in 
principle, more informed. Thus, counterarguments generated based on
the specificity criterion are expected to be preferable (since they are
more informed) to the arguments they try to rebut. However, there
is no guarantee that such counterarguments will always win, since,
as we have stated in Section 5, agents in our framework use a 
preference relation based on joint confidence. Moreover, one may think
that it would be better that the agents generate counterarguments
based on the joint confidence preference relation; however it is not
obvious how to generate counterarguments based on joint 
confidence in an efficient way, since collaboration is required in order to
evaluate joint confidence. Thus, the agent generating the 
counterargument should constantly communicate with the other agents at
each step of the induction algorithm used to generate 
counterarguments (presently one of our future research lines).
Thus, in our framework, when an agent wants to generate a 
counterargument β to an argument α, β has to be more specific than α
(i.e. α.D < β.D).
The generation of counterarguments using the specificity 
criterion imposes some restrictions over the learning method, although
LID or ID3 can be easily adapted for this task. For instance, LID is
an algorithm that generates a description starting from scratch and
heuristically adding features to that term. Thus, at every step, the
description is made more specific than in the previous step, and the
number of cases that are subsumed by that description is reduced.
When the description covers only (or almost only) cases of a 
single solution class LID terminates and predicts that solution class.
To generate a counterargument to an argument α LID just has to
use as starting point the description α.D instead of starting from
scratch. In this way, the justification provided by LID will always
be subsumed by α.D, and thus the resulting counterargument will
be more specific than α. However, notice that LID may sometimes
not be able to generate counterarguments, since LID may not be
able to specialize the description α.D any further, or because the
agent Ai has no case inCi that is subsumed by α.D. Figure 4 shows
how an agent A2 that disagreed with the argument shown in 
Figure 3, generates a counterargument using LID. Moreover, Figure 4
shows the generation of a counterargument β1
2 for the argument α0
1
(in Figure 3) that is a specialization of α0
1.
978 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Solution: hadromerida
Justification: D1
Sponge
Spikulate
skeleton
External
features
External features
Gemmules: no
Spikulate Skeleton
Megascleres
Uniform length: no
Megascleres
Smooth form: tylostyle
Case Base
of A1
LID
New
sponge
P
Figure 3: Example of a real justification generated by LID in the marine sponges data set.
Specifically, in our experiments, when an agent Ai wants to rebut
an argument α, uses the following policy:
1. Agent Ai uses LID to try to find a counterargument β more
specific than α; if found, β is sent to the other agent as a
counterargument of α.
2. If not found, then Ai searches for a counterexample c ∈ Ci
of α. If a case c is found, then c is sent to the other agent as
a counterexample of α.
3. If no counterexamples are found, then Ai cannot rebut the
argument α.
