3.1 Conditional Difference Independence
Our first step is to generalize Definition 6 to a conditional 
version.
DEFINITION 7. Let X, Y, Z be a partition of the set of attributes
A. X is conditionally difference independent of Y given Z, 
denoted as CDI(X, Y | Z), if
∀ instantiations ˆZ, X1
, X2
, Y 1
, Y 2
[X1
Y 1 ˆZ, X2
Y 1 ˆZ] ∼ [X1
Y 2 ˆZ, X2
Y 2 ˆZ].
Since the conditional set is always the complement, we sometimes
leave it implicit, using the abbreviated notation CDI(X, Y ).
CDI leads to a decomposition similar to that obtained from CAI
[17].
LEMMA 3. Let u(A) be an MVF representing preference 
differences. Then CDI(X, Y | Z) iff
u(A) = u(X0
, Y, Z) + u(X, Y 0
, Z) − u(X0
, Y 0
, Z).
To complete the analogy with CAI, we generalize Lemma 3 as
follows.
PROPOSITION 4. CDI(X, Y | Z) iff there exist functions
ψ1(X, Z) and ψ2(Y, Z), such that
u(X, Y, Z) = ψ1(X, Z) + ψ2(Y, Z). (2)
An immediate result of Proposition 4 is that CDI is a symmetric
relation.
The conditional independence condition is much more 
applicable than the unconditional one. For example, if attributes a ∈ X
and b /∈ X are complements or substitutes, X cannot be difference
independent of ¯X. However, X \ {a} may still be CDI of ¯X given
a.
3.2 GAI Structure for MVF
A single CDI condition decomposes the value function into two
parts. We seek a finer-grain global decomposition of the utility
function, similar to that obtained from mutual preferential 
independence. For this purpose we are now ready to employ the results
of Bacchus and Grove [1], who establish that the CAI condition
has a perfect map [20]; that is, there exists a graph whose nodes
correspond to the set A, and its node separation reflects exactly the
complete set of CAI conditions on A. Moreover, they show that the
utility function decomposes over the set of maximal cliques of the
perfect map. Their proofs can be easily adapted to CDI, since they
only rely on the decomposition property of CAI that is also implied
by CDI according to Proposition 4.
THEOREM 5. Let G = (A, E) be a perfect map for the CDI
conditions on A. Then
u(A) =
g
X
r=1
fr(Ir), (3)
where I1, . . . , Ig are (overlapping) subsets of A, each 
corresponding to a maximal clique of G.
Given Theorem 5, we can now identify an MVF GAI structure
from a collection of CDI conditions. The CDI conditions, in turn,
are particularly intuitive to detect when the preference differences
carry a direct interpretation, as in the case with monetary 
differences discussed below. Moreover, the assumption or detection of
CDI conditions can be performed incrementally, until the MVF is
decomposed to a reasonable dimension. This is in contrast with the
fully additive decomposition of MVF that requires mutual 
preferential independence [11].
Theorem 5 defines a decomposition structure, but to represent
the actual MVF we need to specify the functions over the cliques.
229
The next theorem establishes that the functional constituents of
MVF are the same as those for GAI decompositions as defined by
Fishburn [13] for EU. We adopt the following conventional 
notation. Let (a0
1, . . . , a0
m) be a predefined vector called the reference
outcome. For any I ⊆ A, the function u([I]) stands for the 
projection of u(A) to I where the rest of the attributes are fixed at their
reference levels.
THEOREM 6. Let G = (A, E) be a perfect map for the CDI
condition on A, and {I1, . . . , Ig} a set of maximal cliques as 
defined in Theorem 5. Then the functional decomposition from that
theorem can be defined as
f1 = u([I1]), and for r = 2, . . . , g (4)
fr = u([Ir]) +
r−1X
k=1
(−1)k
X
1≤i1<···<ik<r
u([
k\
s=1
Iis ∩ Ir])
The proof directly shows that if graph G = (A, E) is a perfect
map of CDI, u(A) decomposes to a sum over the functions defined
in (4).1
Thus this proof does not rely on the decomposition result
of Theorem 5, only on the existence of the perfect map.
To summarize, the results of this section generalize additive MVF
theory. In particular it justifies the application of methods recently
developed under the EU framework [1, 4, 14, 6] to representation
of value under certainty.
