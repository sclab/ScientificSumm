We are interested in the following hypotheses:
1. Some systems are more effective than others;
t1 · · · tn MAP
s1 AP(s1, t1) · · · AP(s1, tn) MAP(s1)
...
...
...
sm AP(sm, t1) · · · AP(sm, tn) MAP(sm)
AAP AAP(t1) · · · AAP(tn)
(a)
t1 t2 · · · MAP
s1 0.5 0.4 · · · 0.6
s2 0.4 · · · · · · 0.3
...
...
...
...
AAP 0.6 0.3 · · ·
(b)
Table 1: AP, MAP and AAP
2. Some topics are easier than others;
3. Some systems are better than others at distinguishing
easy and difficult topics;
4. Some topics are better than others at distinguishing
more or less effective systems.
The first of these hypotheses needs no further justification
- every reported significant difference between any two 
systems supports it. There is now also quite a lot of evidence
for the second, centered on the TREC Robust Track [14].
Our primary interest is in the third and fourth. The third
might be regarded as being of purely academic interest; 
however, the fourth has the potential for being of major 
practical importance in evaluation studies. If we could identify
a relatively small number of topics which were really good
at distinguishing effective and ineffective systems, we could
save considerable effort in evaluating systems.
One possible direction from this point would be to attempt
direct identification of such small sets of topics. However, in
the present paper, we seek instead to explore the 
relationships suggested by the hypotheses, between what different
topics tell us about systems and what different systems tell
us about topics. We seek methods of building and analysing
a matrix of system-topic normalised performances, with a
view to giving insight into the issue and confirming or 
refuting the third and fourth hypotheses. It turns out that
the obvious symmetry implied by the above formulation of
the hypotheses is a property worth investigating, and the
investigation does indeed give us valuable insights.
