In this section, we study how to compute the optimal
strategy to commit to for games represented in normal form.
2.1 Definitions
In a normal-form game, every player i ∈ {1, . . . , n} has a
set of pure strategies (or actions) Si, and a utility function
ui : S1×S2×. . .×Sn → R that maps every outcome (a vector
consisting of a pure strategy for every player, also known
as a profile of pure strategies) to a real number. To ease
notation, in the case of two players, we will refer to player
1"s pure strategy set as S, and player 2"s pure strategy set
as T. Such games can be represented in (bi-)matrix form,
in which the rows correspond to player 1"s pure strategies,
the columns correspond to player 2"s pure strategies, and
the entries of the matrix give the row and column player"s
utilities (in that order) for the corresponding outcome of the
game. In the case of three players, we will use R, S, and T,
for player 1, 2, and 3"s pure strategies, respectively. A mixed
strategy for a player is a probability distribution over that
player"s pure strategies. In the case of two-player games,
we will refer to player 1 as the leader and player 2 as the
follower.
Before defining optimal leadership strategies, consider the
following game which illustrates the effect of the leader"s
ability to commit.
2, 1 4, 0
1, 0 3, 1
In this normal-form representation, the bottom strategy
for the row player is strictly dominated by the top strategy.
Nevertheless, if the row player has the ability to commit to
a pure strategy before the column player chooses his 
strategy, the row player should commit to the bottom strategy:
doing so will make the column player prefer to play the
right strategy, leading to a utility of 3 for the row player.
By contrast, if the row player were to commit to the top
strategy, the column player would prefer to play the left
strategy, leading to a utility of only 2 for the row player. If
the row player is able to commit to a mixed strategy, then
she can get an even greater (expected) utility: if the row
player commits to placing probability p > 1/2 on the 
bottom strategy, then the column player will still prefer to play
the right strategy, and the row player"s expected utility will
be 3p + 4(1 − p) = 4 − p ≥ 3. If the row player plays each
strategy with probability exactly 1/2, the column player is
83
indifferent between the strategies. In such cases, we will 
assume that the column player will choose the strategy that
maximizes the row player"s utility (in this case, the right
strategy). Hence, the optimal mixed strategy to commit to
for the row player is p = 1/2. There are a few good 
reasons for this assumption. If we were to assume the opposite,
then there would not exist an optimal strategy for the row
player in the example game: the row player would play the
bottom strategy with probability p = 1/2 + with > 0,
and the smaller , the better the utility for the row player.
By contrast, if we assume that the follower always breaks
ties in the leader"s favor, then an optimal mixed strategy
for the leader always exists, and this corresponds to a 
subgame perfect equilibrium of the extensive-form 
representation of the leadership situation. In any case, this is a 
standard assumption for such models (e.g. [20]), although some
work has investigated what can happen in the other 
subgame perfect equilibria [26]. (For generic two-player games,
the leader"s subgame-perfect equilibrium payoff is unique.)
Also, the same assumption is typically used in mechanism
design, in that it is assumed that if an agent is indifferent 
between revealing his preferences truthfully and revealing them
falsely, he will report them truthfully. Given this 
assumption, we can safely refer to optimal leadership strategies
rather than having to use some equilibrium notion.
Hence, for the purposes of this paper, an optimal strategy
to commit to in a 2-player game is a strategy s ∈ S that
maximizes maxt∈BR(s) ul(s, t), where BR(s) =
arg maxt∈T uf (s, t). (ul and uf are the leader and follower"s
utility functions, respectively.) We can have S = S for the
case of commitment to pure strategies, or S = ∆(S), the
set of probability distributions over S, for the case of 
commitment to mixed strategies. (We note that replacing T
by ∆(T) makes no difference in this definition.) For games
with more than two players, in which the players commit
to their strategies in sequence, we define optimal strategies
to commit to recursively. After the leader commits to a
strategy, the game to be played by the remaining agents is
itself a (smaller) leadership game. Thus, we define an 
optimal strategy to commit to as a strategy that maximizes
the leader"s utility, assuming that the play of the remaining
agents is itself optimal under this definition, and maximizes
the leader"s utility among all optimal ways to play the 
remaining game. Again, commitment to mixed strategies may
or may not be a possibility for every player (although for the
last player it does not matter if we allow for commitment to
mixed strategies).
2.2 Commitment to pure strategies
We first study how to compute the optimal pure strategy
to commit to. This is relatively simple, because the number
of strategies to commit to is not very large. (In the following,
#outcomes is the number of complete strategy profiles.)
Theorem 1. Under commitment to pure strategies, the
set of all optimal strategy profiles in a normal-form game
can be found in O(#players · #outcomes) time.
Proof. Each pure strategy that the first player may 
commit to will induce a subgame for the remaining players. We
can solve each such subgame recursively to find all of its
optimal strategy profiles; each of these will give the 
original leader some utility. Those that give the leader maximal
utility correspond exactly to the optimal strategy profiles of
the original game.
We now present the algorithm formally. Let Su(G, s1) be
the subgame that results after the first (remaining) player
in G plays s1 ∈ SG
1 . A game with 0 players is simply an
outcome of the game. The function Append(s, O) appends
the strategy s to each of the vectors of strategies in the set
O. Let e be the empty vector with no elements. In a slight
abuse of notation, we will write uG
1 (C) when all strategy
profiles in the set C give player 1 the same utility in the
game G. (Here, player 1 is the first remaining player in the
subgame G, not necessarily player 1 in the original game.)
We note that arg max is set-valued. Then, the following
algorithm computes all optimal strategy profiles:
Algorithm Solve(G)
if G has 0 players
return {e}
C ← ∅
for all s1 ∈ SG
1 {
O ← Solve(Su(G, s1))
O ← arg maxo∈O uG
1 (s1, o)
if C = ∅ or uG
1 (s1, O ) = uG
1 (C)
C ← C∪Append(s1, O )
if uG
1 (s1, O ) > uG
1 (C)
C ←Append(s1, O )
}
return C
Every outcome is (potentially) examined by every player,
which leads to the given runtime bound.
As an example of how the algorithm works, consider the
following 3-player game, in which the first player chooses
the left or right matrix, the second player chooses a row,
and the third player chooses a column.
0,1,1 1,1,0 1,0,1
2,1,1 3,0,1 1,1,1
0,0,1 0,0,0 3,3,0
3,3,0 0,2,0 3,0,1
4,4,2 0,0,2 0,0,0
0,5,1 0,0,0 3,0,0
First we eliminate the outcomes that do not correspond
to best responses for the third player (removing them from
the matrix):
0,1,1 1,0,1
2,1,1 3,0,1 1,1,1
0,0,1
3,0,1
4,4,2 0,0,2
0,5,1
Next, we remove the entries in which the third player
does not break ties in favor of the second player, as well
as entries that do not correspond to best responses for the
second player.
0,1,1
2,1,1 1,1,1
0,5,1
Finally, we remove the entries in which the second and
third players do not break ties in favor of the first player, as
well as entries that do not correspond to best responses for
the first player.
2,1,1
84
Hence, in optimal play, the first player chooses the left
matrix, the second player chooses the middle row, and the
third player chooses the left column. (We note that this
outcome is Pareto-dominated by (Right, Middle, Left).)
For general normal-form games, each player"s utility for
each of the outcomes has to be explicitly represented in the
input, so that the input size is itself Ω(#players · #outcomes).
Therefore, the algorithm is in fact a linear-time algorithm.
2.3 Commitment to mixed strategies
In the special case of two-player zero-sum games, 
computing an optimal mixed strategy for the leader to commit to
is equivalent to computing a minimax strategy, which 
minimizes the maximum expected utility that the opponent can
obtain. Minimax strategies constitute the only natural 
solution concept for two-player zero-sum games: von Neumann"s
Minimax Theorem [24] states that in two-player zero-sum
games, it does not matter (in terms of the players" utilities)
which player gets to commit to a mixed strategy first, and a
profile of mixed strategies is a Nash equilibrium if and only
if both strategies are minimax strategies. It is well-known
that a minimax strategy can be found in polynomial time,
using linear programming [17]. Our first result in this 
section generalizes this result, showing that an optimal mixed
strategy for the leader to commit to can be efficiently 
computed in general-sum two-player games, again using linear
programming.
Theorem 2. In 2-player normal-form games, an optimal
mixed strategy to commit to can be found in polynomial time
using linear programming.
Proof. For every pure follower strategy t, we compute a
mixed strategy for the leader such that 1) playing t is a best
response for the follower, and 2) under this constraint, the
mixed strategy maximizes the leader"s utility. Such a mixed
strategy can be computed using the following simple linear
program:
maximize
s∈S
psul(s, t)
subject to
for all t ∈ T,
s∈S
psuf (s, t) ≥
s∈S
psuf (s, t )
s∈S
ps = 1
We note that this program may be infeasible for some
follower strategies t, for example, if t is a strictly 
dominated strategy. Nevertheless, the program must be feasible
for at least some follower strategies; among these follower
strategies, choose a strategy t∗
that maximizes the linear
program"s solution value. Then, if the leader chooses as her
mixed strategy the optimal settings of the variables ps for
the linear program for t∗
, and the follower plays t∗
, this
constitutes an optimal strategy profile.
In the following result, we show that we cannot expect to
solve the problem more efficiently than linear programming,
because we can reduce any linear program with a probability
constraint on its variables to a problem of computing the
optimal mixed strategy to commit to in a 2-player 
normalform game.
Theorem 3. Any linear program whose variables xi (with
xi ∈ R≥0
) must satsify
i
xi = 1 can be modeled as a 
problem of computing the optimal mixed strategy to commit to in
a 2-player normal-form game.
Proof. Let the leader have a pure strategy i for every
variable xi. Let the column player have one pure 
strategy j for every constraint in the linear program (other than
i
xi = 1), and a single additional pure strategy 0. Let the
utility functions be as follows. Writing the objective of the
linear program as maximize
i
cixi, for any i, let ul(i, 0) =
ci and uf (i, 0) = 0. Writing the jth constraint of the linear
program (not including
i
xi = 1) as
i
aijxi ≤ bj, for any
i, j > 0, let ul(i, j) = mini ci − 1 and uf (i, j) = aij − bj.
For example, consider the following linear program.
maximize 2x1 + x2
subject to
x1 + x2 = 1
5x1 + 2x2 ≤ 3
7x1 − 2x2 ≤ 2
The optimal solution to this program is x1 = 1/3, x2 =
2/3. Our reduction transforms this program into the 
following leader-follower game (where the leader is the row
player).
2, 0 0, 2 0, 5
1, 0 0, -1 0, -4
Indeed, the optimal strategy for the leader is to play the
top strategy with probability 1/3 and the bottom strategy
with probability 2/3. We now show that the reduction works
in general.
Clearly, the leader wants to incentivize the follower to play
0, because the utility that the leader gets when the follower
plays 0 is always greater than when the follower does not
play 0. In order for the follower not to prefer playing j > 0
rather than 0, it must be the case that
i
pl(i)(aij − bj) ≤
0, or equivalently
i
pl(i)aij ≤ bj. Hence the leader will
get a utility of at least mini ci if and only if there is a
feasible solution to the constraints. Given that the pl(i)
incentivize the follower to play 0, the leader attempts to
maximize
i
pl(i)ci. Thus the leader must solve the original
linear program.
As an alternative proof of Theorem 3, one may observe
that it is known that finding a minimax strategy in a 
zerosum game is as hard as the linear programming problem [6],
and as we pointed out at the beginning of this section, 
computing a minimax strategy in a zero-sum game is a special
case of the problem of computing an optimal mixed strategy
to commit to.
This polynomial-time solvability of the problem of 
computing an optimal mixed strategy to commit to in two-player
normal-form games contrasts with the unknown complexity
of computing a Nash equilibrium in such games [21], as well
as with the NP-hardness of finding a Nash equilibrium with
maximum utility for a given player in such games [8, 2].
Unfortunately, this result does not generalize to more than
two players-here, the problem becomes NP-hard. To show
this, we reduce from the VERTEX-COVER problem.
Definition 1. In VERTEX-COVER, we are given a graph
G = (V, E) and an integer K. We are asked whether there
85
exists a subset of the vertices S ⊆ V , with |S| = K, such
that every edge e ∈ E has at least one of its endpoints in S.
BALANCED-VERTEX-COVER is the special case of
VERTEX-COVER in which K = |V |/2.
VERTEX-COVER is NP-complete [9]. The following
lemma shows that the hardness remains if we require K =
|V |/2. (Similar results have been shown for other NP-complete
problems.)
Lemma 1. BALANCED-VERTEX-COVER is
NP-complete.
Proof. Membership in NP follows from the fact that
the problem is a special case of VERTEX-COVER, which
is in NP. To show NP-hardness, we reduce an arbitrary
VERTEX-COVER instance to a 
BALANCED-VERTEXCOVER instance, as follows. If, for the VERTEX-COVER
instance, K > |V |/2, then we simply add isolated vertices
that are disjoint from the rest of the graph, until K = |V |/2.
If K < |V |/2, we add isolated triangles (that is, the 
complete graph on three vertices) to the graph, increasing K by
2 every time, until K = |V |/2.
Theorem 4. In 3-player normal-form games, finding an
optimal mixed strategy to commit to is NP-hard.
Proof. We reduce an arbitrary 
BALANCED-VERTEXCOVER instance to the following 3-player normal-form game.
For every vertex v, each of the three players has a pure 
strategy corresponding to that vertex (rv, sv, tv, respectively). In
addition, for every edge e, the third player has a pure 
strategy te; and finally, the third player has one additional pure
strategy t0. The utilities are as follows:
• for all r ∈ R, s ∈ S, u1(r, s, t0) = u2(r, s, t0) = 1;
• for all r ∈ R, s ∈ S, t ∈ T−{t0}, u1(r, s, t) = u2(r, s, t) =
0;
• for all v ∈ V, s ∈ S, u3(rv, s, tv) = 0;
• for all v ∈ V, r ∈ R, u3(r, sv, tv) = 0;
• for all v ∈ V , for all r ∈ R − {rv}, s ∈ S − {sv},
u3(r, s, tv) = |V |
|V |−2
;
• for all e ∈ E, s ∈ S, for both v ∈ e, u3(rv, s, te) = 0;
• for all e ∈ E, s ∈ S, for all v /∈ e, u3(rv, s, te) = |V |
|V |−2
.
• for all r ∈ R, s ∈ S, u3(r, s, t0) = 1.
We note that players 1 and 2 have the same utility function.
We claim that there is an optimal strategy profile in which
players 1 and 2 both obtain 1 (their maximum utility) if
and only if there is a solution to the 
BALANCED-VERTEXCOVER problem. (Otherwise, these players will both obtain
0.)
First, suppose there exists a solution to the 
BALANCEDVERTEX-COVER problem. Then, let player 1 play every
rv such that v is in the cover with probability 2
|V |
, and let
player 2 play every sv such that v is not in the cover with
probability 2
|V |
. Then, for player 3, the expected utility
of playing tv (for any v) is (1 − 2
|V |
) |V |
|V |−2
= 1, because
there is a chance of 2
|V |
that rv or sv is played. 
Additionally, the expected utility of playing te (for any e) is at most
(1 − 2
|V |
) |V |
|V |−2
= 1, because there is a chance of at least
2
|V |
that some rv with v ∈ e is played (because player 1 is
randomizing over the pure strategies corresponding to the
cover). It follows that playing t0 is a best response for player
3, giving players 1 and 2 a utility of 1.
Now, suppose that players 1 and 2 obtain 1 in optimal
play. Then, it must be the case that player 3 plays t0. Hence,
for every v ∈ V , there must be a probability of at least 2
|V |
that either rv or sv is played, for otherwise player 3 would
be better off playing tv. Because players 1 and 2 have only
a total probability of 2 to distribute, it must be the case
that for each v, either rv or sv is played with probability
2
|V |
, and the other is played with probability 0. (It is not
possible for both to have nonzero probability, because then
there would be some probability that both are played 
simultaneously (correlation is not possible), hence the total
probability of at least one being played could not be high
enough for all vertices.) Thus, for exactly half the v ∈ V ,
player 1 places probability 2
|V |
on rv. Moreover, for every
e ∈ E, there must be a probability of at least 2
|V |
that some
rv with v ∈ e is played, for otherwise player 3 would be 
better off playing te. Thus, the v ∈ V such that player 1 places
probability 2
|V |
on rv constitute a balanced vertex cover.
