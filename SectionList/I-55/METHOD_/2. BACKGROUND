2.1 Multi-criteria decision making theory
Let A denote the set of feasible alternatives available to a 
decision maker M. As an act, or decision, a in A may involve 
multiple aspects, we usually describe the alternatives a with a set of
attributes j; (j = 1, . . . , m). (Attributes are also referred to as 
issues, or decision variables.) A typical decision maker also has 
several objectives X1, . . . , Xk. We assume that Xi, (i = 1, . . . , k),
maps the alternatives to real numbers. Thus, a tuple (x1, . . . , xk) =
(X1(a), . . . , Xk(a)) denotes the consequence of the act a to the
decision maker M. By definition, objectives are statements that
delineate the desires of a decision maker. Thus, M wishes to 
maximise his objectives. However, as discussed thoroughly by Keeney
and Raiffa [8], it is quite likely that a decision maker"s objectives
will conflict with each other in that the improved achievement with
one objective can only be accomplished at the expense of another.
For instance, most businesses and public services have objectives
like minimise cost and maximise the quality of services. Since
better services can often only be attained for a price, these 
objectives conflict.
Due to the conflicting nature of a decision maker"s objectives, M
usually has to settle at a compromise solution. That is, he may have
to choose an act a ∈ A that does not optimise every objective. This
is the topic of the multi-criteria decision making theory. Part of the
solution to this problem is that M has to try to identify the Pareto
frontier in the consequence space {(X1(a), . . . , Xk(a))}a∈A.
DEFINITION 1. (Dominant)
Let x = (x1, . . . , xk) and x = (x1, . . . , xk) be two 
consequences. x dominates x iff xi > xi for all i, and the inequality is
strict for at least one i.
The Pareto frontier in a consequence space then consists of all
consequences that are not dominated by any other consequence.
This is illustrated in Fig. 1 in which an alternative consists of two
attributes d1 and d2 and the decision maker tries to maximise the
two objectives X1 and X2. A decision a ∈ A whose consequence
does not lie on the Pareto frontier is inefficient. While the Pareto
1x
d2
a (X (a),X (a))
d1
1
x2
2
Alternative spaceA
Pareto frontier
Consequence space
optimal consequenc
Figure 1: The Pareto frontier
frontier allows M to avoid taking inefficient decisions, M still has
to decide which of the efficient consequences on the Pareto frontier
is most preferred by him.
MCDM theorists introduce a mechanism to allow the objective
components of consequences to be normalised to the payoff 
valuations for the objectives. Consequences can then be ordered: if the
gains in satisfaction brought about by C1 (in comparison to C2)
equals to the losses in satisfaction brought about by C1 (in 
comparison to C2), then the two consequences C1 and C2 are considered
indifferent. M can now construct the set of indifference curves1
in
the consequence space (the dashed curves in Fig. 1). The most 
preferred indifference curve that intersects with the Pareto frontier is
in focus: its intersection with the Pareto frontier is the sought after
consequence (i.e., the optimal consequence in Fig. 1).
2.2 A negotiation framework
A multi-agent negotiation framework consists of:
1. A set of two negotiating agents N = {1, 2}.
2. A set of attributes Att = {α1, . . . , αm} characterising the 
issues the agents are negotiating over. Each attribute α can take a
value from the set V alα;
3. A set of alternative outcomes O. An outcome o ∈ O is 
represented by an assignment of values to the corresponding attributes
in Att.
4. Agents" utility: Based on the theory of multiple-criteria decision
making [8], we define the agents" utility as follows:
• Objectives: Agent i has a set of ni objectives, or interests;
denoted by j (j = 1, . . . , ni). To measure how much an 
outcome o fulfills an objective j to an agent i, we use objective
functions: for each agent i, we define i"s interests using the
objective vector function fi = [fij ] : O → Rni
.
• Value functions: Instead of directly evaluating an outcome o,
agent i looks at how much his objectives are fulfilled and will
make a valuation based on these more basic criteria. Thus,
for each agent i, there is a value function σi : Rni
→ R.
In particular, Raiffa [17] shows how to systematically 
construct an additive value function to each party involved in a
negotiation.
• Utility: Now, given an outcome o ∈ O, an agent i is able
to determine its value, i.e., σi(fi(o)). However, a 
negotiation infrastructure is usually required to facilitate negotiation.
This might involve other mechanisms and factors/parties, e.g.,
a mediator, a legal institution, participation fees, etc. The
standard way to implement such a thing is to allow money
1
In fact, given the k-dimensional space, these should be called 
indifference surfaces. However, we will not bog down to that level of
details.
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 509
and side-payments. In this paper, we ignore those side-effects
and assume that agent i"s utility function ui is normalised so
that ui : O → [0, 1].
EXAMPLE 1. There are two agents, A and B. Agent A has
a task T that needs to be done and also 100 units of a resource
R. Agent B has the capacity to perform task T and would like to
obtain at least 10 and at most 20 units of the resource R. Agent B is
indifferent on any amount between 10 and 20 units of the resource
R. The objective functions for both agents A and B are cost and
revenue. And they both aim at minimising costs while maximising
revenues. Having T done generates for A a revenue rA,T while
doing T incurs a cost cB,T to B. Agent B obtains a revenue rB,R
for each unit of the resource R while providing each unit of the
resource R costs agent A cA,R.
Assuming that money transfer between agents is possible, the set
Att then contains three attributes:
• T, taking values from the set {0, 1}, indicates whether the
task T is assigned to agent B;
• R, taking values from the set of non-negative integer, 
indicates the amount of resource R being allocated to agent B;
and
• MT, taking values from R, indicates the payment p to be
transferred from A to B.
Consider the outcome o = [T = 1, R = k, MT = p], i.e., the
task T is assigned to B, and A allocates to B with k units of the
resource R, and A transfers p dollars to B. Then, costA(o) =
k.cA,R + p and revA(o) = rA,T ; and costB(o) = cB,T and
revA(o) =
j
k.rB,R + p if 10 ≤ k ≤ 20
p otherwise.
And, σi(costi(o), revi(o)) = revi(o) − costi(o), (i = A, B).
