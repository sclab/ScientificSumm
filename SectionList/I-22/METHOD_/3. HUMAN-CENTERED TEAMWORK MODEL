People are limited information processors, and so are 
intelligent agent systems; this is especially true when they act
under hard or soft timing constraints imposed by the domain
problems. In respect to our goal to build realistic 
expectations among teammates, we take two important steps.
First, agents are resource-bounded; their processing 
capacity is limited by computing resources, inference 
knowledge, concurrent tasking capability, etc. We withdraw the
assumption that an agent knows all the information/intentions
communicated from other teammates. Instead, we contend
that due to limited processing capacity, an agent may only
have opportunities to process (make sense of) a portion of
the incoming information, with the rest ignored. Taking
this approach will largely change the way in which an agent
views (models) the involvement and cooperativeness of its
teammates in a team activity. In other words, the 
establishment of shared mental models regarding team members"
beliefs, intentions, and responsibilities can no longer rely on
inter-agent communication only. This being said, we are not
dropping the assumption that teammates are trustable.
We still stick to this, only that team members cannot 
overtrust each other; an agent has to consider the possibility that
its information being shared with others might not be as
effective as expected due to the recipients" limited 
processing capacities. Second, human teammates are bounded by
their cognitive capacities. As far as we know, the research
reported here is the first attempt in the area of 
humancentered multi-agent teamwork that really considers 
building and using human"s cognitive load model to facilitate
teamwork involving both humans and agents.
We use Hi, Ai to denote Human-Agent-Pair (HAP) i.
3.1 Computational Cognitive Capacity Model
An intelligent agent being a cognitive aid, it is desirable
that the model of its human partner implemented within
the agent is cognitively-acceptable, if not descriptively 
accurate. Of course, building a cognitive load model that is
cognitively-acceptable is not trivial; there exist a variety of
cognitive load theories and different measuring techniques.
We here choose to focus on the performance variables of
secondary tasks, given the ample evidence supporting 
secondary task performance as a highly sensitive and reliable
technique for measuring human"s cognitive load [12]. It"s
worth noting that just for the purpose of estimating a 
human subject"s cognitive load, any artificial task (e.g, pressing
a button in response to unpredictable stimuli) can be used
as a secondary task to force the subject to go through. 
However, in a realistic application, we have to make sure that the
selected secondary task interacts with the primary task in
meaningful ways, which is not easy and often depends on the
domain problem at hand. For example, in the experiment
below, we used the number of newly available information
correctly recalled as the secondary task, and the 
effective0 1 2 3 4
negligibly slightly fairly heavily overly
0.4 0.4 0.4 0.4 0.6
0.4
0.2 0.1
0.2
0.3
0.2
0.2
0.1
0.1
0.25
0.25
0.1
0.2
0.2
0 1 2 3 4 5 6 7 8 ≥ 9
B =
0
1
2
3
4
⎡
⎢
⎢
⎢
⎢
⎣
0 0 0 0 0 0.02 0.03 0.05 0.1 0.8
0 0 0 0 0 0.05 0.05 0.1 0.7 0.1
0 0 0 0 0.01 0.02 0.45 0.4 0.1 0.02
0.02 0.03 0.05 0.15 0.4 0.3 0.03 0.02 0 0
0.1 0.3 0.3 0.2 0.1 0 0 0 0 0
⎤
⎥
⎥
⎥
⎥
⎦
Figure 2: A HMM Cognitive Load Model.
ness of information sharing as the primary task. This is
realistic to intelligence workers because in time stress 
situations they have to know what information to share in order
to effectively establish an awareness of the global picture.
In the following, we adopt the Hidden Markov Model
(HMM) approach [13] to model human"s cognitive 
capacity. It is thus assumed that at each time step the secondary
task performance of a human subject in a team composed
of human-agent-pairs (HAP) is observable to all the team
members. Human team members" secondary task 
performance is used for estimating their hidden cognitive loads.
A HMM is denoted by λ = N, V, A, B, π , where N is a
set of hidden states, V is a set of observation symbols, A
is a set of state transition probability distributions, B is a
set of observation symbol probability distributions (one for
each hidden state), and π is the initial state distribution.
We consider a 5-state HMM model of human cognitive
load as follows (Figure 2). The hidden states are 0 
(negligiblyloaded), 1 (slightly-loaded), 2 (fairly-loaded), 3 
(heavilyloaded), and 4 (overly loaded). The observable states are
tied with secondary task performance, which, in this study,
is measured in terms of the number of items correctly 
recalled. According to Miller"s 7±2 rule, the observable states
take integer values from 0 to 9 ( the state is 9 when the
number of items correctly recalled is no less than 9). For
the example B Matrix given in Fig. 2, it is very likely that
the cognitive load of the subject is negligibly when the
number of items correctly recalled is larger than 9.
However, to determine the current hidden load status of
a human partner is not trivial. The model might be 
oversensitive if we only consider the last-step secondary task
performance to locate the most likely hidden state. There
is ample evidence suggesting that human cognitive load is
a continuous function over time and does not manifest 
sudden shifts unless there is a fundamental changes in tasking
demands. To address this issue, we place a constraint on
the state transition coefficients: no jumps of more than 2
states are allowed. In addition, we take the position that,
a human subject is very likely overloaded if his secondary
task performance is mostly low in recent time steps, while
he is very likely not overloaded if his secondary task 
performance is mostly high recently. This leads to the following
Windowed-HMM approach.
Given a pre-trained HMM λ of human cognitive load and
the recent observation sequence Ot of length w, let 
parameter w be the effective window size, ελ
t be the estimated
hidden state at time step t. First apply the HMM to the
observation sequence to find the optimal sequence of hidden
states Sλ
t = s1s2 · · · sw (Viterbi algorithm). Then, compute
the estimated hidden state ελ
t for the current time step, 
viewing it as a function of Sλ
t . We consider all the hidden states
in Sλ
t , weighted by their respective distance to ελ
t−1 (the 
estimated state of the last step): the closer of a state in Sλ
t
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 397
to ελ
t−1, the higher probability of the state being ελ
t . ελ
t is
set to be the state with the highest probability (note that a
state may have multiple appearances in Sλ
t ). More formally,
the probability of state s ∈ S being ελ
t is given by:
pλ(s, t) =
s=sj ∈Sλ
t
η(sj)e−|sj −ελ
t−1|
, (1)
where η(sj) = ej
/ w
k=1 ek
is the weight of sj ∈ Sλ
t (the
most recent hidden state has the most significant influence
in predicting the next state). The estimated state for the
current step is the state with maximum likelihood:
ελ
t = argmax
s∈Sλ
t
pλ(s, t) (2)
3.2 Agent Processing Load Model
According to schema theory [11], multiple elements of 
information can be chunked as single elements in cognitive
schemas. A schema can hold a huge amount of information,
yet is processed as a single unit. We adapt this idea and 
assume that agent i"s estimation of agent j"s processing load
at time step t is a function of two factors: the number of
chunks cj(t) and the total number sj(t) of information 
being considered by agent j. If cj(t) and sj(t) are observable
to agent i, agent i can employ a Windowed-HMM approach
as described in Section 3.1 to model and estimate agent j"s
instantaneous processing load.
In the study reported below, we also used 5-state HMM
models for agent processing load. With the 5 hidden states
similar to the HMM models adopted for human cognitive
load, we employed multivariate Gaussian observation 
probability distributions for the hidden states.
3.3 HAP"s Processing Load Model
As discussed above, a Human-Agent-Pair (HAP) is viewed
as a unit when teaming up with other HAPs. The processing
load of a HAP can thus be modeled as the co-effect of the
processing load of the agent and the cognitive load of the
human partner as captured by the agent.
Suppose agent Ai has models for its processing load and
its human partner Hi"s cognitive load. Denote the agent
processing load and human cognitive load of HAP Hi, Ai
at time step t by μi
t and νi
t, respectively. Agent Ai can use μi
t
and νi
t to estimate the load of Hi, Ai as a whole. Similarly,
if μj
t and νj
t are observable to agent Ai, it can estimate the
load of Hj, Aj . For model simplicity, we still used 5-state
HMM models for HAP processing load, with the estimated
hidden states of the corresponding agent processing load and
human cognitive load as the input observation vectors.
Building a load estimation model is the means. The goal
is to use the model to enhance information sharing 
performance so that a team can form better shared mental models
(e.g., to develop inter-agent role expectations in their 
collaboration), which is the key to high team performance.
3.4 Load-Sensitive Information Processing
Each agent has to adopt a certain strategy to process the
incoming information. As far as resource-bounded agents
are concerned, it is of no use for an agent to share 
information with teammates who are already overloaded; they
simply do not have the capacity to process the information.
Consider the incoming information processing strategy as
shown in Table 1. Agent Ai (of HAPi) ignores all the 
incoming information when it is overloaded, and processes all the
incoming information when it is negligibly loaded. When it
Table 1: Incoming information processing strategy
HAPi Load Strategy
Overly Ignore all shared info
Heavily Consider every teammate A ∈ [1, 1
q
|Q| ],
randomly process half amount of info from A;
Ignore info from any teammate B ∈ ( 1
q
|Q|, |Q|]
Fairly Process half of shared info from any teammate
Slightly Process all info from any A ∈ [1, 1
q
|Q| ];
For any teammate B ∈ ( 1
q
|Q|, |Q|]
randomly process half amount of info from B
Negligibly Process all shared info
HAPj Process all info from HAPj if it is overloaded
*Q is a FIFO queue of agents from whom this HAP has received
information at the current step; q is a constant known to all.
is heavily loaded, Ai randomly processes half of the messages
from those agents which are the first 1/q teammates 
appeared in its communication queue; when it is fairly loaded,
Ai randomly processes half of the messages from any 
teammates; when it is slightly loaded, Ai processes all the 
messages from those agents which are the first 1/q teammates
appeared in its communication queue, and randomly 
processes half of the messages from other teammates.
To further encourage sharing information at the right time,
the last row of Table 1 says that HAPi , if having not sent
information to HAPj who is currently overloaded, will 
process all the information from HAPj . This can be justified
from resource allocation perspective: an agent can reallocate
its computing resource reserved for communication to 
enhance its capacity of processing information. This strategy
favors never sending information to an overloaded 
teammate, and it suggests that estimating and exploiting 
others" loads can be critical to enable an agent to share the
right information with the right party at the right time.
