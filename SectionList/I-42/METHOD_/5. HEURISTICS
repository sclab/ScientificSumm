In our assessment of complexity in DCPOP we focused on the
worst case possibly produced by the algorithm. We acknowledge
744 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
Algorithm 1 DCPOP Algorithm
1: DCPOP(X; D; U)
Each agent Xi executes:
Phase 1: pseudotree creation
2: elect leader from all Xj ∈ X
3: elected leader initiates pseudotree creation
4: afterwards, Xi knows P(Xi), PP(Xi), BP(Xi), C(Xi), BC(Xi)
and PC(Xi)
Phase 2: UTIL message propagation
5: if |BP(Xi)| > 0 then
6: BRANCHXi ← |BP(Xi)| + 1
7: for all Xk ∈BP(Xi) do
8: UTILXi (Xk) ←Compute utils(Xi, Xk)
9: Send message(Xk,UTILXi (Xk),BRANCHXi )
10: if |C(Xi)| = 0(i.e. Xi is a leaf node) then
11: UTILXi (P(Xi)) ← Compute utils(P(Xi),PP(Xi))
for all PP(Xi)
12: Send message(P(Xi),
UTILXi (P(Xi)),BRANCHXi )
13: Send message(PP(Xi), empty UTIL,
empty BRANCH) to all PP(Xi)
14: activate UTIL Message handler()
Phase 3: VALUE message propagation
15: activate VALUE Message handler()
END ALGORITHM
UTIL Message handler(Xk,UTILXk (Xi),
BRANCHXk )
16: store UTILXk (Xi),BRANCHXk (Xi)
17: if UTIL messages from all children and branch children arrived
then
18: for all Bj ∈BRANCH(Xi) do
19: if Bj is merged then
20: join all hypercubes where Bj ∈UTIL(Xi)
21: eliminate Bj from the joined hypercube
22: if P(Xi) == null (that means Xi is the root) then
23: v ∗ i ← Choose optimal(null)
24: Send VALUE(Xi, v ∗ i) to all C(Xi)
25: else
26: UTILXi (P(Xi)) ← Compute utils(P(Xi),
PP(Xi))
27: Send message(P(Xi),UTILXi (P(Xi)),
BRANCHXi (P(Xi)))
VALUE Message handler(VALUEXi ,P(Xi))
28: add all Xk ← v ∗ k ∈VALUEXi ,P(Xi) to agent view
29: Xi ← v ∗ i =Choose optimal(agent view)
30: Send VALUEXl , Xi to all Xl ∈C(Xi)
that in real world problems the generation of the pseudotree has
a significant impact on the actual performance. The problem of
finding the best pseudotree for a given DCOP instance is NP-Hard.
Thus a heuristic is used for generation, and the performance of the
algorithm depends on the pseudotree found by the heuristic. Some
previous research focused on finding heuristics to generate good
pseudotrees [8]. While we have developed some heuristics that
generate good cross-edged pseudotrees for use with DCPOP, our
focus has been to use multiple heuristics and then select the best
pseudotree from the generated pseudotrees.
We consider only heuristics that run in polynomial time with 
respect to the number of nodes in the original DCOP instance. The
actual DCPOP algorithm has worst case exponential complexity,
but we can calculate the maximum message size, computation size,
and sequential path cost for a given cross-edged pseudotree in 
linear space-time complexity. To do this, we simply run the algorithm
without attempting to calculate any of the local utility hypercubes
or optimal value assignments. Instead, messages include 
dimensional and branch information but no utility hypercubes.
After each heuristic completes its generation of a pseudotree, we
execute the measurement procedure and propagate the 
measurement information up to the chosen root in that pseudotree. The
root then broadcasts the total complexity for that heuristic to all
nodes. After all heuristics have had a chance to complete, every
node knows which heuristic produced the best pseudotree. Each
node then proceeds to begin the DCPOP algorithm using its 
knowledge of the pseudotree generated by the best heuristic.
The heuristics used to generate traditional pseudotrees perform
a distributed DFS traversal. The general distributed algorithm uses
a token passing mechanism and a linear number of messages. 
Improved DFS based heuristics use a special procedure to choose the
root node, and also provide an ordering function over the neighbors
of a node to determine the order of path recursion. The DFS based
heuristics used in our experiments come from the work done in [4,
8].
5.1 The best-first cross-edged pseudotree
heuristic
The heuristics used to generate cross-edged pseudotrees 
perform a best-first traversal. A general distributed best-first 
algorithm for node expansion is presented in Algorithm 2. An 
evaluation function at each node provides the values that are used to
determine the next best node to expand. Note that in this 
algorithm each node only exchanges its best value with its neighbors.
In our experiments we used several evaluation functions that took
as arguments an ordered list of ancestors and a node, which 
contains a list of neighbors (with each neighbor"s placement depth in
the tree if it was placed). From these we can calculate 
branchparents, branch-children, and unknown relationships for a potential
node placement. The best overall function calculated the value as
ancestors−(branchparents+branchchildren) with the 
number of unknown relationships being a tiebreak. After completion
each node has knowledge of its parent and ancestors, so it can 
easily determine which connected nodes are pseudo-parents, 
branchparents, pseudo-children, and branch-children.
The complexity of the best-first traversal depends on the 
complexity of the evaluation function. Assuming a complexity of O(V )
for the evaluation function, which is the case for our best 
overall function, the best-first traversal is O(V · E) which is at worst
O(n3
). For each v ∈ V we perform a place operation, and find the
next node to place using the getBestNeighbor operation. The place
operation is at most O(V ) because of the sent messages. 
Finding the next node uses recursion and traverses only already placed
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 745
Algorithm 2 Distributed Best-First Search Algorithm
root ← electedleader
next(root, ∅)
place(node, parent)
node.parent ← parent
node.ancestors ← parent.ancestors ∪ parent
send placement message (node, node.ancestors) to all 
neighbors of node
next(current, previous)
if current is not placed then
place(current, previous)
next(current, ∅)
else
best ← getBestNeighbor(current, previous)
if best = ∅ then
if previous = ∅ then
terminate, all nodes are placed
next(previous, ∅)
else
next(best, current)
getBestNeighbor(current, previous)
best ← ∅; score ← 0
for all n ∈ current.neighbors do
if n! = previous then
if n is placed then
nscore ← getBestNeighbor(n, current)
else
nscore ← evaluate(current, n)
if nscore > score then
score ← nscore
best ← n
return best, score
nodes, so it has O(V ) recursions. Each recursion performs a 
recursive getBestNeighbor operation that traverses all placed nodes
and their neighbors. This operation is O(V · E), but results can
be cached using only O(V ) space at each node. Thus we have
O(V ·(V +V +V ·E)) = O(V 2
·E). If we are smart about evaluating
local changes when each node receives placement messages from
its neighbors and cache the results the getBestNeighbor operation
is only O(E). This increases the complexity of the place operation,
but for all placements the total complexity is only O(V · E). Thus
we have an overall complexity of O(V ·E+V ·(V +E)) = O(V ·E).
