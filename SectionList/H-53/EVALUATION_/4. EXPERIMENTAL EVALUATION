4.1 Evaluation metrics
We will measure both relevance improvement and the
stemming cost required to achieve the relevance.
1
a context segment can not be a single stop word.
4.1.1 Relevance measurement
We use a variant of the average Discounted Cumulative
Gain (DCG), a recently popularized scheme to measure search
engine relevance [1, 11]. Given a query and a ranked list of K
documents (K is set to 5 in our experiments), the DCG(K)
score for this query is calculated as follows:
DCG(K) =
KX
k=1
gk
log2(1 + k)
. (7)
where gk is the weight for the document at rank k. Higher
degree of relevance corresponds to a higher weight. A page is
graded into one of the five scales: Perfect, Excellent, Good,
Fair, Bad, with corresponding weights. We use dcg to 
represent the average DCG(5) over a set of test queries.
4.1.2 Stemming cost
Another metric is to measure the additional cost incurred
by stemming. Given the same level of relevance 
improvement, we prefer a stemming method that has less additional
cost. We measure this by the percentage of queries that are
actually stemmed, over all the queries that could possibly
be stemmed.
4.2 Data preparation
We randomly sample 870 queries from a three month
query log, with 290 from each month. Among all these 870
queries, we remove all misspelled queries since misspelled
queries are not of interest to stemming. We also remove all
one word queries since stemming one word queries without
context has a high risk of changing query intent, especially
for short words. In the end, we have 529 correctly spelled
queries with at least 2 words.
4.3 Naive stemming for Web search
Before explaining the experiments and results in detail,
we"d like to describe the traditional way of using stemming
for Web search, referred as the naive model. This is to treat
every word variant equivalent for all possible words in the
query. The query book store will be transformed into
(book OR books)(store OR stores) when limiting stemming
to pluralization handling only, where OR is an operator that
denotes the equivalence of the left and right arguments.
4.4 Experimental setup
The baseline model is the model without stemming. We
first run the naive model to see how well it performs over
the baseline. Then we improve the naive stemming model
by document sensitive matching, referred as document 
sensitive matching model. This model makes the same stemming
as the naive model on the query side, but performs 
conservative matching on the document side using the strategy
described in section 3.5. The naive model and document
sensitive matching model stem the most queries. Out of the
529 queries, there are 408 queries that they stem, 
corresponding to 46.7% query traffic (out of a total of 870). We
then further improve the document sensitive matching model
from the query side with selective word stemming based on
statistical language modeling (section 3.4), referred as 
selective stemming model. Based on language modeling 
prediction, this model stems only a subset of the 408 queries
stemmed by the document sensitive matching model. We
experiment with unigram language model and bigram 
language model. Since we only care how much we can improve
the naive model, we will only use these 408 queries (all the
queries that are affected by the naive stemming model) in
the experiments.
To get a sense of how these models perform, we also have
an oracle model that gives the upper-bound performance a
stemmer can achieve on this data. The oracle model only
expands a word if the stemming will give better results.
To analyze the pluralization handling influence on 
different query categories, we divide queries into short queries
and long queries. Among the 408 queries stemmed by the
naive model, there are 272 short queries with 2 or 3 words,
and 136 long queries with at least 4 words.
4.5 Results
We summarize the overall results in Table 4, and present
the results on short queries and long queries separately in
Table 5. Each row in Table 4 is a stemming strategy 
described in section 4.4. The first column is the name of the
strategy. The second column is the number of queries 
affected by this strategy; this column measures the stemming
cost, and the numbers should be low for the same level of
dcg. The third column is the average dcg score over all
tested queries in this category (including the ones that were
not stemmed by the strategy). The fourth column is the
relative improvement over the baseline, and the last column
is the p-value of Wilcoxon significance test.
There are several observations about the results. We can
see the naively stemming only obtains a statistically 
insignificant improvement of 1.5%. Looking at Table 5, it gives an
improvement of 2.7% on short queries. However, it also
hurts long queries by -2.4%. Overall, the improvement is
canceled out. The reason that it improves short queries is
that most short queries only have one word that can be
stemmed. Thus, blindly pluralizing short queries is 
relatively safe. However for long queries, most queries can have
multiple words that can be pluralized. Expanding all of
them without selection will significantly hurt precision.
Document context sensitive stemming gives a significant
lift to the performance, from 2.7% to 4.2% for short queries
and from -2.4% to -1.6% for long queries, with an overall
lift from 1.5% to 2.8%. The improvement comes from the
conservative context sensitive document matching. An 
expanded word is valid only if it occurs within the context of
original query in the document. This reduces many spurious
matches. However, we still notice that for long queries, 
context sensitive stemming is not able to improve performance
because it still selects too many documents and gives the
ranking function a hard problem. While the chosen window
size of 4 works the best amongst all the choices, it still 
allows spurious matches. It is possible that the window size
needs to be chosen on a per query basis to ensure tighter
proximity constraints for different types of noun phrases.
Selective word pluralization further helps resolving the
problem faced by document context sensitive stemming. It
does not stem every word that places all the burden on the
ranking algorithm, but tries to eliminate unnecessary 
stemming in the first place. By predicting which word variants
are going to be useful, we can dramatically reduce the 
number of stemmed words, thus improving both the recall and
the precision. With the unigram language model, we can 
reduce the stemming cost by 26.7% (from 408/408 to 300/408)
and lift the overall dcg improvement from 2.8% to 3.4%. In
particular, it gives significant improvements on long queries.
The dcg gain is turned from negative to positive, from âˆ’1.6%
to 1.1%. This confirms our hypothesis that reducing 
unnecessary word expansion leads to precision improvement. For
short queries too, we observe both dcg improvement and
stemming cost reduction with the unigram language model.
The advantages of predictive word expansion with a 
language model is further boosted with a better bigram 
language model. The overall dcg gain is lifted from 3.4%
to 3.9%, and stemming cost is dramatically reduced from
408/408 to 250/408, corresponding to only 29% of query
traffic (250 out of 870) and an overall 1.8% dcg 
improvement overall all query traffic. For short queries, bigram 
language model improves the dcg gain from 4.4% to 4.7%,
and reduces stemming cost from 272/272 to 150/272. For
long queries, bigram language model improves dcg gain from
1.1% to 2.5%, and reduces stemming cost from 136/136 to
100/136. We observe that the bigram language model gives
a larger lift for long queries. This is because the uncertainty
in long queries is larger and a more powerful language model
is needed. We hypothesize that a trigram language model
would give a further lift for long queries and leave this for
future investigation.
Considering the tight upper-bound 2
on the improvement
to be gained from pluralization handling (via the oracle
model), the current performance on short queries is very 
satisfying. For short queries, the dcg gain upper-bound is 6.3%
for perfect pluralization handling, our current gain is 4.7%
with a bigram language model. For long queries, the dcg
gain upper-bound is 4.6% for perfect pluralization handling,
our current gain is 2.5% with a bigram language model. We
may gain additional benefit with a more powerful language
model for long queries. However, the difficulties of long
queries come from many other aspects including the 
proximity and the segmentation problem. These problems have
to be addressed separately. Looking at the the upper-bound
of overhead reduction for oracle stemming, 75% (308/408)
of the naive stemmings are wasteful. We currently capture
about half of them. Further reduction of the overhead 
requires sacrificing the dcg gain.
Now we can compare the stemming strategies from a 
different aspect. Instead of looking at the influence over all
queries as we described above, Table 6 summarizes the dcg
improvements over the affected queries only. We can see
that the number of affected queries decreases as the 
stemming strategy becomes more accurate (dcg improvement).
For the bigram language model, over the 250/408 stemmed
queries, the dcg improvement is 6.1%. An interesting 
observation is the average dcg decreases with a better model,
which indicates a better stemming strategy stems more 
difficult queries (low dcg queries).
