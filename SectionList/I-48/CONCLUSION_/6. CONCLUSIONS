Social norms are supposed to restrict our behaviour. Of course,
such a restriction does not have to be bad: the fact that an agent"s
behaviour is restricted may seem a limitation, but there may be 
benefits if he can assume that others will also constrain their behaviour.
The question then, for an agent is, how to be sure that others will
comply with a norm. And, for a system designer, how to be sure
that the system will behave socially, that is, according to its norm.
Game theory is a very natural tool to analyse and answer these
questions, which involve strategic considerations, and we have 
proposed a way to translate key questions concerning logic-based 
normative systems to game theoretical questions. We have proposed
a logical framework to reason about such scenarios, and we have
given some computational costs for settling some of the main 
questions about them. Of course, our approach is in many senses open
for extension or enrichment. An obvious issue is to consider is the
complexity of the questions we give for more practical 
representations of models (cf. [1]), and to consider other classes of allowable
goals.
