THE ART TESTBED
To exemplify the use of mappings from last section, we define a
scenario where several agents are implemented using different
agent reputation models. This scenario includes the agents"
interaction during the simulation of the game defined by ART [6]
in order to describe the ways interoperability is possible between
different trust models using the FORe.
4.1 The ART testbed
The ART testbed provides a simulation engine on which several
agents, using different trust models, may run. The simulation
consists in a game where the agents have to decide to trust or not
other agents. The game"s domain is art appraisal, in which agents
are required to evaluate the value of paintings based on
information exchanged among other agents during agents"
interaction. The information can be an opinion transaction, when
an agent asks other agents to help it in its evaluation of a painting;
or a reputation transaction, when the information required is
about the reputation of another agent (a target) for a given era.
More details about the ART testbed can be found in [6].
The ART common reputation model was enhanced with semantic
data obtained from FORe. A general agent architecture for
interoperability was defined [11] to allow agents to reason about
the information received from reputation interactions. This
architecture contains two main modules: the Reputation Mapping
Module (RMM) which is responsible for mapping concepts
between an agent reputation model and FORe; and the Reputation
Reasoning Module (RRM) which is responsible for deal with
information about reputation according to the agent reputation
model.
4.2 Reputation transaction scenarios
While including the FORe to the ART common reputation model,
we have incremented it to allow richer interactions that involve
reputation transaction. In this section we describe scenarios
concerning reputation transactions in the context of ART testbed,
but the first is valid for any kind of reputation transaction and the
second is specific for the ART domain.
4.2.1 General scenario
Suppose that agents A, B and C are implemented according to the
aforementioned general agent architecture with the enhanced ART
common reputation model, using different reputation models.
Agent A uses the Typology of Reputation model, agent B uses the
Cognitive Reputation Model and agent C uses the ReGret System
model. Consider the interaction about reputation where agents A
and B receive from agent C information about the reputation of
agent Y. A big picture of this interaction is showed in Figure 2.
ReGret
Ontology
(Y, value=0.8,
witnessreputation)
C
Typol.
Ontology
(Y, value=0.8,
propagatedreputation)
A
CogMod.
Ontology
(Y, value=0.8,
reputation)
B
(Y, value=0.8,
PropagatedReputation)
(Y, value=0.8,
PropagatedReputation)
ReGret
Ontology
(Y, value=0.8,
witnessreputation)
C
ReGret
Ontology
(Y, value=0.8,
witnessreputation)
ReGret
Ontology
(Y, value=0.8,
witnessreputation)
(Y, value=0.8,
witnessreputation)
C
Typol.
Ontology
(Y, value=0.8,
propagatedreputation)
A
Typol.
Ontology
(Y, value=0.8,
propagatedreputation)
Typol.
Ontology
(Y, value=0.8,
propagatedreputation)
(Y, value=0.8,
propagatedreputation)
A
CogMod.
Ontology
(Y, value=0.8,
reputation)
B
CogMod.
Ontology
(Y, value=0.8,
reputation)
CogMod.
Ontology
(Y, value=0.8,
reputation)
(Y, value=0.8,
reputation)
B
(Y, value=0.8,
PropagatedReputation)
(Y, value=0.8,
PropagatedReputation)
(Y, value=0.8,
PropagatedReputation)
(Y, value=0.8,
PropagatedReputation)
Figure 1. Interaction about reputation
The information witness reputation from agent C is treated by its
RMM and is sent as PropagatedReputation to both agents. The
corresponding information in agent A reputation model is
propagated reputation and in agent B reputation model is
reputation. The way agents A and B make use of the information
depends on their internal reputation model and their RRM
implementation.
1048 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
4.2.2 ART scenario
Considering the same agents A and B and the art appraisal domain
of ART, another interesting scenario describes the following
situation: agent A asks to agent B information about agents it
knows that have skill on some specific painting era. In this case
agent A wants information concerning the direct reputation agent
B has about agents that have skill on an specific era, such as
cubism. Following the same steps of the previous scenario, agent
A message is prepared in its RRM using information from its
internal model. A big picture of this interaction is in Figure 2.
Typol.
Ontology
(agent = ?, value = ?,
skill = cubism,
reputation = directreputation)
A
(agent = ?, value = ?, skill = cubism,
reputation = PrimaryReputation)
CogMod.
Ontology
(agent = ?, value = ?,
skill = cubism,
reputation = image)
B
Typol.
Ontology
(agent = ?, value = ?,
skill = cubism,
reputation = directreputation)
A
(agent = ?, value = ?, skill = cubism,
reputation = PrimaryReputation)
CogMod.
Ontology
(agent = ?, value = ?,
skill = cubism,
reputation = image)
B
Figure 2. Interaction about specific types of reputation values
Agent B response to agent A is processed in its RRM and it is
composed of tuples (agent, value, cubism, image) , where
the pair (agent, value) is composed of all agents and associated
reputation values whose agent B knows their expertise about
cubism by its own opinion. This response is forwarded to the
RMM in order to be translated to the enriched common model and
to be sent to agent A. After receiving the information sent by
agent B, agent A processes it in its RMM and translates it to its
own reputation model to be analyzed by its RRM.
