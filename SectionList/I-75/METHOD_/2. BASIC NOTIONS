We start by defining the basic elements of our system.
Environment
Let O be the (potentially infinite) set of possible 
observations. We assume the sensors of our agents to be perfect,
hence the observations to be certain. Let H be the set of
hypotheses, uncertain and revisable. Let Cons(h, O) be the
consistency relation, a binary relation between a hypothesis
h ∈ H and a set of observations O ⊆ O. In most cases, Cons
will refer to classical consistency relation, however, we may
overload its meaning and add some additional properties to
that relation (in which case we will mention it).
The environment may include some dynamics, and change
over the course of time. We define below sequences of time
points to deal with it:
Definition 1 (Sequence of time points). A 
sequence of time points t1, t2, . . . , tn from t is an ordered
set of time points t1, t2, . . . , tn such that t1 ≥ t and
∀i ∈ [1, n − 1], ti+1 ≥ ti.
Agent
We take a system populated by n agents a1, . . . , an. Each
agent is defined as a tuple F, Oi, hi , where:
• F, the set of facts, common knowledge to all agents.
• Oi ∈ 2O
, the set of observations made by the agent
so far. We assume a perfect memory, hence this set
grows monotonically.
• hi ∈ H, the favourite hypothesis of the agent.
A key notion governing the formation of hypotheses is that
of consistency, defined below:
Definition 2 (Consistency). We say that:
• An agent is consistent (Cons(ai)) iff Cons(hi, Oi)
(that is, its hypothesis is consistent with its 
observation set).
• An agent ai consistent with a partner agent aj iff
Cons(ai) and Cons(hi, Oj) (that is, this agent is 
consistent and its hypothesis can explain the observation
set of the other agent).
• Two agents ai and aj are mutually consistent
(MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai).
• A system is consistent iff ∀(i, j)∈[1, n]2
it is the case
that MCons(ai, aj).
To ensure its consistency, each agent is equipped with an
abstract reasoning machinery that we shall call the 
explanation function Eh. This (deterministic) function takes a
set of observation and returns a single prefered hypothesis
(2O
→ H). We assume h = Eh(O) to be consistent with
O by definition of Eh, so using this function on its 
observation set to determine its favourite hypothesis is a sure way
for the agent to achieve consistency. Note however that an
hypothesis does not need to be generated by Eh to be 
consistent with an observation set. As a concrete example of such
a function, and one of the main inspiration of this work,
one can cite the Theorist reasoning system [6] -as long as
it is coupled with a filter selecting a single prefered theory
among the ones initially selected by Theorist.
Note also that hi may only be modified as a consequence
of the application Eh. We refer to this as the autonomy of the
agent: no other agent can directly impose a given 
hypothesis to an agent. As a consequence, only a new observation
(being it a new perception, or an observation communicated
by a fellow agent) can result in a modification of its prefered
hypothesis hi (but not necessarily of course).
We finally define a property of the system that we shall
use in the rest of the paper:
Definition 3 (Bounded Perceptions). A system
involves a bounded perception for agents iff ∃n0 s.t.
∀t| ∪N
i=1 Oi| ≤ n0. (That is, the number of observations to
be made by the agents in the system is not infinite.)
Agent Cycle
Now we need to see how these agents will evolve and interact
in their environment. In our context, agents evolve in a 
dynamic environment, and we classicaly assume the following
system cycle:
1. Environment dynamics: the environment evolves 
according to the defined rules of the system dynamics.
2. Perception step : agents get perceptions from the 
environment. These perceptions are typically partial (e.g.
the agent can only see a portion of a map).
3. Reasoning step: agents compare perception with
predictions, seek explanations for (potential) 
difference(s), refine their hypothesis, draw new conclusions.
4. Communication step: agents can communicate 
hypotheses and observations with other agents through
a defined protocol. Any agent can only be involved in
one communication with another agent by step.
5. Action step: agents do some practical reasoning using
the models obtained from the previous steps and select
an action. They can then modify the environment by
executing it.
The communication of the agents will be further 
constrained by topological consideration. At a given time, an
agent will only be able to communicate with a number of
neighbours. Its connexions with these others agents may
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999
evolve with its situation in the environment. Typically, an
agent can only communicate with agents that it can sense,
but one could imagine evolving topological constraints on
communication based on a network of communications 
between agents where the links are not always active.
Communication
In our system, agents will be able to communicate with each
other. However, due to the aforementionned topological 
constraints, they will not be able to communicate with any
agents at anytime. Who an agent can communicate with
will be defined dynamically (for instance, this can be a 
consequence of the agents being close enough to get in touch).
We will abstractly denote by C(ai, aj, t) the communication
property, in other words, the fact that agents ai and aj can
communicate at time t (note that this relation is assumed
to be symetric, but of course not transitive). We are now in
a position to define two essential properties of our system.
Definition 4 (Temporal Path). There exists a 
temporal communication path at horizon tf (noted Ltf (aI , aJ ))
between ai and aj iff there exists a sequence of time points
t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn
s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n],
C(aki , aki+1 , ti)
Intuitively, what this property says is that it is possible to
find a temporal path in the future that would allow to link
agent ai and aj via a sequence of intermediary agents. Note
that the time points are not necessarily successive, and that
the sequence of agents may involve the same agents several
times.
Definition 5 (Temporal Connexity). A system is
temporaly connex iff ∀t ∀(i, j)∈[1, n]2
Lt(ai, aj)
In short, a temporaly connex system guarantees that any
agent will be able to communicate with any other agents,
no matter how long it might take to do so, at any time. To
put it another way, it is never the case that an agent will be
isolated for ever from another agent of the system.
We will next discuss the detail of how communication 
concretely takes place in our system. Remember that in this
paper, we only consider the case of bilateral exchanges (an
agent can only speak to a single other agent), and that we
also assume that any agent can only engage in a single 
exchange in a given round.
