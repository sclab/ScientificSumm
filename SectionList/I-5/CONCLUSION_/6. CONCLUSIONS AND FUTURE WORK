In this paper a self-organising distributed resource 
allocation technique for multi-agent systems was presented. We
enable agents to select the execution platform for their tasks
themselves before each execution at run-time. In our 
approach the agents compete for an allocation at one of the
0 500 1,000 1,500 2,000
Time
0
2,500
5,000
7,500
ResourceLoad
(a) Total resource load 
versus total shared resource 
capacity
0 500 1,000 1,500 2,000
Time
0
500
1,000
1,500
2,000
2,500
3,000
3,500
4,000
ResourceLoad
(b) Resource load server 1
0 500 1,000 1,500 2,000
Time
0
500
1,000
1,500
2,000
2,500
3,000
3,500
4,000
ResourceLoad
(c) Resource load server 2
0 500 1,000 1,500 2,000
Time
0
500
1,000
1,500
2,000
2,500
3,000
3,500
4,000
ResourceLoad
(d) Resource load server 3
Figure 5: Results of experiment 2 in a dynamic
server environment averaged over 100 repetitions.
available shared resource. Agents sense their server 
environment and adopt their action to compete more efficient in
the new created environment. This process is adaptive and
has a strong feedback as allocation decisions influence 
indirectly decisions of other agents. The resource allocation is a
purely emergent effect. Our mechanism demonstrates that
resource allocation can be done by the effective 
competition of individual and autonomous agents. Neither do they
need coordination or information from a higher authority
nor is an additional direct communication between agents
required.
This mechanism was inspired by inductive reasoning and
bounded rationality principles which enables the agents" 
adaptation of their strategies to compete effectively in a 
dynamic environment. In the case of a server becomes 
unavailable, the agents can adapt quickly to this new situation
by exploring new resources or remain at the home server
if an allocation is not possible. Especially in dynamic and
scalable environments such as grid systems, a robust and
distributed mechanism for resource allocation is required.
Our self-organising resource allocation approach was 
evaluated with a number of simulation experiments in a dynamic
environment of agents and server resources. The presented
results for this new approach for strategic migration 
optimisation are very promising and justify further investigation
in a real multi-agent system environment.
It is a distributed, scalable and easy-to-understand 
policy for the regulation of supply and demand of resources.
All control is implemented in the agents. A simple decision
mechanism based on different beliefs of the agent creates an
emergent behaviour that leads to effective resource 
allocation. This approach can be easily extended or supported
by resource balancing/queuing mechanisms provided by 
resources.
Our approach adapts to changes in the environment but it
is not evolutionary. There is no discovery of new strategies
by the agents. The set of predictors stays the same over the
whole life. In fact, we believe that this could further improve
the system"s behaviour over a long term period and could be
80 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
investigated in the future. The evolution would be very slow
and selective and will not influence the system behaviour
in a short-term period that is covered by our experimental
results.
In the near future we will investigate if an automatic 
adaptation of the decay rate of historical information our 
algorithm is possible and can improve the resource allocation
performance. The decay rate is currently predefined and
must be altered manually depending on the environment.
A large number of shared resources requires older historical
information to avoid a too frequently resources exploration.
In contrast, a dynamic environment with varying capacities
requires more up-to-date information to make more reliable
predictions.
We are aware of the long learning phase in environments
with a large number of shared resources known by each
agent. In the case that more resources are requested by
agents than shared resources are provided by all servers, all
agents will randomly explore all known servers. This 
process of acquiring resource load information about all servers
can take a long time in the case that no not enough shared
resources for all tasks are provided. In the worst case, by
the time for exploring all servers, historical information of
some servers could be already outdated and the exploration
starts again. In this situation, it is difficult for an agent
to efficiently gather historical information about all remote
servers. This issue needs more investigation in the future.
