Ranking search results is a fundamental problem in
information retrieval. The most common approaches in the
context of the web use both the similarity of the query to the
page content, and the overall quality of a page [3, 20]. A 
state-ofthe-art search engine may use hundreds of features to describe a
candidate page, employing sophisticated algorithms to rank
pages based on these features. Current search engines are
commonly tuned on human relevance judgments. Human
annotators rate a set of pages for a query according to perceived
relevance, creating the gold standard against which different
ranking algorithms can be evaluated. Reducing the dependence on
explicit human judgments by using implicit relevance feedback
has been an active topic of research.
Several research groups have evaluated the relationship
between implicit measures and user interest. In these studies,
both reading time and explicit ratings of interest are collected.
Morita and Shinoda [14] studied the amount of time that users
spent reading Usenet news articles and found that reading time
could predict a user"s interest levels. Konstan et al. [13] showed
that reading time was a strong predictor of user interest in their
GroupLens system. Oard and Kim [15] studied whether implicit
feedback could substitute for explicit ratings in recommender
systems. More recently, Oard and Kim [16] presented a
framework for characterizing observable user behaviors using two
dimensions-the underlying purpose of the observed behavior and
the scope of the item being acted upon.
Goecks and Shavlik [8] approximated human labels by
collecting a set of page activity measures while users browsed the
World Wide Web. The authors hypothesized correlations between
a high degree of page activity and a user"s interest. While the
results were promising, the sample size was small and the
implicit measures were not tested against explicit judgments of
user interest. Claypool et al. [6] studied how several implicit
measures related to the interests of the user. They developed a
custom browser called the Curious Browser to gather data, in a
computer lab, about implicit interest indicators and to probe for
explicit judgments of Web pages visited. Claypool et al. found
that the time spent on a page, the amount of scrolling on a page,
and the combination of time and scrolling have a strong positive
relationship with explicit interest, while individual scrolling
methods and mouse-clicks were not correlated with explicit
interest. Fox et al. [7] explored the relationship between implicit
and explicit measures in Web search. They built an instrumented
browser to collect data and then developed Bayesian models to
relate implicit measures and explicit relevance judgments for both
individual queries and search sessions. They found that
clickthrough was the most important individual variable but that
predictive accuracy could be improved by using additional
variables, notably dwell time on a page.
Joachims [9] developed valuable insights into the collection of
implicit measures, introducing a technique based entirely on
clickthrough data to learn ranking functions. More recently,
Joachims et al. [10] presented an empirical evaluation of
interpreting clickthrough evidence. By performing eye tracking
studies and correlating predictions of their strategies with explicit
ratings, the authors showed that it is possible to accurately
interpret clickthrough events in a controlled, laboratory setting. A
more comprehensive overview of studies of implicit measures is
described in Kelly and Teevan [12].
Unfortunately, the extent to which existing research applies to
real-world web search is unclear. In this paper, we build on
previous research to develop robust user behavior interpretation
models for the real web search setting.
