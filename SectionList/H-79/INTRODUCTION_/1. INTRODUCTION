Over the past decade, the Web has grown exponentially in size.
Unfortunately, this growth has not been isolated to good-quality
pages. The number of incorrect, spamming, and malicious (e.g.,
phishing) sites has also grown rapidly. The sheer number of both
good and bad pages on the Web has led to an increasing reliance
on search engines for the discovery of useful information. Users
rely on search engines not only to return pages related to their
search query, but also to separate the good from the bad, and
order results so that the best pages are suggested first.
To date, most work on Web page ranking has focused on
improving the ordering of the results returned to the user 
(querydependent ranking, or dynamic ranking). However, having a good
query-independent ranking (static ranking) is also crucially
important for a search engine. A good static ranking algorithm
provides numerous benefits:
• Relevance: The static rank of a page provides a general
indicator to the overall quality of the page. This is a
useful input to the dynamic ranking algorithm.
• Efficiency: Typically, the search engine"s index is
ordered by static rank. By traversing the index from 
highquality to low-quality pages, the dynamic ranker may
abort the search when it determines that no later page
will have as high of a dynamic rank as those already
found. The more accurate the static rank, the better this
early-stopping ability, and hence the quicker the search
engine may respond to queries.
• Crawl Priority: The Web grows and changes as quickly
as search engines can crawl it. Search engines need a way
to prioritize their crawl-to determine which pages to 
recrawl, how frequently, and how often to seek out new
pages. Among other factors, the static rank of a page is
used to determine this prioritization. A better static rank
thus provides the engine with a higher quality, more 
upto-date index.
Google is often regarded as the first commercially successful
search engine. Their ranking was originally based on the
PageRank algorithm [5][27]. Due to this (and possibly due to
Google"s promotion of PageRank to the public), PageRank is
widely regarded as the best method for the static ranking of Web
pages.
Though PageRank has historically been thought to perform quite
well, there has yet been little academic evidence to support this
claim. Even worse, there has recently been work showing that
PageRank may not perform any better than other simple measures
on certain tasks. Upstill et al. have found that for the task of
finding home pages, the number of pages linking to a page and the
type of URL were as, or more, effective than PageRank [32]. They
found similar results for the task of finding high quality
companies [31]. PageRank has also been used in systems for
TREC"s very large collection and Web track competitions,
but with much less success than had been expected [17]. Finally,
Amento et al. [1] found that simple features, such as the number
of pages on a site, performed as well as PageRank.
Despite these, the general belief remains among many, both
academic and in the public, that PageRank is an essential factor
for a good static rank. Failing this, it is still assumed that using the
link structure is crucial, in the form of the number of inlinks or the
amount of anchor text.
In this paper, we show there are a number of simple url- or 
pagebased features that significantly outperform PageRank (for the
purposes of statically ranking Web pages) despite ignoring the
structure of the Web. We combine these and other static features
using machine learning to achieve a ranking system that is
significantly better than PageRank (in pairwise agreement with
human labels).
A machine learning approach for static ranking has other
advantages besides the quality of the ranking. Because the
measure consists of many features, it is harder for malicious users
to manipulate it (i.e., to raise their page"s static rank to an
undeserved level through questionable techniques, also known as
Web spamming). This is particularly true if the feature set is not
known. In contrast, a single measure like PageRank can be easier
to manipulate because spammers need only concentrate on one
goal: how to cause more pages to point to their page. With an
algorithm that learns, a feature that becomes unusable due to
spammer manipulation will simply be reduced or removed from
the final computation of rank. This flexibility allows a ranking
system to rapidly react to new spamming techniques.
A machine learning approach to static ranking is also able to take
advantage of any advances in the machine learning field. For
example, recent work on adversarial classification [12] suggests
that it may be possible to explicitly model the Web page
spammer"s (the adversary) actions, adjusting the ranking model in
advance of the spammer"s attempts to circumvent it. Another
example is the elimination of outliers in constructing the model,
which helps reduce the effect that unique sites may have on the
overall quality of the static rank. By moving static ranking to a
machine learning framework, we not only gain in accuracy, but
also gain in the ability to react to spammer"s actions, to rapidly
add new features to the ranking algorithm, and to leverage
advances in the rapidly growing field of machine learning.
Finally, we believe there will be significant advantages to using
this technique for other domains, such as searching a local hard
drive or a corporation"s intranet. These are domains where the
link structure is particularly weak (or non-existent), but there are
other domain-specific features that could be just as powerful. For
example, the author of an intranet page and his/her position in the
organization (e.g., CEO, manager, or developer) could provide
significant clues as to the importance of that page. A machine
learning approach thus allows rapid development of a good static
algorithm in new domains.
This paper"s contribution is a systematic study of static features,
including PageRank, for the purposes of (statically) ranking Web
pages. Previous studies on PageRank typically used subsets of the
Web that are significantly smaller (e.g., the TREC VLC2 corpus,
used by many, contains only 19 million pages). Also, the
performance of PageRank and other static features has typically
been evaluated in the context of a complete system for dynamic
ranking, or for other tasks such as question answering. In contrast,
we explore the use of PageRank and other features for the direct
task of statically ranking Web pages.
We first briefly describe the PageRank algorithm. In Section 3 we
introduce RankNet, the machine learning technique used to
combine static features into a final ranking. Section 4 describes
the static features. The heart of the paper is in Section 5, which
presents our experiments and results. We conclude with a
discussion of related and future work.
