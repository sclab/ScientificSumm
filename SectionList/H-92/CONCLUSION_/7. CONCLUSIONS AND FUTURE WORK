In this paper we explored the utility of incorporating noisy implicit
feedback obtained in a real web search setting to improve web
search ranking. We performed a large-scale evaluation over 3,000
queries and more than 12 million user interactions with a major
search engine, establishing the utility of incorporating noisy
implicit feedback to improve web search relevance.
We compared two alternatives of incorporating implicit feedback
into the search process, namely reranking with implicit feedback
and incorporating implicit feedback features directly into the
trained ranking function. Our experiments showed significant
improvement over methods that do not consider implicit feedback.
The gains are particularly dramatic for the top K=1 result in the
final ranking, with precision improvements as high as 31%, and
the gains are substantial for all values of K. Our experiments
showed that implicit user feedback can further improve web
search performance, when incorporated directly with popular
content- and link-based features.
Interestingly, implicit feedback is particularly valuable for queries
with poor original ranking of results (e.g., MAP lower than 0.1).
One promising direction for future work is to apply recent research
on automatically predicting query difficulty, and only attempt to
incorporate implicit feedback for the difficult queries. As
another research direction we are exploring methods for extending
our predictions to the previously unseen queries (e.g., query
clustering), which should further improve the web search
experience of users.
ACKNOWLEDGMENTS
We thank Chris Burges and Matt Richardson for an
implementation of RankNet for our experiments. We also thank
Robert Ragno for his valuable suggestions and many discussions.
