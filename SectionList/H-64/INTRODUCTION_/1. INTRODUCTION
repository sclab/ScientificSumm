The GovStat Project is a joint effort of the University
of North Carolina Interaction Design Lab and the 
University of Maryland Human-Computer Interaction Lab1
. 
Citing end-user difficulty in finding governmental information
(especially statistical data) online, the project seeks to 
create an integrated model of user access to US government
statistical information that is rooted in realistic data 
models and innovative user interfaces. To enable such models
and interfaces, we propose a data-driven approach, based
on data mining and machine learning techniques. In 
particular, our work analyzes a particular digital library-the
website of the Bureau of Labor Statistics2
(BLS)-in efforts
to discover a small number of linguistically meaningful 
concepts, or bins, that collectively summarize the semantic
domain of the site.
The project goal is to classify the site"s web content 
according to these inferred concepts as an initial step towards
data filtering via active user interfaces (cf. [13]). Many
digital libraries already make use of content classification,
both explicitly and implicitly; they divide their resources
manually by topical relation; they organize content into 
hierarchically oriented file systems. The goal of the present
1
http://www.ils.unc.edu/govstat
2
http://www.bls.gov
151
research is to develop another means of browsing the content
of these collections. By analyzing the distribution of terms
across documents, our goal is to supplement the agency"s
pre-existing information structures. Statistical learning 
technologies are appealing in this context insofar as they stand
to define a data-driven-as opposed to an 
agency-drivennavigational structure for a site.
Our approach combines supervised and unsupervised 
learning techniques. A pure document clustering [12] approach
to such a large, diverse collection as BLS led to poor results
in early tests [6]. But strictly supervised techniques [5] are
inappropriate, too. Although BLS designers have defined
high-level subject headings for their collections, as we 
discuss in Section 2, this scheme is less than optimal. Thus we
hope to learn an additional set of concepts by letting the
data speak for themselves.
The remainder of this paper describes the details of our
concept discovery efforts and subsequent evaluation. In 
Section 2 we describe the previously existing, human-created
conceptual structure of the BLS website. This section also
describes evidence that this structure leaves room for 
improvement. Next (Sections 3-5), we turn to a description
of the concepts derived via content clustering under three
document representations: keyword, title only, and full-text.
Section 6 describes a two-part evaluation of the derived 
conceptual structures. Finally, we conclude in Section 7 by 
outlining upcoming work on the project.
