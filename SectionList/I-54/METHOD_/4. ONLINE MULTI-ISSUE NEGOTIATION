We now consider a more general and, arguably more realistic, 
version of multi-issue negotiation, where the agents are uncertain about
the issues they will have to negotiate about in future. In this setting,
when negotiating an issue, the agents know that they will negotiate
more issues in the future, but they are uncertain about the details of
those issues. As before, let m be the total number of issues that are
up for negotiation. The agents have a probability distribution over
the possible values of ka
c and kb
c. For 1 ≤ c ≤ m let ka
c and kb
c be
uniformly distributed over [0,1]. This probability distribution, n,
and m are common knowledge to the agents. However, the agents
come to know ka
c and kb
c only just before negotiation for issue c
begins. Once the agents reach an agreement on issue c, it cannot be
re-negotiated.
This scenario requires online negotiation since the agents must
make decisions about an issue prior to having the information about
the future issues [3]. We first give a brief introduction to online
problems and then draw an analogy between the online knapsack
problem and the negotiation problem we want to solve.
In an online problem, data is given to the algorithm 
incrementally, one unit at a time [3]. The online algorithm must also 
produce the output incrementally: after seeing i units of input it must
output the ith unit of output. Since decisions about the output are
made with incomplete knowledge about the entire input, an 
online algorithm often cannot produce an optimal solution. Such an
algorithm can only approximate the performance of the optimal 
algorithm that sees all the inputs in advance. In the design of online
algorithms, the main aim is to achieve a performance that is close
to that of the optimal offline algorithm on each input. An online 
algorithm is said to be stochastic if it makes decisions on the basis of
the probability distributions for the future inputs. The performance
of stochastic online algorithms is assessed in terms of the expected
difference between the optimum and the approximate solution 
(denoted E[z∗
m −zm] where z∗
m is the optimal and zm the approximate
solution). Note that the subscript m is used to indicate the fact that
this difference depends on m.
We now describe the protocol for online negotiation and then
obtain an approximate equilibrium. The protocol is defined as 
follows. Let agent a denote the first mover (since we focus on the
package deal procedure, the first mover is the same for all the m
issues).
Step 1. For c = 1, the agents are given the values of ka
c and kb
c.
These two values are now common5
knowledge.
Step 2. The agents settle issue c using the alternating offers 
protocol described in Section 2. Negotiation for issue c must end
within n time periods from the start of negotiation on the 
issue. If an agreement is not reached within this time, then
negotiation fails on this and on all remaining issues.
Step 3. The above steps are repeated for issues c = 2, 3, . . . , m.
Negotiation for issue c (2 ≤ c ≤ m) begins in the time
period following an agreement on issue c − 1.
5
We assume common knowledge because it simplifies exposition.
However, if ka
c (kb
c) is a"s (b"s) private knowledge, then our analysis
will still hold but now an agent must find its opponent"s expected
utility on the basis of the p.d.fs for ka
c and kb
c.
Thus, during time period t, the problem for the offering agent (say
a) is to find the optimal offer for issue c on the basis of ka
c and
kb
c and the probability distribution for ka
i and kb
i (c < i ≤ m).
In order to solve this online negotiation problem we draw analogy
with the online knapsack problem. Before doing so, however, we
give a brief overview of the online knapsack problem.
In the online knapsack problem, there are m items. The agent
must examine the m items one at a time according to the order they
are input (i.e., as their profit and size coefficients become known).
Hence, the algorithm is required to decide whether or not to 
include each item in the knapsack as soon as its weight and profit
become known, without knowledge concerning the items still to be
seen, except for their total number. Note that since the agents have
a probability distribution over the weights and profits of the future
items, this is a case of stochastic online knapsack problem. Our 
online negotiation problem is analogous to the online knapsack 
problem. This analogy is described in detail in the proof for Theorem 5.
Again, researchers in algorithms have developed time efficient 
approximate solutions to the online knapsack problem [16]. Hence
we use this solution and show that it forms an equilibrium.
The following theorem characterizes an approximate equilibrium
for online negotiation. Here the agents have to choose a 
strategy without knowing the features of the future issues. Because of
this information incompleteness, the relevant equilibrium solution
is that of a Bayes" Nash Equilibrium (BNE) in which each agent
plays the best response to the other agents with respect to their 
expected utilities [18]. However, finding an agent"s BNE strategy is
analogous to solving the online 0-1 knapsack problem. Also, the
online knapsack can only be solved approximately [16]. Hence
the relevant equilibrium solution concept is approximate BNE (see
[26] for example). The following theorem finds this equilibrium
using procedures ONLINE- TRADEOFFA and ONLINE-TRADEOFFB
which are defined in the proof of the theorem. For a given time
period, we let zm denote the approximately optimal solution 
generated by ONLINE-TRADEOFFA (or ONLINE-TRADEOFFB) and z∗
m
the actual optimum.
THEOREM 5. For the package deal procedure, the following
strategies form an approximate Bayes" Nash equilibrium. The 
equilibrium strategy for t = n is:
A(n) =
j
OFFER [1, 0] IF a"s TURN
ACCEPT IF b"s TURN
B(n) =
j
OFFER [0, 1] IF b"s TURN
ACCEPT IF a"s TURN
For all preceding time periods t < n, if [xt
, yt
] denotes the 
offer made at time t, then the equilibrium strategies are defined as
follows:
A(t) =
8
<
:
OFFER ONLINE-TRADEOFFA(P, UB(t), t) IF a"s TURN
If (Ua
([xt
, yt
], t) ≥ UA(t)) ACCEPT
else REJECT IF b"s TURN
B(t) =
8
<
:
OFFER ONLINE-TRADEOFFB(P, UA(t), t) IF b"s TURN
If (Ub
([xt
, yt
], t) ≥ UB(t)) ACCEPT
else REJECT IF a"s TURN
where UA(t) = Ua
([¯at+1
,¯bt+1
], t + 1) and UB(t) = Ub
([¯at+1
,
¯bt+1
], t + 1). An agreement on issue c takes place at t = c. For a
given time period, the expected difference between the solution 
generated by the optimal strategy and that by the approximate strategy
is E[z∗
m − zm] = O(
√
m).
956 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
PROOF. As in Theorem 1 we find the equilibrium offer for time
period t = 1 using backward induction. Let a be the offering agent
for t = 1 for all the m issues. Consider the last time period t = n
(recall from Step 2 of the online protocol that n is the deadline for
completing negotiation on the first issue). Since the first mover is
the same for all the issues, and the agents make offers alternately,
the offering agent for t = n is also the same for all the m issues.
Assume that b is the offering agent for t = n. As in Section 3,
the offering agent for t = n gets a hundred percent of all the m
issues. Since b is the offering agent for t = n, his utility for this
time period is:
UB(n) = kb
1δn−1
1 + 1/2
mX
i=2
δ
i(n−1)
i (6)
Recall that ka
i and kb
i (for c < i ≤ m) are not known to the
agents. Hence, the agents can only find their expected utilities from
the future issues on the basis of the probability distribution 
functions for ka
i and kb
i . However, during the negotiation for issue c
the agents know ka
c but not kb
c (see Step 1 of the online protocol).
Hence, a computes UB(n) as follows. Agent b"s utility from issue
c = 1 is kb
1δn−1
1 (which is the first term of Equation 6). Then,
on the basis of the probability distribution functions for ka
i and
kb
i , agent a computes b"s expected utility from each future issue i
as δ
i(n−1)
i /2 (since ka
i and kb
i are uniformly distributed on [0, 1]).
Thus, b"s expected cumulative utility from these m − c issues is
1/2
Pm
i=2 δ
i(n−1)
i (which is the second term of Equation 6).
Now, in order to decide what to offer for issue c = 1, the offering
agent for t = n − 1 (i.e., agent a) must solve the following online
knapsack problem:
maximize Σm
i=1ka
i (1 − ¯bt
i)δn−1
i (7)
such that Σm
i=1kb
i
¯bt
i ≥ UB(n)
¯bt
i = 0 or 1 for 1 ≤ i ≤ m
The only variables in the above maximization problem are ¯bt
i. Now,
maximizing Σm
i=1ka
i (1−¯bt
i)δn−1
i is the same as minimizing Σm
i=1ka
i
¯bt
i
since δn−1
i and ka
i are constants. Thus, we write Equation 7 as:
minimize Σm
i=1ka
i
¯bt
i (8)
such that Σm
i=1kb
i
¯bt
i ≥ UB(n)
¯bt
i = 0 or 1 for 1 ≤ i ≤ m
The above optimization problem is analogous to the online 0-1
knapsack problem. An algorithm to solve the online knapsack 
problem has already proposed in [16]. This algorithm is called the
fixed-choice online algorithm. It has time complexity linear in the
number of items (m) in the knapsack problem. We use this to solve
our online negotiation problem. Thus, our ONLINE-TRADEOFFA
algorithm is nothing but the fixed-choice online algorithm and 
therefore has the same time complexity as the latter. This algorithm takes
the values of ka
i and kb
i one at a time and generates an approximate
solution to the above knapsack problem. The expected difference
between the optimum and approximate solution is E[z∗
m − zm] =
O(
√
m) [16] (see [16] for the detailed fixed-choice online 
algorithm and a proof for E[z∗
m − zm] = O(
√
m)).
The fixed-choice online algorithm of [16] is a generalization of
the basic greedy algorithm for the offline knapsack problem; the
idea behind it is as follows. A threshold value is determined on the
basis of the information regarding weights and profits for the 0-1
knapsack problem. The method then includes into the knapsack all
items whose profit density (profit density of an item is its profit per
unit weight) exceeds the threshold until either the knapsack is filled
or all the m items have been considered.
In more detail, the algorithm ONLINE-TRADEOFFA works as 
follows. It first gets the values of ka
1 and kb
1 and finds ¯bt
c. Since we
have a 0-1 knapsack problem, ¯bt
c can be either zero or one. Now, if
¯bt
c = 1 for t = n, then ¯bt
c must be one for 1 ≤ t < n (i.e., a must
offer ¯bt
c = 1 at t = 1). If ¯bt
c = 1 for t = n, but a offers ¯bt
c = 0
at t = 1, then agent b gets less utility than what it expects from a"s
offer and rejects the proposal. Thus, if ¯bt
c = 1 for t = n, then the
optimal strategy for a is to offer ¯bt
c = 1 at t = 1. Agent b accepts
the offer. Thus, negotiation on the first issue starts at t = 1 and an
agreement on it is also reached at t = 1.
In the next time period (i.e., t = 2), negotiation proceeds to the
next issue. The deadline for the second issue is n time periods from
the start of negotiation on the issue. For c = 2, the algorithm
ONLINE-TRADEOFFA is given the values of ka
2 and kb
2 and finds ¯bt
c
as described above. Agent offers bc at t = 2 and b accepts. Thus,
negotiation on the second issue starts at t = 2 and an agreement
on it is also reached at t = 2.
This process repeats for the remaining issues c = 3, . . . , m.
Thus, each issue is agreed upon in the same time period in which
it starts. As negotiation for the next issue starts in the following
time period (see step 3 of the online protocol), agreement on issue
i occurs at time t = i.
On the other hand, if b is the offering agent at t = 1, he uses
the algorithm ONLINE-TRADEOFFB which is defined analogously.
Thus, irrespective of who makes the first move, all the m issues are
settled at time t = m.
THEOREM 6. The time complexity of finding the approximate
equilibrium offers of Theorem 5 is linear in m.
PROOF. The time complexity of ONLINE-TRADEOFFA and 
ONLINETRADEOFFB is the same as the time complexity of the fixed-choice
online algorithm of [16]. Since the latter has time complexity linear
in m, the time complexity of ONLINE-TRADEOFFA and 
ONLINETRADEOFFB is also linear in m.
It is worth noting that, for the 0-1 knapsack problem, the lower
bound on the expected difference between the optimum and the 
solution found by any online algorithm is Ω(1) [16]. Thus, it follows
that this lower bound also holds for our negotiation problem.
