A promising extension to the work presented here is a hybrid
distribution of a Gaussian (on the outside slopes) and exponentials
(on the inner slopes). From the empirical evidence presented in
[22], the expectation is that such a distribution might allow more
emphasis of the probability mass around the modes (as with the
exponential) while still providing more accurate estimates toward
the tails.
Just as logistic regression allows the log-odds of the posterior
distribution to be fit directly with a line, we could directly fit the
log-odds of the posterior with a three-piece line (a spline) instead of
indirectly doing the same thing by fitting the asymmetric Laplace.
This approach may provide more power since it retains the 
asymmetry assumption but not the assumption that the class-conditional
densities are from an asymmetric Laplace.
Finally, extending these methods to the outputs of other 
discriminative classifiers is an open area. We are currently evaluating the
appropriateness of these methods for the output of a voted 
perceptron [11]. By analogy to the log-odds, the operative score that 
appears promising is log
weight perceptrons voting +
weight perceptrons voting âˆ’
.
