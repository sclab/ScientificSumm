We picked 28 topics from the TDT2 corpus and 25 topics from
the TDT3 corpus. The criterion we used for selecting a topic is that
it should contain at least 15 on-topic stories from CNN headline
news. If the topic contained more than 30 CNN stories, we picked
only the first 30 stories to keep the topic short enough for 
annotators. The reason for choosing only CNN as the source is that the
stories from this source tend to be short and precise and do not tend
to digress or drift too far away from the central theme. We believe
modeling such stories would be a useful first step before dealing
with more complex data sets.
We hired an annotator to create truth data. Annotation includes
defining the event membership for each story and also the 
dependencies. We supervised the annotator on a set of three topics that
we did our own annotations on and then asked her to annotate the
28 topics from TDT2 and 25 topics from TDT3.
In identifying events in a topic, the annotator was asked to broadly
follow the TDT definition of an event, i.e., ‘something that happens
at a specific time and location". The annotator was encouraged to
merge two events A and B into a single event C if any of the 
stories discusses both A and B. This is to satisfy our assumption that
each story corresponds to a unique event. The annotator was also
encouraged to avoid singleton events, events that contain a single
news story, if possible. We realized from our own experience that
people differ in their perception of an event especially when the
number of stories in that event is small. As part of the guidelines,
we instructed the annotator to assign titles to all the events in each
topic. We believe that this would help make her understanding of
the events more concrete. We however, do not use or model these
titles in our algorithms.
In defining dependencies between events, we imposed no 
restrictions on the graph structure. Each event could have single, 
multiple or no parents. Further, the graph could have cycles or 
orphannodes. The annotator was however instructed to assign a 
dependency from event A to event B if and only if the occurrence of B
is ‘either causally influenced by A or is closely related to A and
follows A in time".
From the annotated topics, we created a training set of 26 topics
and a test set of 27 topics by merging the 28 topics from TDT2 and
25 from TDT3 and splitting them randomly. Table 1 shows that the
training and test sets have fairly similar statistics.
Feature Training set Test set
Num. topics 26 27
Avg. Num. Stories/Topic 28.69 26.74
Avg. Doc. Len. 64.60 64.04
Avg. Num. Stories/Event 5.65 6.22
Avg. Num. Events/Topic 5.07 4.29
Avg. Num. Dependencies/Topic 3.07 2.92
Avg. Num. Dependencies/Event 0.61 0.68
Avg. Num. Days/Topic 30.65 34.48
Table 1: Statistics of annotated data
