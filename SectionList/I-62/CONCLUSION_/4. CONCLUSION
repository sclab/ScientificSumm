The experiments have shown that Q-decomposition seems
a very efficient approach when a group of agents have to
allocate resources which are only available to themselves,
but the actions made by an agent may influence the reward
obtained by at least another agent.
On the other hand, when the available resource are
shared, no Q-decomposition is possible and we proposed
tight bounds for heuristic search. In this case, the 
planning time of bounded-rtdp, which prunes the action space,
is significantly lower than for lrtdp. Furthermore, The
marginal revenue bound proposed in this paper compares
favorably to the Singh and Cohn [10] approach. 
boundedrtdp with our proposed bounds may apply to a wide range
of stochastic environments. The only condition for the use
our bounds is that each task possesses consumable and/or
non-consumable limited resources.
An interesting research avenue would be to experiment
our bounds with other heuristic search algorithms. For 
instance, frtdp [11], and brtdp [6] are both efficient 
heuristic search algorithms. In particular, both these approaches
proposed an efficient state trajectory updates, when given
upper and lower bounds. Our tight bounds would enable,
for both frtdp and brtdp, to reduce the number of backup
to perform before convergence. Finally, the bounded-rtdp
function prunes the action space when QU (a, s) â‰¤ L(s), as
Singh and Cohn [10] suggested. frtdp and brtdp could
also prune the action space in these circumstances to 
further reduce their planning time.
