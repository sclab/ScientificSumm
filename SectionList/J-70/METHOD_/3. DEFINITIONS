We now formalize the automated mechanism design 
setting.
Definition 1. In an automated mechanism design 
setting, we are given:
• a finite set of outcomes O;
• a finite set of N agents;
• for each agent i,
1. a finite set of types Θi,
2. a probability distribution γi over Θi (in the case of
correlated types, there is a single joint distribution
γ over Θ1 × . . . × ΘN ), and
3. a utility function ui : Θi × O → R; 1
• An objective function whose expectation the designer
wishes to maximize.
There are many possible objective functions the designer
might have, for example, social welfare (where the designer
seeks to maximize the sum of the agents" utilities), or the
minimum utility of any agent (where the designer seeks to
maximize the worst utility had by any agent). In both
of these cases, the designer is benevolent, because the 
designer, in some sense, is pursuing the agents" collective 
happiness. However, in this paper, we focus on the case of
a self-interested designer. A self-interested designer cares
only about the outcome chosen (that is, the designer does
not care how the outcome relates to the agents" preferences,
but rather has a fixed preference over the outcomes), and
about the net payments made by the agents, which flow to
the designer.
Definition 2. A self-interested designer has an objective
function given by g(o) +
N
i=1
πi, where g : O → R indicates
the designer"s own preference over the outcomes, and πi is
the payment made by agent i. In the case where g = 0
everywhere, the designer is said to be payment maximizing.
In the case where payments are not possible, g constitutes
the objective function by itself.
We now define the kinds of mechanisms under study. By
the revelation principle, we can restrict attention to 
truthful, direct revelation mechanisms, where agents report their
types directly and never have an incentive to misreport them.
Definition 3. We consider the following kinds of 
mechanism:
• A deterministic mechanism without payments consists
of an outcome selection function o : Θ1 × Θ2 × . . . ×
ΘN → O.
• A randomized mechanism without payments consists
of a distribution selection function p : Θ1 × Θ2 × . . . ×
ΘN → P(O), where P(O) is the set of probability 
distributions over O.
• A deterministic mechanism with payments consists of
an outcome selection function o : Θ1 ×Θ2 ×. . .×ΘN →
O and for each agent i, a payment selection function
πi : Θ1 × Θ2 × . . . × ΘN → R, where πi(θ1, . . . , θN )
gives the payment made by agent i when the reported
types are θ1, . . . , θN .
1
Though this follows standard game theory notation [16],
the fact that the agent has both a utility function and a type
is perhaps confusing. The types encode the various possible
preferences that the agent may turn out to have, and the
agent"s type is not known to the aggregator. The utility
function is common knowledge, but because the agent"s type
is a parameter in the agent"s utility function, the aggregator
cannot know what the agent"s utility is without knowing the
agent"s type.
134
• A randomized mechanism with payments consists of
a distribution selection function p : Θ1 × Θ2 × . . . ×
ΘN → P(O), and for each agent i, a payment selection
function πi : Θ1 × Θ2 × . . . × ΘN → R.2
There are two types of constraint on the designer in 
building the mechanism.
3.1 Individual rationality (IR) constraints
The first type of constraint is the following. The utility of
each agent has to be at least as great as the agent"s fallback
utility, that is, the utility that the agent would receive if it
did not participate in the mechanism. Otherwise that agent
would not participate in the mechanism-and no agent"s
participation can ever hurt the mechanism designer"s 
objective because at worst, the mechanism can ignore an agent
by pretending the agent is not there. (Furthermore, if no
such constraint applied, the designer could simply make the
agents pay an infinite amount.) This type of constraint is
called an IR (individual rationality) constraint. There are
three different possible IR constraints: ex ante, ex interim,
and ex post, depending on what the agent knows about its
own type and the others" types when deciding whether to
participate in the mechanism. Ex ante IR means that the
agent would participate if it knew nothing at all (not even
its own type). We will not study this concept in this paper.
Ex interim IR means that the agent would always 
participate if it knew only its own type, but not those of the others.
Ex post IR means that the agent would always participate
even if it knew everybody"s type. We will define the 
latter two notions of IR formally. First, we need to formalize
the concept of the fallback outcome. We assume that each
agent"s fallback utility is zero for each one of its types. This
is without loss of generality because we can add a constant
term to an agent"s utility function (for a given type), 
without affecting the decision-making behavior of that expected
utility maximizing agent [16].
Definition 4. In any automated mechanism design 
setting with an IR constraint, there is a fallback outcome o0 ∈
O where, for any agent i and any type θi ∈ Θi, we have
ui(θi, o0) = 0. (Additionally, in the case of a self-interested
designer, g(o0) = 0.)
We can now to define the notions of individual rationality.
Definition 5. Individual rationality (IR) is defined by:
• A deterministic mechanism is ex interim IR if for any
agent i, and any type θi ∈ Θi, we have
E(θ1,..,θi−1,θi+1,..,θN )|θi
[ui(θi, o(θ1, .., θN ))−πi(θ1, .., θN )]
≥ 0.
A randomized mechanism is ex interim IR if for any
agent i, and any type θi ∈ Θi, we have
E(θ1,..,θi−1,θi+1,..,θN )|θi
Eo|θ1,..,θn [ui(θi, o)−πi(θ1, .., θN )]
≥ 0.
• A deterministic mechanism is ex post IR if for any
agent i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . ×
ΘN , we have ui(θi, o(θ1, . . . , θN )) − πi(θ1, . . . , θN ) ≥
0.
2
We do not randomize over payments because as long as
the agents and the designer are risk neutral with respect to
payments, that is, their utility is linear in payments, there
is no reason to randomize over payments.
A randomized mechanism is ex post IR if for any agent
i, and any type vector (θ1, . . . , θN ) ∈ Θ1 × . . . × ΘN ,
we have Eo|θ1,..,θn [ui(θi, o) − πi(θ1, .., θN )] ≥ 0.
The terms involving payments can be left out in the case
where payments are not possible.
3.2 Incentive compatibility (IC) constraints
The second type of constraint says that the agents should
never have an incentive to misreport their type (as justified
above by the revelation principle). For this type of 
constraint, the two most common variants (or solution concepts)
are implementation in dominant strategies, and 
implementation in Bayes-Nash equilibrium.
Definition 6. Given an automated mechanism design 
setting, a mechanism is said to implement its outcome and
payment functions in dominant strategies if truthtelling is
always optimal even when the types reported by the other
agents are already known. Formally, for any agent i, any
type vector (θ1, . . . , θi, . . . , θN ) ∈ Θ1 × . . . × Θi × . . . × ΘN ,
and any alternative type report ˆθi ∈ Θi, in the case of 
deterministic mechanisms we have
ui(θi, o(θ1, . . . , θi, . . . , θN )) − πi(θ1, . . . , θi, . . . , θN ) ≥
ui(θi, o(θ1, . . . , ˆθi, . . . , θN )) − πi(θ1, . . . , ˆθi, . . . , θN ).
In the case of randomized mechanisms we have
Eo|θ1,..,θi,..,θn [ui(θi, o) − πi(θ1, . . . , θi, . . . , θN )] ≥
Eo|θ1,.., ˆθi,..,θn
[ui(θi, o) − πi(θ1, . . . , ˆθi, . . . , θN )].
The terms involving payments can be left out in the case
where payments are not possible.
Thus, in dominant strategies implementation, truthtelling
is optimal regardless of what the other agents report. If it
is optimal only given that the other agents are truthful, and
given that one does not know the other agents" types, we
have implementation in Bayes-Nash equilibrium.
Definition 7. Given an automated mechanism design 
setting, a mechanism is said to implement its outcome and
payment functions in Bayes-Nash equilibrium if truthtelling
is always optimal to an agent when that agent does not yet
know anything about the other agents" types, and the other
agents are telling the truth. Formally, for any agent i, any
type θi ∈ Θi, and any alternative type report ˆθi ∈ Θi, in the
case of deterministic mechanisms we have
E(θ1,..,θi−1,θi+1,..,θN )|θi
[ui(θi, o(θ1, . . . , θi, . . . , θN ))−
πi(θ1, . . . , θi, . . . , θN )] ≥
E(θ1,..,θi−1,θi+1,..,θN )|θi
[ui(θi, o(θ1, . . . , ˆθi, . . . , θN ))−
πi(θ1, . . . , ˆθi, . . . , θN )].
In the case of randomized mechanisms we have
E(θ1,..,θi−1,θi+1,..,θN )|θi
Eo|θ1,..,θi,..,θn [ui(θi, o)−
πi(θ1, . . . , θi, . . . , θN )] ≥
E(θ1,..,θi−1,θi+1,..,θN )|θi
Eo|θ1,.., ˆθi,..,θn
[ui(θi, o)−
πi(θ1, . . . , ˆθi, . . . , θN )].
The terms involving payments can be left out in the case
where payments are not possible.
135
3.3 Automated mechanism design
We can now define the computational problem we study.
Definition 8. (AUTOMATED-MECHANISM-DESIGN
(AMD)) We are given:
• an automated mechanism design setting,
• an IR notion (ex interim, ex post, or none),
• a solution concept (dominant strategies or Bayes-Nash),
• whether payments are possible,
• whether randomization is possible,
• (in the decision variant of the problem) a target value
G.
We are asked whether there exists a mechanism of the 
specified kind (in terms of payments and randomization) that
satisfies both the IR notion and the solution concept, and
gives an expected value of at least G for the objective.
An interesting special case is the setting where there is
only one agent. In this case, the reporting agent always
knows everything there is to know about the other agents"
types-because there are no other agents. Since ex post and
ex interim IR only differ on what an agent is assumed to
know about other agents" types, the two IR concepts 
coincide here. Also, because implementation in dominant 
strategies and implementation in Bayes-Nash equilibrium only 
differ on what an agent is assumed to know about other agents"
types, the two solution concepts coincide here. This 
observation will prove to be a useful tool in proving hardness
results: if we prove computational hardness in the 
singleagent setting, this immediately implies hardness for both
IR concepts, for both solution concepts, for any number of
agents.