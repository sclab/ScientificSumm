There is a large amount of work in related areas, such as
Private Information Retrieval [7], Privacy-Preserving Data
Mining [2], and other privacy-preserving protocols [4, 16],
most of which is based on Secure Multi-Party Computation
[27]. We have ruled out Secure Multi-Party Computation
approaches mainly because of their complexity, and because
the algorithm that is computed securely is not considered to
be private in these approaches.
Various enforcement mechanisms have been suggested
that are applicable in the context of privacy-preserving 
Information Filtering, such as enterprise privacy policies [17]
or hippocratic databases [1], both of which annotate user
data with additional meta-information specifying how the
data is to be handled on the provider side. These approaches
ultimately assume that the provider actually intends to 
protect the privacy of the user data, and offer support for this
task, but they are not intended to prevent the provider
from acting in a malicious manner. Trusted computing, as
specified by the Trusted Computing Group, aims at 
realizing trusted systems by increasing the security of open 
systems to a level comparable with the level of security that
is achievable in closed systems. It is based on a 
combination of tamper-proof hardware and various software 
components. Some example applications, including peer-to-peer
networks, distributed firewalls, and distributed computing
in general, are listed in [13].
There are some approaches for privacy-preserving 
Recommender Systems based on distributed collaborative filtering,
in which recommendations are generated via a public model
aggregating the distributed user profiles without containing
explicit information about user profiles themselves. This
is achieved via Secure Multi-Party Computation [6], or via
random perturbation of the user data [20]. In [19], 
various approaches are integrated within a single architecture.
In [10], an agent-based approach is described in which user
agents representing similar users are discovered via a 
transitive traversal of user agents. Privacy is preserved through
pseudonymous interaction between the agents and through
adding obfuscating data to personal information. More 
recent related approaches are described in [18].
In [3], an agent-based architecture for privacy-preserving
demographic filtering is described which may be 
generalized in order to support other kinds of filtering techniques.
While in some aspects similar to our approach, this 
architecture addresses at least two aspects inadequately, namely
the protection of the filter against manipulation attempts,
and the prevention of collusions between the filter and the
provider.
