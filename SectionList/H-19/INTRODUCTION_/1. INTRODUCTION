There are more than 4,000 online news sources in the
world. Manually monitoring all of them for important events
has become difficult or practically impossible. In fact, the
topic detection and tracking (TDT) community has for many
years been trying to come up with a practical solution to
help people monitor news effectively. Unfortunately, the
holy grail is still elusive, because the vast majority of TDT
solutions proposed for event detection [20, 5, 17, 4, 21, 7, 14,
10] are either too simplistic (based on cosine similarity [5])
or impractical due to the need to tune a large number of
parameters [9]. The ineffectiveness of current TDT 
technologies can be easily illustrated by subscribing to any of
the many online news alerts services such as the 
industryleading Google News Alerts [2], which generates more than
50% false alarms [10]. As further proof, portals like Yahoo
take a more pragmatic approach by requiring all machine
generated news alerts to go through a human operator for
confirmation before sending them out to subscribers.
Instead of attacking the problem with variations of the
same hammer (cosine similarity and TFIDF), a 
fundamental understanding of the characteristics of news stream data
is necessary before any major breakthroughs can be made in
TDT. Thus in this paper, we look at news stories and 
feature trends from the perspective of analyzing a time-series
word signal. Previous work like [9] has attempted to 
reconstruct an event with its representative features. However,
in many predictive event detection tasks (i.e., retrospective
event detection), there is a vast set of potential features
only for a fixed set of observations (i.e., the obvious bursts).
Of these features, often only a small number are expected
to be useful. In particular, we study the novel problem of
analyzing feature trajectories for event detection, 
borrowing a well-known technique from signal processing: 
identifying distributional correlations among all features by spectral
analysis. To evaluate our method, we subsequently propose
an unsupervised event detection algorithm for news streams.
0
0.2
0.4
0.6
0.8
8/20/1996 12/8/1996 3/28/1997 7/16/1997
Easter
April
(a) aperiodic event
0
0.1
0.2
0.3
0.4
8/20/1996 12/8/1996 3/28/1997 7/16/1997
Unaudited
Ended
(b) periodic event
Figure 1: Feature correlation (DFIDF:time) 
between a) Easter and April b) Unaudited and Ended.
As an illustrative example, consider the correlation 
between the words Easter and April from the Reuters 
Corpus1
. From the plot of their normalized DFIDF in Figure
1(a), we observe the heavy overlap between the two words
circa 04/1997, which means they probably both belong to
the same event during that time (Easter feast). In this 
example, the hidden event Easter feast is a typical important
aperiodic event over 1-year data. Another example is given
by Figure 1(b), where both the words Unaudited and Ended
1
Reuters Corpus is the default dataset for all examples.
exhibit similar behaviour over periods of 3 months. These
two words actually originated from the same periodic event,
net income-loss reports, which are released quarterly by 
publicly listed companies.
Other observations drawn from Figure 1 are: 1) the bursty
period of April is much longer than Easter, which suggests
that April may exist in other events during the same period;
2) Unaudited has a higher average DFIDF value than Ended,
which indicates Unaudited to be more representative for the
underlying event. These two examples are but the tip of
the iceberg among all word trends and correlations hidden
in a news stream like Reuters. If a large number of them
can be uncovered, it could significantly aid TDT tasks. In
particular, it indicates the significance of mining correlating
features for detecting corresponding events. To summarize,
we postulate that: 1) An event is described by its 
representative features. A periodic event has a list of periodic
features and an aperiodic event has a list of aperiodic 
features; 2) Representative features from the same event share
similar distributions over time and are highly correlated; 3)
An important event has a set of active (largely reported)
representative features, whereas an unimportant event has
a set of inactive (less-reported) representative features; 4)
A feature may be included by several events with overlaps
in time frames. Based on these observations, we can 
either mine representative features given an event or detect
an event from a list of highly correlated features. In this 
paper, we focus on the latter, i.e., how correlated features can
be uncovered to form an event in an unsupervised manner.
1.1 Contributions
This paper has three main contributions:
• To the best of our knowledge, our approach is the first
to categorize word features for heterogenous events.
Specifically, every word feature is categorized into one
of the following five feature types based on its power
spectrum strength and periodicity: 1) HH (high power
and high/long periodicity): important aperiodic events,
2) HL (high power and low periodicity): important 
periodic events, 3) LH (low power and high periodicity):
unimportant aperiodic events, 4) LL (low power and
low periodicity): non-events, and 5) SW (stopwords),
a higher power and periodicity subset of LL comprising
stopwords, which contains no information.
• We propose a simple and effective mixture 
densitybased approach to model and detect feature bursts.
• We come up with an unsupervised event detection 
algorithm to detect both aperiodic and periodic events.
Our algorithm has been evaluated on a real news stream
to show its effectiveness.
