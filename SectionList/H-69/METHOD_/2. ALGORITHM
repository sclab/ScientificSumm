2.1 Overview
The difficulty of integrating multiple Web forums is in
their different rating systems, where there are generally two
kinds of freedom. The first kind of freedom is the rating
interval or rating scale including the minimal and maximal
ratings for each Web object. For example, some forums use
a 5-point rating scale whereas other forums use 3-point or
10-point rating scales. It seems easy to fix this freedom, but
detailed analysis of the data and experiments show that it
is a non-trivial problem.
The second kind of freedom is the varying rating criteria
found in different Web forums. That is, the same score does
not mean the same quality in different forums. Intuitively, if
we can detect same photographers or same photographs, we
can build relationships between any two photo forums and
therefore can standardize the rating criterion by score 
normalization and transformation. Fortunately, we find that
quite a number of duplicate photographs exist in various
Web photo forums. This fact is reasonable when 
considering that photographers sometimes submit a photo to more
than one forum to obtain critiques or in hopes of widespread
publicity. In this work, we adopt an efficient duplicate photo
detection algorithm [10] to find these photos.
The proposed methods below are based on the following
considerations. Faced with the need to overcome a ranking
problem, a standardized rating criterion rather than a 
reasonable rating criterion is needed. Therefore, we can take
a large scale forum as the reference forum, and align other
forums by taking into account duplicate Web objects 
(duplicate photos in this work). Ideally, the scores of duplicate
photos should be equal even though they are in different
forums. Yet we can deem that scores in different 
forumsexcept for the reference forum - can vary in a parametric
space. This can be determined by minimizing the objective
function defined by the sum of squares of the score 
differences. By formulating the ranking problem as an 
optimization problem that attempts to make the scores of duplicate
photos in non-reference forums as close as possible to those
in the reference forum, we can effectively solve the ranking
problem.
For convenience, the following notations are employed.
Ski and ¯Ski denote the total score and mean score of ith Web
object (photo) in the kth Web site, respectively. The total
score refers to the sum of the various rating scores (e.g., 
novelty rating and aesthetic rating), and the mean score refers
to the mean of the various rating scores. Suppose there are
a total of K Web sites. We further use
{Skl
i |i = 1, ..., Ikl; k, l = 1, ..., K; k = l}
to denote the set of scores for Web objects (photos) in kth
Web forums that are duplicate with the lth Web forums,
where Ikl is the total number of duplicate Web objects 
between these two Web sites. In general, score fusion can be
seen as the procedure of finding K transforms
ψk(Ski) = eSki, k = 1, ..., K
such that eSki can be used to rank Web objects from different
Web sites. The objective function described in the above
Figure 1: Web community integration. Each Web
community forms a subgraph, and all communities
are linked together by some hidden links (dashed
lines).
paragraph can then be formulated as
min
{ψk|k=2,...,K}
KX
k=2
Ik1X
i=1
¯wk
i

S1k
i − ψk(Sk1
i )
2
(1)
where we use k = 1 as the reference forum and thus ψ1(S1i) =
S1i. ¯wk
i (≥ 0) is the weight coefficient that can be set 
heuristically according to the numbers of voters (reviewers or 
commenters) in both the reference forum and the non-reference
forum. The more reviewers, the more popular the photo is
and the larger the corresponding weight ¯wk
i should be. In
this work, we do not inspect the problem of how to choose ¯wk
i
and simply set them to one. But we believe the proper use
of ¯wk
i , which leverages more information, can significantly
improve the results.
Figure 1 illustrates the aforementioned idea. The Web
Community 1 is the reference community. The dashed lines
are links indicating that the two linked Web objects are 
actually the same. The proposed algorithm will try to find the
best ψk(k = 2, ..., K), which has certain parametric forms
according to certain models. So as to minimize the cost
function defined in Eq. 1, the summation is taken on all the
red dashed lines.
We will first discuss the score normalization methods in
Section 2.2, which serves as the basis for the following work.
Before we describe the proposed ranking algorithms, we first
introduce a manually tuned method in Section 2.3, which is
laborious and even impractical when the number of 
communities become large. In Section 2.4, we will briefly explain
how to precisely find duplicate photos between Web forums.
Then we will describe the two proposed methods: Linear 
fusion and Non-linear fusion, and a performance measure for
result evaluation in Section 2.5. Finally, in Section 2.6 we
will discuss the relationship of the proposed methods with
some other related work.
2.2 Score Normalization
Since different Web (photo) forums on the Web usually
have different rating criteria, it is necessary to normalize
them before applying different kinds of fusion methods. In
addition, as there are many kinds of ratings, such as 
ratings for novelty, ratings for aesthetics etc, it is reasonable
to choose a common one - total score or average 
scorethat can always be extracted in any Web forum or 
calculated by corresponding ratings. This allows the 
normaliza379
tion method on the total score or average score to be viewed
as an impartial rating method between different Web 
forums.
It is straightforward to normalize average scores by 
linearly transforming them to a fixed interval. We call this
kind of score as Scaled Mean Score. The difficulty, however,
of using this normalization method is that, if there are only
a few users rating an object, say a photo in a photo forum,
the average score for the object is likely to be spammed or
skewed.
Total score can avoid such drawbacks that contain more
information such as a Web object"s quality and popularity.
The problem is thus how to normalize total scores in 
different Web forums. The simplest way may be normalization
by the maximal and minimal scores. The drawback of this
normalization method is it is non robust, or in other words,
it is sensitive to outliers.
To make the normalization insensitive to unusual data,
we propose the Mode-90% Percentile normalization method.
Here, the mode score represents the total score that has been
assigned to more photos than any other total score. And The
high percentile score (e.g.,90%) represents the total score for
which the high percentile of images have a lower total score.
This normalization method utilizes the mode and 90% 
percentile as two reference points to align two rating systems,
which makes the distributions of total scores in different 
forums more consistent. The underlying assumption, for 
example in different photo forums, is that even the qualities of
top photos in different forums may vary greatly and be less
dependent on the forum quality, the distribution of photos
of middle-level quality (from mode to 90% percentile) should
be almost of the same quality up to the freedom which 
reflects the rating criterion (strictness) of Web forums. 
Photos of this middle-level in a Web forum usually occupy more
than 70 % of total photos in that forum.
We will give more detailed analysis of the scores in Section
3.2.
2.3 Manual Fusion
The Web movie forum, IMDB [16], proposed to use a
Bayesian-ranking function to normalize rating scores within
one community. Motivated by this ranking function, we 
propose this manual fusion method: For the kth Web site, we
use the following formula
eSki = αk ·
„
nk · ¯Ski
nk + n∗
k
+
n∗
k · S∗
k
nk + n∗
k
«
(2)
to rank photos, where nk is the number of votes and n∗
k,
S∗
k and αk are three parameters. This ranking function first
takes a balance between the original mean score ¯Ski and a
reference score S∗
k to get a weighted mean score which may
be more reliable than ¯Ski. Then the weighted mean score is
scaled by αk to get the final score fSki.
For n Web communities, there are then about 3n 
parameters in {(αk, n∗
k, S∗
k)|k = 1, ..., n} to tune. Though this
method can achieves pretty good results after careful and
thorough manual tuning on these parameters, when n 
becomes increasingly large, say there are tens or hundreds of
Web communities crawled and indexed, this method will 
become more and more laborious and will eventually become
impractical. It is therefore desirable to find an effective 
fusion method whose parameters can be automatically 
determined.
2.4 Duplicate Photo Detection
We use Dedup [10], an efficient and effective duplicate 
image detection algorithm, to find duplicate photos between
any two photo forums. This algorithm uses hash function
to map a high dimensional feature to a 32 bits hash code
(see below for how to construct the hash code). Its 
computational complexity to find all the duplicate images among
n images is about O(n log n). The low-level visual feature
for each photo is extracted on k × k regular grids. Based
on all features extracted from the image database, a PCA
model is built. The visual features are then transformed to
a relatively low-dimensional and zero mean PCA space, or
29 dimensions in our system. Then the hash code for each
photo is built as follows: each dimension is transformed to
one, if the value in this dimension is greater than 0, and 0
otherwise. Photos in the same bucket are deemed potential
duplicates and are further filtered by a threshold in terms
of Euclidean similarity in the visual feature space.
Figure 2 illustrates the hashing procedure, where visual
features - mean gray values - are extracted on both 6 × 6
and 7×7 grids. The 85-dimensional features are transformed
to a 32-dimensional vector, and the hash code is generated
according to the signs.
Figure 2: Hashing procedure for duplicate photo
dectection
2.5 Score Fusion
In this section, we will present two solutions on score 
fusion based on different parametric form assumptions of ψk
in Eq. 1.
2.5.1 Linear Fusion by Duplicate Photos
Intuitively, the most straightforward way to factor out the
uncertainties caused by the different criterion is to scale, 
rel380
ative to a given center, the total scores of each unreferenced
Web photo forum with respect to the reference forum. More
strictly, we assume ψk has the following form
ψk(Ski) = αkSki + tk, k = 2, ..., K (3)
ψ1(S1i) = S1i (4)
which means that the scores of k(= 1)th forum should be
scaled by αk relative to the center tk
1−αk
as shown in Figure
3.
Then, if we substitute above ψk to Eq. 1, we get the
following objective function,
min
{αk,tk|k=2,...,K}
KX
k=2
Ik1X
i=1
¯wk
i
h
S1k
i − αkSk1
i − tk
i2
. (5)
By solving the following set of functions,
(
∂f
∂αk
= = 0
∂f
∂tk
= 0
, k = 1, ..., K
where f is the objective function defined in Eq. 5, we get
the closed form solution as:
„
αk
tk
«
= A−1
k Lk (6)
where
Ak =
„ P
i ¯wi(Sk1
i )2 P
i ¯wiSk1
iP
i ¯wiSk1
i
P
i ¯wi
«
(7)
Lk =
„ P
i ¯wiS1k
i Sk1
iP
i ¯wiS1k
i
«
(8)
and k = 2, ..., K.
This is a linear fusion method. It enjoys simplicity and
excellent performance in the following experiments.
Figure 3: Linear Fusion method
2.5.2 Nonlinear Fusion by Duplicate Photos
Sometimes we want a method which can adjust scores on
intervals with two endpoints unchanged. As illustrated in
Figure 4, the method can tune scores between [C0, C1] while
leaving scores C0 and C1 unchanged. This kind of fusion
method is then much finer than the linear ones and 
contains many more parameters to tune and expect to further
improve the results.
Here, we propose a nonlinear fusion solution to satisfy
such constraints. First, we introduce a transform:
ηc0,c1,α(x) =
( 
x−c0
c1−c0
α
(c1 − c0) + c0, if x ∈ (c0, c1]
x otherwise
where α > 0. This transform satisfies that for x ∈ [c0, c1],
ηc0,c1,α(x) ∈ [c0, c1] with ηc0,c1,α(c0) = c0 and ηc0,c1,α(c1) =
c1. Then we can utilize this nonlinear transform to adjust
the scores in certain interval, say (M, T],
ψk(Ski) = ηM,T,α(Ski) . (9)
Figure 4: Nonlinear Fusion method. We intent to
finely adjust the shape of the curves in each segment.
Even there is no closed-form solution for the following
optimization problem,
min
{αk|k∈[2,K]}
KX
k=2
Ik1X
i=1
¯wk
i
h
S1k
i − ηM,T,α(Ski)
i2
it is not hard to get the numeric one. Under the same 
assumptions made in Section 2.2, we can use this method to
adjust scores of the middle-level (from the mode point to
the 90 % percentile).
This more complicated non-linear fusion method is 
expected to achieve better results than the linear one. 
However, difficulties in evaluating the rank results block us from
tuning these parameters extensively. The current 
experiments in Section 3.5 do not reveal any advantages over the
simple linear model.
2.5.3 Performance Measure of the Fusion Results
Since our objective function is to make the scores of the
same Web objects (e.g. duplicate photos) between a 
nonreference forum and the reference forum as close as possible,
it is natural to investigate how close they become to each
other and how the scores of the same Web objects change
between the two non-reference forums before and after score
fusion.
Taken Figure 1 as an example, the proposed algorithms
minimize the score differences of the same Web objects in
two Web forums: the reference forum (the Web Community
1) and a non-reference forum, which corresponds to 
minimizing the objective function on the red dashed (hidden)
links. After the optimization, we must ask what happens to
the score differences of the same Web objects in two 
nonreference forums? Or, in other words, whether the scores
of two objects linked by the green dashed (hidden) links
become more consistent?
We therefore define the following performance 
measureδ measure - to quantify the changes for scores of the same
Web objects in different Web forums as
δkl = Sim(Slk
, Skl
) − Sim(Slk
∗ , Skl
∗ ) (10)
381
where Skl
= (Skl
1 , ..., Skl
Ikl
)T
, Skl
∗ = (eSkl
1 , ..., eSkl
Ikl
)T
and
Sim(a, b) =
a · b
||a||||b||
.
δkl > 0 means after score fusion, scores on the same Web
objects between kth and lth Web forum become more 
consistent, which is what we expect. On the contrary, if δkl < 0,
those scores become more inconsistent.
Although we cannot rely on this measure to evaluate our
final fusion results as ranking photos by their popularity and
qualities is such a subjective process that every person can
have its own results, it can help us understand the 
intermediate ranking results and provide insights into the final
performances of different ranking methods.
2.6 Contrasts with Other Related Work
We have already mentioned the differences of the proposed
methods with the traditional methods, such as PageRank
[22], PopRank [21], and LinkFusion [27] algorithms in 
Section 1. Here, we discuss some other related works.
The current problem can also be viewed as a rank 
aggregation one [13, 14] as we deal with the problem of how to
combine several rank lists. However, there are 
fundamental differences between them. First of all, unlike the Web
pages, which can be easily and accurately detected as the
same pages, detecting the same photos in different Web 
forums is a non-trivial work, and can only be implemented by
some delicate algorithms while with certain precision and
recall. Second, the numbers of the duplicate photos from
different Web forums are small relative to the whole photo
sets (see Table 1). In another words, the top K rank lists
of different Web forums are almost disjointed for a given
query. Under this condition, both the algorithms proposed
in [13] and their measurements - Kendall tau distance or
Spearman footrule distance - will degenerate to some 
trivial cases.
Another category of rank fusion (aggregation) methods is
based on machine learning algorithms, such as RankSVM
[17, 19], RankBoost [15], and RankNet [12]. All of these
methods entail some labelled datasets to train a model. In
current settings, it is difficult or even impossible to get these
datasets labelled as to their level of professionalism or 
popularity, since the photos are too vague and subjective to rank.
Instead, the problem here is how to combine several ordered
sub lists to form a total order list.
