DATABASE RECOMMENDATION
All four testbeds described in Section 4 were used in the
experiments to evaluate the resource selection effectiveness of
the database recommendation system.
The resource descriptions were created using query-based
sampling. About 80 queries were sent to each database to
download 300 unique documents. The database size statistics
were estimated by the sample-resample method [21]. Fifty
queries (101-150) were used as training queries to build the
relevant logistic model and to fit the exponential functions of the
centralized document score curves for large ratio databases
(details in Section 3.1). Another 50 queries (51-100) were used
as test data.
Resource selection algorithms of database recommendation
systems are typically compared using the recall metric nR
[1,17,18,21]. Let B denote a baseline ranking, which is often the
RBR (relevance based ranking), and E as a ranking provided by
a resource selection algorithm. And let Bi and Ei denote the
number of relevant documents in the ith
ranked database of B or
E. Then Rn is defined as follows:
=
=
= k
i i
k
i i
k
B
E
R
1
1
(17)
Usually the goal is to search only a few databases, so our figures
only show results for selecting up to 20 databases.
The experiments summarized in Figure 3 compared the
effectiveness of the three resource selection algorithms, namely
the CORI, ReDDE and UUM/HR. The UUM/HR algorithm is
described in Section 3.3. It can be seen from Figure 3 that the
ReDDE and UUM/HR algorithms are more effective (on the
representative, relevant and nonrelevant testbeds) or as good as
(on the Trec123-100Col testbed) the CORI resource selection
algorithm. The UUM/HR algorithm is more effective than the
ReDDE algorithm on the representative and relevant testbeds
and is about the same as the ReDDE algorithm on the 
Trec123100Col and the nonrelevant testbeds. This suggests that the
UUM/HR algorithm is more robust than the ReDDE algorithm.
It can be noted that when selecting only a few databases on the
Trec123-100Col or the nonrelevant testbeds, the ReDEE
algorithm has a small advantage over the UUM/HR algorithm.
We attribute this to two causes: i) The ReDDE algorithm was
tuned on the Trec123-100Col testbed; and ii) Although the
difference is small, this may suggest that our logistic model of
estimating probabilities of relevance is not accurate enough.
More training data or a more sophisticated model may help to
solve this minor puzzle.
Collections Selected. Collections Selected.
Trec123-100Col Testbed. Representative Testbed.
Collection Selected. Collection Selected.
Relevant Testbed. Nonrelevant Testbed.
Figure 3. Resource selection experiments on the four testbeds.
38
