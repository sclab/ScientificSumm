Functions that transform extensive form games have been
introduced [50, 11]. In contrast to our work, those 
approaches were not for making the game smaller and easier
to solve. The main result is that a game can be derived
from another by a sequence of those transformations if and
only if the games have the same pure reduced normal form.
The pure reduced normal form is the extensive form game
represented as a game in normal form where duplicates of
pure strategies (i.e., ones with identical payoffs) are removed
and players essentially select equivalence classes of 
strategies [27]. An extension to that work shows a similar result,
but for slightly different transformations and mixed reduced
normal form games [21]. Modern treatments of this prior
work on game transformations exist [38, Ch. 6], [10].
The recent notion of weak isomorphism in extensive form
games [7] is related to our notion of restricted game 
isomorphism. The motivation of that work was to justify solution
concepts by arguing that they are invariant with respect
to isomorphic transformations. Indeed, the author shows,
among other things, that many solution concepts, including
Nash, perfect, subgame perfect, and sequential equilibrium,
are invariant with respect to weak isomorphisms. However,
that definition requires that the games to be tested for weak
isomorphism are of the same size. Our focus is totally 
different: we find strategically equivalent smaller games. Also,
their paper does not provide algorithms.
Abstraction techniques have been used in artificial 
intelligence research before. In contrast to our work, most (but
not all) research involving abstraction has been for 
singleagent problems (e.g. [20, 32]). Furthermore, the use of
abstraction typically leads to sub-optimal solutions, unlike
the techniques presented in this paper, which yield 
optimal solutions. A notable exception is the use of abstraction
to compute optimal strategies for the game of Sprouts [2].
However, a significant difference to our work is that Sprouts
is a game of perfect information.
One of the first pieces of research to use abstraction in
multi-agent settings was the development of partition search,
which is the algorithm behind GIB, the world"s first 
expertlevel computer bridge player [17, 18]. In contrast to other
game tree search algorithms which store a particular game
position at each node of the search tree, partition search
stores groups of positions that are similar. (Typically, the
similarity of two game positions is computed by ignoring the
less important components of each game position and then
checking whether the abstracted positions are similar-in
some domain-specific expert-defined sense-to each other.)
Partition search can lead to substantial speed improvements
over α-β-search. However, it is not game theory-based (it
does not consider information sets in the game tree), and
thus does not solve for the equilibrium of a game of 
imperfect information, such as poker.8
Another difference is that
the abstraction is defined by an expert human while our
abstractions are determined automatically.
There has been some research on the use of abstraction
for imperfect information games. Most notably, Billings et
al [4] describe a manually constructed abstraction for Texas
Hold"em poker, and include promising results against expert
players. However, this approach has significant drawbacks.
First, it is highly specialized for Texas Hold"em. Second,
a large amount of expert knowledge and effort was used in
constructing the abstraction. Third, the abstraction does
not preserve equilibrium: even if applied to a smaller game,
it might not yield a game-theoretic equilibrium. Promising
ideas for abstraction in the context of general extensive form
games have been described in an extended abstract [39], but
to our knowledge, have not been fully developed.