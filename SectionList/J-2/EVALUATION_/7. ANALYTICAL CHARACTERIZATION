OF THE WORST-CASE OPTIMAL
MECHANISM
We recall that our linear program has the following form:
Variables: cm+1, cm+2, . . . , cn−1, k
Maximize k (the percentage redistributed in the
worst case)
Subject to:Pj
i=m+1 ci ≥ 0 for j = m + 1, . . . , n − 1
km ≤ (n − m − 1)cm+1 ≤ m
km ≤ n
Pj=m+i−1
j=m+1 cj + (n − m − i)cm+i ≤ m for
i = 2, . . . , n − m − 1
km ≤ n
Pj=n−1
j=m+1 cj ≤ m
A linear program has no solution if and only if either the
objective is unbounded, or the constraints are contradictory
(there is no feasible solution). It is easy to see that k is
bounded above by 1 (redistributing more than 100% 
violates the non-deficit constraint). Also, a feasible solution
always exists, for example, k = 0 and ci = 0 for all i. So an
optimal solution always exists. Observe that the linear 
program model depends only on the number of agents n and the
number of units m. Hence the optimal solution is a function
of n and m. It turns out that this optimal solution can be
analytically characterized as follows.
Theorem 1. For any m and n with n ≥ m+2, the 
worstcase optimal mechanism (among linear VCG redistribution
mechanisms) is unique. For this mechanism, the percentage
redistributed in the worst case is
k∗
= 1 −
`n−1
m
´
Pn−1
j=m
`n−1
j
´
The worst-case optimal mechanism is characterized by the
following values for the ci:
c∗
i =
(−1)i+m−1
(n − m)
`n−1
m−1
´
i
Pn−1
j=m
`n−1
j
´
1
`n−1
i
´
n−1X
j=i
n − 1
j
!
for i = m + 1, . . . , n − 1.
It should be noted that we have proved ci = 0 for i ≤ m in
Claim 1.
Proof. We first rewrite the linear program as follows.
We introduce new variables xm+1, xm+2, . . . , xn−1, defined
by xj =
Pj
i=m+1 ci for j = m + 1, . . . , n − 1. The linear
program then becomes:
Variables: xm+1, xm+2, . . . , xn−1, k
Maximize k
Subject to:
km ≤ (n − m − 1)xm+1 ≤ m
km ≤ (m + i)xm+i−1 + (n − m − i)xm+i ≤ m for
i = 2, . . . , n − m − 1
km ≤ nxn−1 ≤ m
xi ≥ 0 for i = m + 1, m + 2, . . . , n − 1
We will prove that for any optimal solution to this linear
program, k = k∗
. Moreover, we will prove that when k = k∗
,
xj =
Pj
i=m+1 c∗
i for j = m + 1, . . . , n − 1. This will prove
the theorem.
We first make the following observations:
(n − m − 1)c∗
m+1
= (n − m − 1)
(n−m)(n−1
m−1)
(m+1)
Pn−1
j=m (n−1
j )
1
(n−1
m+1)
Pn−1
j=m+1
`n−1
j
´
= (n − m − 1)
(n−m)(n−1
m−1)
(m+1)
Pn−1
j=m (n−1
j )
1
(n−1
m+1)
(
Pn−1
j=m
`n−1
j
´
−
`n−1
m
´
)
= (n − m − 1) m
n−m−1
− (n − m − 1)
m(n−1
m )
(n−m−1)
Pn−1
j=m (n−1
j )
= m − (1 − k∗
)m = k∗
m
For i = m + 1, . . . , n − 2,
ic∗
i + (n − i − 1)c∗
i+1
= i
(−1)i+m−1
(n−m)(n−1
m−1)
i
Pn−1
j=m (n−1
j )
1
(n−1
i )
Pn−1
j=i
`n−1
j
´
+
(n − i − 1)
(−1)i+m
(n−m)(n−1
m−1)
(i+1)
Pn−1
j=m (n−1
j )
1
(n−1
i+1 )
Pn−1
j=i+1
`n−1
j
´
=
(−1)i+m−1
(n−m)(n−1
m−1)
Pn−1
j=m (n−1
j )
1
(n−1
i )
Pn−1
j=i
`n−1
j
´
−
(n − i − 1)
(−1)i+m−1
(n−m)(n−1
m−1)
(i+1)
Pn−1
j=m (n−1
j )
i+1
(n−1
i )(n−i−1)
Pn−1
j=i+1
`n−1
j
´
=
(−1)i+m−1
(n−m)(n−1
m−1)
Pn−1
j=m (n−1
j )
= (−1)i+m−1
m(1 − k∗
)
Finally,
(n − 1)c∗
n−1
= (n − 1)
(−1)n+m
(n−m)(n−1
m−1)
(n−1)
Pn−1
j=m (n−1
j )
1
(n−1
n−1)
Pn−1
j=n−1
`n−1
j
´
= (−1)m+n
m(1 − k∗
)
Summarizing the above, we have:
(n − m − 1)c∗
m+1 = k∗
m
(m + 1)c∗
m+1 + (n − m − 2)c∗
m+2 = m(1 − k∗
)
(m + 2)c∗
m+2 + (n − m − 3)c∗
m+3 = −m(1 − k∗
)
(m + 3)c∗
m+3 + (n − m − 4)c∗
m+4 = m(1 − k∗
)
...
35
(n − 3)c∗
n−3 + 2c∗
n−2 = (−1)m+n−2
m(1 − k∗
)
(n − 2)c∗
n−2 + c∗
n−1 = (−1)m+n−1
m(1 − k∗
)
(n − 1)c∗
n−1 = (−1)m+n
m(1 − k∗
)
Let x∗
j =
Pj
i=m+1 c∗
i for j = m + 1, m + 2, . . . , n − 1, the
first equation in the above tells us that
(n − m − 1)x∗
m+1 = k∗
m.
By adding the first two equations, we get
(m + 2)x∗
m+1 + (n − m − 2)x∗
m+2 = m
By adding the first three equations, we get
(m + 3)x∗
m+2 + (n − m − 3)x∗
m+3 = k∗
m
By adding the first i equations, where i = 2, . . . , n−m−1,
we get
(m + i)x∗
m+i−1 + (n − m − i)x∗
m+i = m if i is even
(m + i)x∗
m+i−1 + (n − m − i)x∗
m+i = k∗
m if i is odd
Finally by adding all the equations, we get
nx∗
n−1 = m if n − m is even;
nx∗
n−1 = k∗
m if n − m is odd.
Thus, for all of the constraints other than the 
nonnegativity constraints, we have shown that they are satisfied by
setting xj = x∗
j =
Pj
i=m+1 c∗
i and k = k∗
. We next show
that the nonnegativity constraints are satisfied by these 
settings as well.
For m + 1 ≤ i, i + 1 ≤ n − 1, we have
1
i
Pn−1
j=i (n−1
j )
(n−1
i )
= 1
i
Pn−1
j=i
i!(n−1−i)!
j!(n−1−j)!
≥ 1
i+1
Pn−2
j=i
i!(n−1−i)!
j!(n−1−j)!
≥
1
i+1
Pn−2
j=i
(i+1)!(n−1−i−1)!
(j+1)!(n−1−j−1)!
= 1
i+1
Pn−1
j=i+1 (n−1
j )
(n−1
i+1 )
This implies that the absolute value of c∗
i is decreasing
as i increases (if the c∗
contains more than one number).
We further observe that the sign of c∗
i alternates, with the
first element c∗
m+1 positive. So x∗
j =
Pj
i=m+1 c∗
i ≥ 0 for
all j. Thus, we have shown that these xi = x∗
i together
with k = k∗
form a feasible solution of the linear program.
We proceed to show that it is in fact the unique optimal
solution.
First we prove the following claim:
Claim 4. If ˆk, ˆxi, i = m + 1, m + 2, . . . , n − 1 satisfy the
following inequalities:
ˆkm ≤ (n − m − 1)ˆxm+1 ≤ m
ˆkm ≤ (m + i)ˆxm+i−1 + (n − m − i)ˆxm+i ≤ m for
i = 2, . . . , n − m − 1
ˆkm ≤ nˆxn−1 ≤ m
ˆk ≥ k∗
Then we must have that ˆxi = ˆx∗
i and ˆk = k∗
.
Proof of claim. Consider the first inequality. We know
that (n − m − 1)x∗
m+1 = k∗
m, so (n − m − 1)ˆxm+1 ≥ ˆkm ≥
k∗
m = (n − m − 1)x∗
m+1. It follows that ˆxm+1 ≥ x∗
m+1
(n − m − 1 = 0).
Now, consider the next inequality for i = 2. We know
that (m + 2)x∗
m+1 + (n − m − 2)x∗
m+2 = m. It follows that
(n−m−2)ˆxm+2 ≤ m−(m+2)ˆxm+1 ≤ m−(m+2)x∗
m+1 =
(n − m − 2)x∗
m+2, so ˆxm+2 ≤ x∗
m+2 (i = 2 ≤ n − m − 1 ⇒
n − m − 2 = 0).
Now consider the next inequality for i = 3. We know
that (m + 3)x∗
m+2 + (n − m − 3)x∗
m+3 = m. It follows that
(n−m−3)ˆxm+3 ≥ ˆkm−(m+3)ˆxm+2 ≥ k∗
m−(m+3)x∗
m+2 =
(n − m − 3)x∗
m+3, so ˆxm+3 ≥ x∗
m+3 (i = 3 ≤ n − m − 1 ⇒
n − m − 3 = 0).
Proceeding like this all the way up to i = n−m−1, we get
that ˆxm+i ≥ x∗
m+i if i is odd and ˆxm+i ≤ x∗
m+i if i is even.
Moreover, if one inequality is strict, then all subsequent 
inequalities are strict. Now, if we can prove ˆxn−1 = x∗
n−1,
it would follow that the x∗
i are equal to the ˆxi (which also
implies that ˆk = k∗
). We consider two cases:
Case 1: n − m is even. We have: n − m even ⇒ n − m − 1
odd ⇒ ˆxn−1 ≥ x∗
n−1. We also have: n−m even ⇒ nx∗
n−1 =
m. Combining these two, we get m = nx∗
n−1 ≤ nˆxn−1 ≤
m ⇒ ˆxn−1 = x∗
n−1.
Case 2: n − m is odd. In this case, we have ˆxn−1 ≤ x∗
n−1,
and nx∗
n−1 = k∗
m. Then, we have: k∗
m ≤ ˆkm ≤ nˆxn−1 ≤
nx∗
n−1 = k∗
m ⇒ ˆxn−1 = x∗
n−1.
This completes the proof of the claim.
It follows that if ˆk, ˆxi, i = m + 1, m + 2, . . . , n − 1 is a
feasible solution and ˆk ≥ k∗
, then since all the inequalities
in Claim 4 are satisfied, we must have ˆxi = x∗
i and ˆk =
k∗
. Hence no other feasible solution is as good as the one
described in the theorem.
Knowing the analytical characterization of the worst-case
optimal mechanism provides us with at least two major 
benefits. First, using these formulas is computationally more
efficient than solving the linear program using a 
generalpurpose solver. Second, we can derive the following 
corollary.
Corollary 1. If the number of units m is fixed, then as
the number of agents n increases, the worst-case percentage
redistributed linearly converges to 1, with a rate of 
convergence 1
2
. (That is, limn→∞
1−k∗
n+1
1−k∗
n
= 1
2
. That is, in the
limit, the percentage that is not redistributed halves for 
every additional agent.)
We note that this is consistent with the experimental data
for the single-unit case, where the worst-case remaining 
percentage roughly halves each time we add another agent.
The worst-case percentage that is redistributed under the
Bailey-Cavallo mechanism also converges to 1 as the 
number of agents goes to infinity, but the convergence is much
slower-it does not converge linearly (that is, letting kC
n be
the percentage redistributed by the Bailey-Cavallo 
mechanism in the worst case for n agents, limn→∞
1−kC
n+1
1−kC
n
=
limn→∞
n
n+1
= 1). We now present the proof of the 
corollary.
Proof. When the number of agents is n, the worst-case
percentage redistributed is k∗
n = 1 −
(n−1
m )
Pn−1
j=m (n−1
j )
. When the
number of agents is n + 1, the percentage becomes k∗
n+1 =
1 −
(n
m)
Pn
j=m (n
j )
. For n sufficiently large, we will have 2n
−
mnm−1
> 0, and hence
1−k∗
n+1
1−k∗
n
=
(n
m)
Pn−1
j=m (n−1
j )
(n−1
m )
Pn
j=m (n
j )
=
n
n−m
2n−1
−
Pm−1
j=0 (n−1
j )
2n−
Pm−1
j=0 (n
j )
, and n
n−m
2n−1
−m(n−1)m−1
2n ≤
1−k∗
n+1
1−k∗
n
≤ n
n−m
2n−1
2n−mnm−1 (because
`n
j
´
≤ ni
if j ≤ i).
Since we have
limn→∞
n
n−m
2n−1
−m(n−1)m−1
2n = 1
2
, and
limn→∞
n
n−m
2n−1
2n−mnm−1 = 1
2
,
it follows that limn→∞
1−k∗
n+1
1−k∗
n
= 1
2
.
36
