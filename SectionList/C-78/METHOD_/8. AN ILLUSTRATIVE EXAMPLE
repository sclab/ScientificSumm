A simple example for many important properties of the
proposed system showing the coordination through the 
environment and events disseminated over the network is the
demo of two cooperating robots depicted in Figure 5.
Each robot is equipped with smart distance sensors, speed
sensors, acceleration sensors and one of the robots (the guide
(KURT2) in front (Figure 5)) has a tracking camera 
allowing to follow a white line. The robots form a WAN-of-CANs
system in which their local CANs are interconnected via a
wireless 802.11 network. COSMIC provides the event layer
for seamless interaction. The blind robot (N.N.) is 
searching the guide randomly. Whenever the blind robot detects
(by its front distance sensors) an obstacle, it checks whether
this may be the guide. For this purpose, it dynamically 
subscribes to the event channel disseminating distance events
from rear distance sensors of the guide(s) and compares
these with the distance events from its local front sensors.
If the distance is approximately the same it infers that it
is really behind a guide. Now N.N. also subscribes to the
event channels of the tracking camera and the speed sensors
37
Figure 5: Cooperating robots.
to follow the guide. The demo application highlights the
following properties of the system:
1. Dynamic interaction of robots which is not known in
advance. In principle, any two a priori unknown robots
can cooperate. All what publishers and subscribers
have to know to dynamically interact in this 
environment is the subject of the respective event class. A
problem will be to receive only the events of the robot
which is closest. A robot identity does not help much
to solve this problem. Rather, the position of the event
generation entity which is captured in the respective
attributes can be evaluated to filter the relevant event
out of the event stream. A suitable wireless protocol
which uses proximity to filter events has been proposed
by Meier and Cahill [22] in the CORTEX project.
2. Interaction through the environment. The 
cooperation between the robots is controlled by sensing the
distance between the robots. If the guide detects that
the distance grows, it slows down. Respectively, if the
blind robot comes too close it reduces its speed. The
local distance sensors produce events which are 
disseminated through a low latency, highly predictable event
channel. The respective reaction time can be 
calculated as function of the speed and the distance of the
robots and define a dynamic dissemination deadline
for events. Thus, the interaction through the 
environment will secure the safety properties of the 
application, i.e. the follower may not crash into the guide and
the guide may not loose the follower. Additionally, the
robots have remote subscriptions to the respective 
distance events which are used to check it with the local
sensor readings to validate that they really follow the
guide which they detect with their local sensors. 
Because there may be longer latencies and omissions, this
check occasionally will not be possible. The 
unavailability of the remote events will decrease the quality
of interaction and probably and slow down the robots,
but will not affect safety properties.
3. Cooperative sensing. The blind robot subscribes to the
events of the line tracking camera. Thus it can see
through the eye of the guide. Because it knows the 
distance to the guide and the speed as well, it can foresee
the necessary movements. The proposed system 
provides the architectural framework for such a 
cooperation. The respective sentient object controlling the
actuation of the robot receives as input the position
and orientation of the white line to be tracked. In the
case of the guide robot, this information is directly 
delivered as a body event with a low latency and a high
reliability over the internal network. For the follower
robot, the information comes also via an event channel
but with different quality attributes. These quality 
attributes are reflected in the event channel description.
The sentient object controlling the actuation of the
follower is aware of the increased latency and higher
probability of omission.
