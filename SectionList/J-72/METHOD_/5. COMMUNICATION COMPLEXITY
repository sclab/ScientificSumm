In this section, we turn to the issue of the 
communication complexity of elicitation. Nisan and Segal [12] show
that for a variety of rich valuation spaces (such as general
and submodular valuations), the worst-case communication
burden of determining Lindahl prices is exponential in the
number of goods, m. The communication burden is 
measured in terms of the number of bits transmitted between
agents and auctioneer in the case of discrete communication,
or in terms of the number of real numbers transmitted in the
case of continuous communication.
Converting efficient learning algorithms to an elicitation
algorithm produces an algorithm whose queries have sizes
polynomial in the parameters m and size(v1, . . . , vn).
Theorem 2. The representation classes V1, . . . , Vn can
be efficiently elicited from value and demand queries if they
can each be efficiently exactly learned from membership and
equivalence queries.
Proof. The size of any value query is O(m): the 
message consists solely of the queried bundle. To communicate
Lindahl prices to agent i, it is sufficient to communicate
the agent"s manifest valuation function and the value πi, by
equality (4). Note that an efficient learning algorithm never
builds up a manifest hypothesis of superpolynomial size, 
because the algorithm"s runtime would then also be 
superpolynomial, contradicting efficiency. Thus communicating the
manifest valuation requires size at most p(size(vi), m), for
some polynomial p that upper-bounds the runtime of the
efficient learning algorithm. Representing the surplus πi to
agent i cannot require space greater than q(size(˜vi), m) for
some fixed polynomial q, because we assume that the chosen
representation is polynomially interpretable, and thus any
value generated will be of polynomial size. We must also
communicate to i its allocated bundle, so the total 
message size for a demand query is at most p(size(vi), m) +
q(p(size(vi), m), m)+O(m). Clearly, an agent"s response to
a value or demand query has size at most q(size(vi), m) +
O(m). Thus the value and demand queries, and the 
responses to these queries, are always of polynomial size. An
efficient learning algorithm performs a polynomial number of
queries, so the total communication of the resulting 
elicitation algorithm is polynomial in the relevant parameters.
There will often be explicit bounds on the number of 
membership and equivalence queries performed by a learning 
algorithm, with constants that are not masked by big-O 
notation. These bounds can be translated to explicit bounds
on the number of value and demand queries made by the
resulting elicitation algorithm. We upper-bounded the size
of the manifest hypothesis with the runtime of the learning
algorithm in Theorem 2. We are likely to be able to do
much better than this in practice. Recall that an 
equivalence query is proper if size( ˜f) ≤ size(f) at the time the
query is made. If the learning algorithm"s equivalence 
queries are all proper, it may then also be possible to provide
tight bounds on the communication requirements of the 
resulting elicitation algorithm.
Theorem 2 show that elicitation algorithms that depend
on the size(v1, . . . , vn) parameter sidestep Nisan and 
Segal"s [12] negative results on the worst-case communication
complexity of efficient allocation problems. They provide
guarantees with respect to the sizes of the instances of 
valuation functions faced at any run of the algorithm. These
algorithms will fare well if the chosen representation class
provides succinct representations for the simplest and most
common of valuations, and thus the focus moves back to one
of compact yet expressive bidding languages. We consider
these issues below.
