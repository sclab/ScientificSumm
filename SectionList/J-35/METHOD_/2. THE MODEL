To begin, we formalize providing service in a P2P network
as a non-cooperative game. Unlike much of the modeling in
this area, our model will model the asymmetric interactions
in a file sharing system in which the matching of players
(those requesting a file with those who have that particular
file) is a key part of the system. This is in contrast with
much previous work which uses random matching in a 
prisoner"s dilemma. Such models were studied in the economics
literature [18, 7] and first applied to online reputations in
[11]; an application to P2P is found in [9].
This random-matching model fails to capture some salient
aspects of a number of important settings. When a request
is made, there are typically many people in the network who
can potentially satisfy it (especially in a large P2P network),
but not all can. For example, some people may not have
the time or resources to satisfy the request. The 
randommatching process ignores the fact that some people may not
be able to satisfy the request. Presumably, if the person
matched with the requester could not satisfy the match, he
would have to defect. Moreover, it does not capture the fact
that the decision as to whether to volunteer to satisfy
the request should be made before the matching process,
not after. That is, the matching process does not capture
1
Although we refer to our unit of scrip as the dollar, these
are not real dollars nor do we view them as convertible to
dollars.
141
the fact that if someone is unwilling to satisfy the request,
there will doubtless be others who can satisfy it. Finally, the
actions and payoffs in the prisoner"s dilemma game do not
obviously correspond to actual choices that can be made.
For example, it is not clear what defection on the part of
the requester means. In our model we try to deal with all
these issues.
Suppose that there are n agents. At each round, an agent
is picked uniformly at random to make a request. Each other
agent is able to satisfy this request with probability β > 0 at
all times, independent of previous behavior. The term β is
intended to capture the probability that an agent is busy, or
does not have the resources to fulfill the request. Assuming
that β is time-independent does not capture the intution
that being an unable to fulfill a request at time t may well
be correlated with being unable to fulfill it at time t+1. We
believe that, in large systems, we should be able to drop the
independence assumption, but we leave this for future work.
In any case, those agents that are able to satisfy the request
must choose whether or not to volunteer to satisfy it. If
at least one agent volunteers, the requester gets a benefit
of 1 util (the job is done) and one of volunteers is chosen
at random to fulfill the request. The agent that fulfills the
request pays a cost of α < 1. As is standard in the literature,
we assume that agents discount future payoffs by a factor of
δ per time unit. This captures the intuition that a util now is
worth more than a util tomorrow, and allows us to compute
the total utility derived by an agent in an infinite game.
Lastly, we assume that with more players requests come
more often. Thus we assume that the time between rounds
is 1/n. This captures the fact that the systems we want
to model are really processing many requests in parallel, so
we would expect the number of concurrent requests to be
proportional to the number of users.2
Let G(n, δ, α, β) denote this game with n agents, a 
discount factor of δ, a cost to satisfy requests of α, and a 
probability of being able to satisfy requests of β. When the
latter two parameters are not relevant, we sometimes write
G(n, δ).
We use the following notation throughout the paper:
• pt
denotes the agent chosen in round t.
• Bt
i ∈ {0, 1} denotes whether agent i can satisfy the
request in round t. Bt
i = 1 with probability β > 0 and
Bt
i is independent of Bt
i for all t = t.
• V t
i ∈ {0, 1} denotes agent i"s decision about whether
to volunteer in round t; 1 indicates volunteering. V t
i
is determined by agent i"s strategy.
• vt
∈ {j | V t
j Bt
j = 1} denotes the agent chosen to satisfy
the request. This agent is chosen uniformly at random
from those who are willing (V t
j = 1) and able (Bt
j = 1)
to satisfy the request.
• ut
i denotes agent i"s utility in round t.
A standard agent is one whose utility is determined as
discussed in the introduction; namely, the agent gets
2
For large n, our model converges to one in which players
make requests in real time, and the time between a player"s
requests are exponentially distributed with mean 1. In 
addition, the time between requests served by a single player
is also exponentially distributed.
a utility of 1 for a fulfilled request and utility −α for
fulfilling a request. Thus, if i is a standard agent, then
ut
i =
8
<
:
1 if i = pt and
P
j=i V t
j Bt
j > 0
−α if i = vt
0 otherwise.
• Ui =
P∞
t=0 δt/n
ut
i denotes the total utility for agent
i. It is the discounted total of agent i"s utility in each
round. Note that the effective discount factor is δ1/n
since an increase in n leads to a shortening of the time
between rounds.
Now that we have a model of making and satisfying 
requests, we use it to analyze free riding. Take an altruist to
be someone who always fulfills requests. Agent i might 
rationally behave altruistically if agent i"s utility function has
the following form, for some α > 0:
ut
i =
8
<
:
1 if i = pt and
P
j=i V t
j Bt
j > 0
α if i = vt
0 otherwise.
Thus, rather than suffering a loss of utility when satisfying
a request, an agent derives positive utility from satisfying
it. Such a utility function is a reasonable representation of
the pleasure that some people get from the sense that they
provide the music that everyone is playing. For such 
altruistic agents, playing the strategy that sets V t
i = 1 for all t
is dominant. While having a nonstandard utility function
might be one reason that a rational agent might use this
strategy, there are certainly others. For example a naive
user of filesharing software with a good connection might
well follow this strategy. All that matters for the 
following discussion is that there are some agents that use this
strategy, for whatever reason.
As we have observed, such users seem to exist in some
large systems. Suppose that our system has a altruists. 
Intuitively, if a is moderately large, they will manage to satisfy
most of the requests in the system even if other agents do
no work. Thus, there is little incentive for any other agent
to volunteer, because he is already getting full advantage of
participating in the system. Based on this intuition, it is a
relatively straightforward calculation to determine a value
of a that depends only on α, β, and δ, but not the number
n of players in the system, such that the dominant strategy
for all standard agents i is to never volunteer to satisfy any
requests (i.e., V t
i = 0 for all t).
Proposition 2.1. There exists an a that depends only on
α, β, and δ such that, in G(n, δ, α, β) with at least a altruists,
not volunteering in every round is a dominant strategy for
all standard agents.
Proof. Consider the strategy for a standard player j in
the presence of a altruists. Even with no money, player
j will get a request satisfied with probability 1 − (1 − β)a
just through the actions of these altruists. Thus, even if j is
chosen to make a request in every round, the most additional
expected utility he can hope to gain by having money isP∞
k=1(1 − β)a
δk
= (1 − β)a
/(1 − δ). If (1 − β)a
/(1 − δ) > α
or, equivalently, if a > log1−β(α(1 − δ)), never volunteering
is a dominant strategy.
Consider the following reasonable values for our 
parameters: β = .01 (so that each player can satisfy 1% of the 
requests), α = .1 (a low but non-negligible cost), δ = .9999/day
142
(which corresponds to a yearly discount factor of 
approximately 0.95), and an average of 1 request per day per player.
Then we only need a > 1145. While this is a large number,
it is small relative to the size of a large P2P network.
Current systems all have a pool of users behaving like our
altruists. This means that attempts to add a reputation
system on top of an existing P2P system to influence users
to cooperate will have no effect on rational users. To have
a fair distribution of work, these systems must be 
fundamentally redesigned to eliminate the pool of altruistic users.
In some sense, this is not a problem at all. In a system
with altruists, the altruists are presumably happy, as are
the standard agents, who get almost all their requests 
satisfied without having to do any work. Indeed, current P2P
network work quite well in terms of distributing content to
people. However, as we said in the introduction, there is
some reason to believe these altruists may not be around
forever. Thus, it is worth looking at what can be done to
make these systems work in their absence. For the rest of
this paper we assume that all agents are standard, and try
to maximize expected utility.
We are interested in equilibria based on a scrip system.
Each time an agent has a request satisfied he must pay the
person who satisfied it some amount. For now, we assume
that the payment is fixed; for simplicity, we take the amount
to be $1. We denote by M the total amount of money in
the system. We assume that M > 0 (otherwise no one will
ever be able to get paid).
In principle, agents are free to adopt a very wide 
variety of strategies. They can make decisions based on the
names of other agents or use a strategy that is heavily 
history dependant, and mix these strategies freely. To aid our
analysis, we would like to be able to restrict our attention to
a simpler class of strategies. The class of strategies we are
interested in is easy to motivate. The intuitive reason for
wanting to earn money is to cater for the possibility that an
agent will run out before he has a chance to earn more. On
the other hand, a rational agent with plenty of mone would
not want to work, because by the time he has managed to
spend all his money, the util will have less value than the
present cost of working. The natural balance between these
two is a threshold strategy. Let Sk be the strategy where
an agent volunteers whenever he has less than k dollars and
not otherwise. Note that S0 is the strategy where the agent
never volunteers. While everyone playing S0 is a Nash 
equilibrium (nobody can do better by volunteering if no one else
is willing to), it is an uninteresting one. As we will show
in Section 4, it is sufficient to restrict our attention to this
class of strategies.
We use Kt
i to denote the amount of money agent i has
at time t. Clearly Kt+1
i = Kt
i unless agent i has a request
satisfied, in which case Kt+1
i = Kt+1
i − 1 or agent i fulfills a
request, in which case Kt+1
i = Kt+1
i + 1. Formally,
Kt+1
i =
8
<
:
Kt
i − 1 if i = pt
,
P
j=i V t
j Bt
j > 0, and Kt
i > 0
Kt
i + 1 if i = vt
and Kt
pt > 0
Kt
i otherwise.
The threshold strategy Sk is the strategy such that
V t
i =

1 if Kt
pt > 0 and Kt
i < k
0 otherwise.
