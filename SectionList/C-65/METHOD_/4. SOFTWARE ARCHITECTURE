The sensor application relies on three subsystems 
exploiting three different computing paradigms as they are shown
in Figure 4. Although each of these execution models suit
their domain specific tasks extremely well, this diversity
(a) (b)
Figure 3: Sensor prototypes mounted on a kevlar
helmet (a) and in a plastic box on a tripod (b).
presents a challenge for software development and system
integration. The sensor fusion and user interface 
subsystem is running on PDAs and were implemented in Java.
The sensing and signal processing tasks are executed by an
FPGA, which also acts as a bridge between various wired
and wireless communication channels. The ad-hoc internode
communication, time synchronization and data sharing are
the responsibilities of a microcontroller based radio module.
Similarly, the application employs a wide variety of 
communication protocols such as Bluetooth and IEEE 802.14.5
wireless links, as well as optional UARTs, I2
C and/or USB
buses.
Soldier
Operated Device
(PDA/Laptop)
FPGA
Sensor Board
Mica Radio
Module
2.4 GHz Wireless Link
Radio Control
Message Routing
Acoustic Event Encoder
Sensor Time Synch.
Network Time Synch.Remote Control
Time
stamping
Interrupts
Virtual
Register
Interface
C
O
O
R
D
I
N
A
T
O
R
A
n
a
l
o
g
c
h
a
n
n
e
l
s Compass
PicoBlaze
Comm.
Interface
PicoBlaze
WT12 Bluetooth Radio
MOTE IF:I2C,Interrupts
USB PSRAM
U
A
R
T
U
A
R
T
MB
det
SW
det
REC
Bluetooth Link
User
Interface
Sensor
Fusion
Location
Engine GPS
Message (Dis-)AssemblerSensor
Control
Figure 4: Software architecture diagram.
The sensor fusion module receives and unpacks raw 
measurements (time stamps and feature vectors) from the 
sensorboard through the Bluetooth link. Also, it fine tunes
the execution of the signal processing cores by setting 
parameters through the same link. Note that measurements
from other nodes along with their location and orientation
information also arrive from the sensorboard which acts as
a gateway between the PDA and the sensor network. The
handheld device obtains its own GPS location data and 
di115
rectly receives orientation information through the 
sensorboard. The results of the sensor fusion are displayed on the
PDA screen with low latency. Since, the application is 
implemented in pure Java, it is portable across different PDA
platforms.
The border between software and hardware is 
considerably blurred on the sensor board. The IP 
cores-implemented in hardware description languages (HDL) on the 
reconfigurable FPGA fabric-closely resemble hardware 
building blocks. However, some of them-most notably the soft
processor cores-execute true software programs. The 
primary tasks of the sensor board software are 1) acquiring
data samples from the analog channels, 2) processing 
acoustic data (detection), and 3) providing access to the results
and run-time parameters through different interfaces.
As it is shown in Figure 4, a centralized virtual register
file contains the address decoding logic, the registers for
storing parameter values and results and the point to point
data buses to and from the peripherals. Thus, it effectively
integrates the building blocks within the sensorboard and
decouples the various communication interfaces. This 
architecture enabled us to deploy the same set of sensors in a
centralized scenario, where the ad-hoc mote network (using
the I2
C interface) collected and forwarded the results to a
base station or to build a decentralized system where the
local PDAs execute the sensor fusion on the data obtained
through the Bluetooth interface (and optionally from other
sensors through the mote interface). The same set of 
registers are also accessible through a UART link with a terminal
emulation program. Also, because the low-level interfaces
are hidden by the register file, one can easily add/replace
these with new ones (eg.: the first generation of motes 
supported a standard μP interface bus on the sensor connector,
which was dropped in later designs).
The most important results are the time stamps of the
detected events. These time stamps and all other timing
information (parameters, acoustic event features) are based
on a 1 MHz clock and an internal timer on the FPGA. The
time conversion and synchronization between the sensor 
network and the board is done by the mote by periodically 
requesting the capture of the current timer value through a
dedicated GPIO line and reading the captured value from
the register file through the I2
C interface. Based on the the
current and previous readings and the corresponding mote
local time stamps, the mote can calculate and maintain the
scaling factor and offset between the two time domains.
The mote interface is implemented by the I2
C slave IP
core and a thin adaptation layer which provides a data and
address bus abstraction on top of it. The maximum 
effective bandwidth is 100 Kbps through this interface. The
FPGA contains several UART cores as well: for 
communicating with the on-board Bluetooth module, for 
controlling the digital compass and for providing a wired RS232
link through a dedicated connector. The control, status and
data registers of the UART modules are available through
the register file. The higher level protocols on these lines are
implemented by Xilinx PicoBlaze microcontroller cores [13]
and corresponding software programs. One of them provides
a command line interface for test and debug purposes, while
the other is responsible for parsing compass readings. By
default, they are connected to the RS232 port and to the
on-board digital compass line respectively, however, they
can be rewired to any communication interface by changing
the register file base address in the programs (e.g. the 
command line interface can be provided through the Bluetooth
channel).
Two of the external interfaces are not accessible through
the register file: a high speed USB link and the SRAM 
interface are tied to the recorder block. The USB module 
implements a simple FIFO with parallel data lines connected to an
external FT245R USB device controller. The RAM driver
implements data read/write cycles with correct timing and
is connected to the on-board pseudo SRAM. These 
interfaces provide 1 MB/s effective bandwidth for downloading
recorded audio samples, for example.
The data acquisition and signal processing paths exhibit
clear symmetry: the same set of IP cores are instantiated
four times (i.e. the number of acoustic channels) and run
independently. The signal paths meet only just before
the register file. Each of the analog channels is driven by
a serial A/D core for providing a 20 MHz serial clock and
shifting in 8-bit data samples at 1 MS/s and a digital 
potentiometer driver for setting the required gain. Each channel
has its own shockwave and muzzle blast detector, which are
described in Section 5. The detectors fetch run-time 
parameter values from the register file and store their results there
as well. The coordinator core constantly monitors the 
detection results and generates a mote interrupt promptly upon
full detection or after a reasonable timeout after partial
detection.
The recorder component is not used in the final 
deployment, however, it is essential for development purposes for
refining parameter values for new types of weapons or for
other acoustic sources. This component receives the 
samples from all channels and stores them in circular buffers in
the PSRAM device. If the signal amplitude on one of the
channels crosses a predefined threshold, the recorder 
component suspends the sample collection with a predefined delay
and dumps the contents of the buffers through the USB link.
The length of these buffers and delays, the sampling rate,
the threshold level and the set of recorded channels can be
(re)configured run-time through the register file. Note that
the core operates independently from the other signal 
processing modules, therefore, it can be used to validate the
detection results off-line.
The FPGA cores are implemented in VHDL, the PicoBlaze
programs are written in assembly. The complete 
configuration occupies 40% of the resources (slices) of the FPGA and
the maximum clock speed is 30 MHz, which is safely higher
than the speed used with the actual device (20MHz).
The MICAz motes are responsible for distributing 
measurement data across the network, which drastically 
improves the localization and classification results at each node.
Besides a robust radio (MAC) layer, the motes require two
essential middleware services to achieve this goal. The 
messages need to be propagated in the ad-hoc multihop network
using a routing service. We successfully integrated the 
Directed Flood-Routing Framework (DFRF) [9] in our 
application. Apart from automatic message aggregation and 
efficient buffer management, the most unique feature of DFRF
is its plug-in architecture, which accepts custom routing
policies. Routing policies are state machines that govern
how received messages are stored, resent or discarded. 
Example policies include spanning tree routing, broadcast, 
geographic routing, etc. Different policies can be used for 
different messages concurrently, and the application is able to
116
change the underlying policies at run-time (eg.: because of
the changing RF environment or power budget). In fact, we
switched several times between a simple but lavish broadcast
policy and a more efficient gradient routing on the field.
Correlating ToA measurements requires a common time
base and precise time synchronization in the sensor network.
The Routing Integrated Time Synchronization (RITS) [15]
protocol relies on very accurate MAC-layer time-stamping
to embed the cumulative delay that a data message accrued
since the time of the detection in the message itself. That
is, at every node it measures the time the message spent
there and adds this to the number in the time delay slot of
the message, right before it leaves the current node. Every
receiving node can subtract the delay from its current time
to obtain the detection time in its local time reference. The
service provides very accurate time conversion (few μs per
hop error), which is more than adequate for this application.
Note, that the motes also need to convert the sensorboard
time stamps to mote time as it is described earlier.
The mote application is implemented in nesC [5] and is
running on top of TinyOS [6]. With its 3 KB RAM and
28 KB program space (ROM) requirement, it easily fits on
the MICAz motes.
