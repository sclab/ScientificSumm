AN EDGE FORMULATION
In this section, we consider a formulation of the clearing
problem as an ILP with one variable for each edge. This
encoding is based on the following classical algorithm for
solving the directed cycle cover problem with no cycle-length
constraints.
Given a market G = (V, E), construct a bipartite graph
with one vertex for each agent, and one vertex for each item.
Add an edge ev with weight 0 between each agent v and its
own item. At this point, the encoding is a perfect matching.
Now, for each edge e = (vi, vj) in the original market, add
an edge e with weight we between agent vi and the item of
vj. Perfect matchings in this encoding correspond exactly
with cycle covers, since whenever an agent"s item is taken,
it must receive some other agent"s item. It follows that the
unrestricted clearing problem can be solved in polynomial
time by finding a maximum-weight perfect matching. 
Figure 3 contains the bipartite graph encoding of the example
market from Figure 1. The weight-0 edges are encoded by
dashed lines, while the market edges are in bold.
Items
Agents
v1 v2 v3 v4 v5
e1 e3 e8
e2
v1 v2 v3 v4 v5
e7e6
e5
e4
Figure 3: Perfect matching encoding of the market
in Figure 1.
Alternatively, we can solve the problem by encoding it
as an ILP with one variable for each edge in the original
market graph G. This ILP, given below, has the advantage
that it can be extended naturally to deal with cycle length
constraints. Therefore, for the rest of this section, this is
the approach we will pursue.
max
e∈E
wee
such that for all vi ∈ V , the conservation constraint
eout=(vi,vj )
eout −
ein=(vj ,vi)
ein = 0
and capacity constraint
eout=(vi,vj )
eout ≤ 1
are satisfied.
If cycles are allowed to have length at most L, it is easy
to see that we only need to make the following changes
to the ILP. For each length-L path (throughout the 
paper, we do not include cycles in the definition of path)
p = ep1 , ep2 , . . . , epL , add a constraint
ep1 + ep2 + . . . + epL ≤ L − 1,
which precludes path p from being in any feasible solution.
Unfortunately, in a market with only 1000 patients, the
number of length-3 paths is in excess of 400 million, and so
we cannot even construct this ILP without running out of
memory.
Therefore, we use a tree search with an incremental 
formulation approach. Specifically, we use CPLEX, though
298
we add constraints as cutting planes during the tree search
process. We begin with only a small subset of the constraints
in the ILP. Since this ILP is small, CPLEX can solve its LP
relaxation. We then check whether any of the missing 
constraints are violated by the fractional solution. If so, we
generate a set of these constraints, add them to the ILP,
and repeat. Even once all constraints are satisfied, there
may be no integral solution matching the fractional upper
bound, and even if there were, the LP solver might not find
it.
In these cases, CPLEX branches on a variable (we used
CPLEX"s default branching strategy), and generates one
new search node corresponding to each of the children. At
each node of the search tree that is visited, this process of
solving the LP and adding constraints is repeated. Clearly,
this approach yields an optimal solution once the tree search
finishes.
We still need to explain the details of the constraint seeder
(i.e., selecting which constraints to begin with) and the 
constraint generation (i.e., selecting which violated constraints
to include). We describe these briefly in the next two 
subsections, respectively.
4.1 Constraint Seeder
The main constraint seeder we developed forbids any path
of length L − 1 that does not have an edge closing the cycle
from its head to its tail. While it is computationally 
expensive to find these constraints, their addition focuses the
search away from paths that cannot be in the final solution.
We also tried seeding the LP with a random collection of
constraints from the ILP.
4.2 Constraint Generation
We experimented with several constraint generators. In
each, given a fractional solution, we construct the subgraph
of edges with positive value. This graph is much smaller
than the original graph, so we can perform the following
computations efficiently.
In our first constraint generator, we simply search for
length-L paths with value sum more than L − 1. For any
such path, we restrict its sum to be at most L − 1. Note
that if there is a cycle c with length |c| > L, it could contain
as many as |c| violating paths.
In our second constraint generator, we only add one 
constraint for such cycles: the sum of edges in the cycle can be
at most |c|(L − 1)/L .
This generator made the algorithm slower, so we went
in the other direction in developing our final generator. It
adds one constraint per violating path p, and furthermore,
it adds a constraint for each path with the same interior
vertices (not counting the endpoints) as p. This improved
the overall speed.
4.3 Experimental performance
It turned out that even with these improvements, the edge
formulation approach cannot clear a kidney exchange with
100 vertices in the time the cycle formulation (described
later in Section 5) can clear one with 10,000 vertices. In
other words, column generation based approaches turned
out to be drastically better than constraint generation based
approaches. Therefore, in the rest of the paper, we will focus
on the cycle formulation and the column generation based
approaches.
