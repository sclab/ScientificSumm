Definition 5 (k-levels Hierarchical Hypercube): Let there are N
nodes totally, then a k-levels Hierarchical Hypercube named
H(k,u,m,v,n) can be constructed as follows:
1) The N nodes are divided into k clusters averagely, and
the [N/k] nodes in any cluster are connected into an n-dimensional
Hypercube: In the n-dimensional Hypercube, any node is encoded
55
as i1i2…in, which are called In-Cluster-Hypercube-Node-Codes,
where 0 ≤ i1,i2,…in ≤ v-1,v=[ n
kN / ],[j] equals to an integer not
less than j. So we can obtain k such kind of different hypercubes.
2) The k different hypercubes obtained above are encoded
as j1j2…jm, which are called Out-Cluster-Hypercube-Node-Codes,
where 0 ≤ j1,j2,…jm ≤ u-1,u=[ m
k ]. And the nodes in the k
different hypercubes are connected into m-dimensional
hypercubes according to the following rules: The nodes with same
In-Cluster-Hypercube-Node-Codes and different 
Out-ClusterHypercube-Node-Codes are connected into an m-dimensional
hypercube.
(The graph constructed through above steps is called a k-levels
Hierarchical Hypercube abbreviated as H(k,u,m,v,n).)
3) Any node A in H(k,u,m,v,n) can be encoded as (i, j),
where i(i=i1i2…in, 0 ≤ i1,i2,…in ≤ v-1) is the 
In-Cluster-HypercubeNode-Code of node A, and j(j=j1j2…jm, 0 ≤ j1,j2,…jm ≤ u-1) is the
Out-Cluster-Hypercube-Node-Code of node A.
Obviously, the H(k,u,m,v,n) model has the following good
properties:
Property 1: The diameter of H(k,u,m,v,n) model is m+n.
Proof: Since the diameter of n-dimensional hypercube is n,
and the diameter of m-dimensional hypercube is m, so it is easy to
know that the diameter of H(k,u,m,v,n) model is m+n from the
definition 5.
Property 2: The distance between any two nodes A(i1, j1) and B(i2,
j2) in H(k,u,m,v,n) model is d(A,B)= dh(i1, i2)+dh(j1, j2), where dh
represents the Hamming distance.
Proof: Since the distance between any two nodes in
hypercube equals to the Hamming distance between them, so it is
obvious that the theorem 2"s conclusion stands from definition 5.
