Papka et al. proposed Single-Pass clustering on NED [6]. When a
new story was encountered, it was processed immediately to
extract term features and a query representation of the story"s
content is built up. Then it was compared with all the previous
queries. If the document did not trigger any queries by exceeding
a threshold, it was marked as a new event. Lam et al build up
previous query representations of story clusters, each of which
corresponds to a topic [7]. In this manner comparisons happen
between stories and clusters.
Recent years, most work focus on proposing better methods on
comparison of stories and document representation. Brants et al.
[8] extended a basic incremental TF-IDF model to include 
sourcespecific models, similarity score normalization based on
document-specific averages, similarity score normalization based
on source-pair specific averages, term reweighting based on
inverse event frequencies, and segmentation of documents. Good
improvements on TDT bench-marks were shown. Stokes et al. [9]
utilized a combination of evidence from two distinct
representations of a document"s content. One of the
representations was the usual free text vector, the other made use
of lexical chains (created using WordNet) to build another term
vector. Then the two representations are combined in a linear
fashion. A marginal increase in effectiveness was achieved when
the combined representation was used.
Some efforts have been done on how to utilize named entities to
improve NED. Yang et al. gave location named entities four times
weight than other terms and named entities [10]. DOREMI
research group combined semantic similarities of person names,
location names and time together with textual similarity [11][12].
UMass [13] research group split document representation into two
parts: named entities and non-named entities. And it was found
that some classes of news could achieve better performance using
named entity representation, while some other classes of news
could achieve better performance using non-named entity
representation. Both [10] and [13] used text categorization
technique to classify news stories in advance. In [13] news stories
are classified automatically at first, and then test sensitivities of
names and non-name terms for NED for each class. In [10]
frequent terms for each class are removed from document
representation. For example, word election does not help
identify different elections. In their work, effectiveness of
different kinds of names (or terms with different POS) for NED in
different news classes are not investigated. We use statistical
analysis to reveal the fact and use it to improve NED performance.