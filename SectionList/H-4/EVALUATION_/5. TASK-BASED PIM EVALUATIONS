The findings described in section 4 are useful with 
respect to evaluation because they provide experimenters with
enough knowledge to conduct controlled user evaluations in
lab conditions. Greco-Latin square experimental designs can
be constructed where participants are assigned n tasks of the
three types described above to perform on their own 
collections using x systems. This would allow the performance of
the systems or the behaviour of the participants using 
different systems to be analysed with respect to the type of task
being performed (look-up, item, or multi-item). In the 
following sections we evaluate the feasibility of this approach
when employing different methods of task creation.
5.1 Using Real Tasks
One method of creating realistic re-finding tasks without
compromising the privacy of participants is to use real tasks.
Diary-studies, similar to that described above, would allow
experimenters to capture a pool of tasks for participants
to complete by searching on their own collections. This
is extremely advantageous because it would allow 
experimenters to evaluate the behaviour of real users, 
completing real search tasks on real collections while in a 
controlled environment. There is also the additional benefit
that the task descriptions would not make any assumptions
about what the user would remember in a real life 
situation because they would only include the information that
had been recorded i.e. the information that was available
when the user originally performed the task. Nevertheless,
to gain these benefits we must, firstly, confirm that the task
descriptions recorded are of sufficient quality to enable the
task to be re-performed at a later date. Secondly, we must
ensure that a diary-study would provide experimenters with
enough tasks to construct a balanced experimental design
that would satisfy their data needs.
To examine the quality of recorded tasks, 6 weeks after
the diary study had completed, we asked 6 of our 
participants, selected randomly from the pool of those who
recorded enough tasks, to re-perform 5 of their own tasks.
The tasks were selected randomly from the pool of those
available. The issued tasks consisted of 10 email and 20
web tasks, 9 of which were lookup tasks, 12 were item tasks,
and 8 were multi-item tasks. The issued tasks represented a
broad-sampling of the complete set of recorded tasks. They
also included tasks with vague descriptions e.g.
• LU5:Find a software key for an application I required to 
reinstall.
• LU6:Trying to find a quote to use in a paper. Cannot 
remember the person or the exact quote
The usefulness of such tasks would rely on the memories of
participants i.e. would the recorder of task LU5 remember
which application he referred to and would the recorder of
LU6 remember enough about the context in which the task
took place to re-perform the task?
Presented with the tasks exactly as they recorded them,
the participants were asked to re-perform each task with any
system of their choice. Of the 30 tasks issued, 26 (86.67%)
were completed without problems, 2 (6.67%) of the tasks
were not completed because the description recorded was
insufficent to recreate the task, and 2 tasks (6.67%) were
not completed because the task was too difficult or the 
required web page no longer existed. Experimenters are likely
to be interested in the final group of tasks because it is 
important to discover what makes a task difficult and how user
behaviour changes in these circumstances. Therefore, from
the 30 tasks tested, only 2 tasks were not of sufficient 
quality to be used in an evaluation situation. Further, there did
not seem to be any issue of the type, temperature or 
difficulty ratings affecting the quality of the task descriptions.
These findings suggest that the participants who recorded
most tasks in the diary study also recorded tasks with 
sufficient quality. However, did the diary study generate enough
tasks to satisfy the needs of experimenters?
Participant Tasks Lookup Item Multi-item Unclass.
10 26 16 8 2 0
43 9 4 5 0 0
26 9 5 4 0 0
8 9 8 1 0 0
40 8 5 3 0 0
18 7 3 4 0 0
4 6 5 1 0 0
7 6 5 0 1 0
12 5 4 0 0 1
22 5 4 1 0 0
36 5 0 5 0 0
46 5 2 2 0 1
3 5 3 2 0 0
Table 3: The quantities of recorded email tasks
Participant Tasks Lookup Item Multi-item Unclass.
26 32 7 20 5 0
32 31 11 18 2 0
10 19 0 10 7 2
33 18 5 13 0 0
5 15 0 7 2 4
8 11 0 6 5 0
22 10 0 3 5 2
28 10 1 7 2 0
37 10 1 9 0 0
35 9 7 2 0 0
6 9 0 1 8 0
40 7 1 5 1 0
9 7 0 0 5 2
12 7 1 0 3 2
42 6 0 4 2 0
29 6 0 3 3 0
15 5 0 2 1 2
4 5 0 4 1 0
43 5 2 3 0 0
18 5 0 0 3 2
Table 4: The quantities of recorded web tasks
Naturally the exact number of tasks required to perform
a user evaluation will depend on the goals of the evaluation,
the number of users and the number of systems to be tested
etc. However, for illustrative purposes we chose 5 tasks as
a cut-off point for our data. From tables 3 and 4, which
show the quantities of email and web tasks recorded for each
participant, we can see that of the 36 participants, only
13 (36.1%) recorded 5 or more email tasks and 20 (55.6%)
recorded 5 or more web tasks. This means that many of the
recruited participants could not actually participate in the
final evaluation. This is a major limitation of using recorded
tasks in evaluations because participant recruitment for user
tests is challenging and it may not be possible to recruit
enough participants if experimenters lose between half and
two-thirds of their populations.
Further, there was some imbalance in the numbers of
recorded tasks of different types. Some participants recorded
several lookup tasks but very few item tasks and others
recorded several item tasks but few lookup tasks. There
was also a specific lack of multi-item email tasks. This 
situation makes it very difficult for experimenters to prepare
balanced experimental designs. Therefore, even though our
first test suggests that the quality of recorded tasks was 
sufficient for the participants to re-perform the tasks at a later
stage, the number of tasks recorded was probably too low
to make this a viable option for experimental task creation.
However, it may be possible to increase the number of tasks
recorded by frequently reminding participants or by making
personal visits etc.
5.2 Using Simulated Tasks Based on Real Tasks
Another benefit of diary-studies is that they provide 
information about the contents and uses of private 
collections without invading participants" privacy. This section
explores the possibility of using a combination of the 
knowledge gained from diary studies and other attributes known
about participants to artificially create re-finding tasks 
corresponding to the taxonomy defined in section 4.1. We 
explain the techniques used and demonstrate the feasibility of
creating simulated tasks within the context of a user 
evaluation investigating email re-finding behaviour. Space 
limitations prevent us from reporting our findings; instead we
concentrate on the methods of task creation.
As preparation for the evaluation, we performed a 
second diary-study, where 34 new participants, consisting of
16 post-graduate students and 18 under-graduate students,
recorded 150 email tasks over a period of approximately 3
weeks. The collected data revealed several patterns that
helped with the creation of artificial tasks. For example,
students in both groups recorded tasks relating to classes
that they were taking at the time and often different 
participants recorded tasks that involved searching for the same
information. This was useful because it provided us with a
clue that even though some of the participants did not record
a particular task, it was possible that the task may still be
applicable to their collections. Other patterns revealed 
included that students within the same group often searched
for emails containing announcements from the same source.
For example, several undergraduate students recorded tasks
that included re-finding information relating to job 
vacancies. There were also tasks that were recorded by 
participants in both groups. For example, searching for an email
that would re-confirm the pin code required to access the
computer labs.
To supplement our knowledge of the participants" email
collections, we asked 2 participants from each group to 
provide email tours. These consisted of short 5-10 minute 
sessions, where participants were asked to explain why they
use email, who sends them email, and their organisational
strategies. This approach has been used successfully in the
past as a non-intrusive means to learn about how people
store and maintain their personal information [17]. 
Originally, we had planned to ask more participants to provide
tours, but we found 2 tours per group was sufficient for
our needs. Again, patterns emerged that helped with task
creation. We found content overlap within and between
groups that confirmed many of our observations from the
diary study data. For example, the students who gave tours
revealed that they received emails from lecturers for 
particular class assignments, receipts for completed assignments,
and various announcements from systems support and about
job vacancies. Importantly, the participants were also able
to confirm which other students had received the same 
information. This confirmed that many of tasks recorded during
the diary study were applicable, not only to the recorder,
but to every participant in 1 or both groups.
Based on this initial investigatory work, a set of 15 tasks
(5 of each type in our taxonomy) was created for each group
of participants. We also created a set of tasks for a third
group of participants that consisted of research and 
academic staff members, based on our knowledge of the emails
our colleagues receive. Where possible we used the 
information recorded in the diary study descriptions to provide
a context for the task i.e. a work task or motivation that
would require the task to be performed. When the diary
study data did not provide sufficient context information to
supply the participants with a robust description of the 
information need, we created simulated work task situations
according to the guidelines of [2]. A further advantage of
using simulated tasks in this way, rather than real-tasks,
is that some of the users will not have performed the task
in the recent past and this allows the examination of tasks
that look for information of different temperatures. If only
real-tasks had been used all of the participants would have
performed the tasks during the period of the diary study.
The created tasks were used in a final evaluation, where
we examined the email re-finding behaviour of users with
three different email systems. 21 users (7 in each group)
performed 9 tasks each (1 task of each type on each system)
using their own personal collections in a Greco-Latin square
experimental design. Performing a PIM evaluation in this
way allowed the examination of re-finding behaviour in a
way not possible before - we were able to observe the email
re-finding strategies employed by real users, performing 
realistic tasks, on their own collections in a controlled 
environment. The study revealed that the participants 
remembered different attributes of emails, demostrated different
finding behaviour, and exhibited different levels of 
performance when asked to complete tasks of the different types
in the taxonomy. The key to both the task creation and the
analysis of the results was our taxonomy, which provided the
template to create tasks and also a means to compare the
behaviour and performance of different users (and systems)
performing different tasks of the same type. Some of the
findings of the evaluation will be published in [10].
Summarising the approach, to conduct a user experiment
using our methodology, researchers would be required to
perform the following steps: 1)Conduct a diary study as
above 1
. 2)Analyse the recorded tasks looking for overlap
between the participants. 3)Supplement the gained 
knowledge about the contents of participants" collections by asking
a selection of the participants to provide a tour of their 
collection. 4)Use the knowledge gained to devise tasks of the
three different types defined within the taxonomy. More 
de1
Information about this and the diary forms required can be
found at http://www.cis.strath.ac.uk/˜dce/PIMevaluations
tailed information on how to use the research described in
this paper to perform task-based PIM evaluations can be
found at our website (see footnote 1).
