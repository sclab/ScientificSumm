Since the simple bag-of-words representation at the document-level leads to a learned model that behaves somewhat like a context-specific prior dependent on the sender/receiver and general topic, a first choice would be to treat it as such when combining probability estimates with the sentence-level classifier.
Such methods include alternate ways of combining the predictions over each  sentence, weightings other than tfidf, which may not be appropriate since sentences are small, better sentence segmentation, and other types of phrasal analysis.
Such a model might serve as a general example for other problems where bag-of-words can establish a baseline model but richer 