We restrict in this paper to the discussion of Poisson,  however, our results show that indeed a smoother distribution than Poisson promises to be a good candidate for improving the estimation of probabilities in information retrieval.
The probability of being  informative defined in our paper can be viewed as the probability of the disjoint terms in the term space of [12].
[9] shows experimentally that most of the terms (words) in a collection are distributed according to a low dimension n-Poisson model.
Entropy is maximal if all events are equiprobable and the frequency-based Lotka law ( N/iÎ» is the number 