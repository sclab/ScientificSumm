Evaluations of IR systems employing QE performed only on the entire collection do not take into account that the purpose of QE is to mitigate the effects of term mismatch in retrieval.
Further, this evaluation framework is not  metricspecific: information in terms of any metric (MAP, P@10, etc.)
The proposed evaluation framework allows us to measure the degree to which different IR systems overcome (or don"t overcome) term mismatch between queries and relevant  documents.
Most importantly, it provides a controlled manner in which to measure the performance of QE with respect to query-document term mismatch.
By systematically 