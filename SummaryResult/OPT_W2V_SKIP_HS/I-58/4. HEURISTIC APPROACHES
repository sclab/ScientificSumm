(4) Problem (4) maximizes the leader"s reward with the follower"s best response (qj for fixed leader"s policy x and hence denoted q(x)j) by selecting a uniform policy from a multiset of constant size k. We complete this problem by including the characterization of q(x) through linear programming optimality conditions.
(3) From strong duality and complementary slackness we obtain that the follower"s maximum reward value, a, is the value of every pure strategy with qj > 0, that is in the support of the optimal mixed strategy.
( 2 ) The 