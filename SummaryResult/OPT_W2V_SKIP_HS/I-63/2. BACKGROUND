In this case, the number of ψ values is exponential in each agent"s planning horizon Tm, resulting in a much larger program.
2.1 Markov Decision Processes A stationary , finite-domain , discrete-time MDP ( see , for example , [ 13 ] for a thorough and detailed development ) can be described as S , A , p , r , where : S is a finite set of system states ; A is a finite set of actions that are available to the agent ; p is a stationary stochastic transition function , where p ( σ|s 