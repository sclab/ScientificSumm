Our evaluation is based on two data sets: a large web graph and a substantial set of queries with associated results, some of which were labeled by human judges.
Since content-match features are very unreliable (and even more so link features, as we will see) we need to ask a human to evaluate the results in order to compare the quality of features.
It is important to point out that our 2.9 billion URL web graph does not cover all these result URLs.
Results were selected for judgment based on their commercial search engine placement ; in other words , 