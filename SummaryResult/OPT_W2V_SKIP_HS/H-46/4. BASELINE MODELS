(7) Here, p(d) denotes the prior distribution over the set U, which  reflects the relevance of the document to the topic.
Lavrenko and Croft [14] suggest a reasonable way of obtaining such an approximation, by assuming that p(t|θk) can be approximated by the probability of term t given the query q.
( 5 ) The probability of a query given a document is estimated by inferring a document language model θd for each document d in a similar manner as the candidate model was inferred : p ( t|θd ) = ( 1 − λ ) p ( 