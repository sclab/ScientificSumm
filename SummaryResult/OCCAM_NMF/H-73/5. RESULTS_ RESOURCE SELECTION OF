figure 3. resource selection experiments on the four testbeds.
nonrelevant testbed.
relevant testbed.
collection selected.
representative testbed.
trec123-100col testbed.
collections selected.
more training data or a more sophisticated model may help to solve this minor puzzle.
we attribute this to two causes: i) the redde algorithm was tuned on the trec123-100col testbed; and ii) although the difference is small, this may suggest that our logistic model of estimating probabilities of relevance is not accurate enough.
it can be noted that when selecting only a few databases on the trec123-100col or the nonrelevant testbeds, the redee algorithm has a small advantage over the uum/hr algorithm.
this suggests that the uum/hr algorithm is more robust than the redde algorithm.
the uum/hr algorithm is more effective than the redde algorithm on the representative and relevant testbeds and is about the same as the redde algorithm on the  trec123100col and the nonrelevant testbeds.
the uum/hr algorithm is described in section 3.3. it can be seen from figure 3 that the redde and uum/hr algorithms are more effective (on the representative, relevant and nonrelevant testbeds) or as good as (on the trec123-100col testbed) the cori resource selection algorithm.
the experiments summarized in figure 3 compared the effectiveness of the three resource selection algorithms, namely the cori, redde and uum/hr.
and let bi and ei denote the number of relevant documents in the ith ranked database of b or e. then rn is defined as follows: = = = k i i k i i k b e r 1 1 (17) usually the goal is to search only a few databases, so our figures only show results for selecting up to 20 databases.
let b denote a baseline ranking, which is often the rbr (relevance based ranking), and e as a ranking provided by a resource selection algorithm.
resource selection algorithms of database recommendation systems are typically compared using the recall metric nr [1,17,18,21].
another 50 queries (51-100) were used as test data.
fifty queries (101-150) were used as training queries to build the relevant logistic model and to fit the exponential functions of the centralized document score curves for large ratio databases (details in section 3.1).
the database size statistics were estimated by the sample-resample method [21].
about 80 queries were sent to each database to download 300 unique documents.
the resource descriptions were created using query-based sampling.
database recommendation all four testbeds described in section 4 were used in the experiments to evaluate the resource selection effectiveness of the database recommendation system.
