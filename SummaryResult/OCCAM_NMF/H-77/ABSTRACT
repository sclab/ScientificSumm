categories and subject descriptors h.3.3 [information storage and retrieval]: information search and retrieval - search process; h.4.1 [information systems applications]: office automation - word processing; d.2.8 [software engineering]: metrics - complexity measures, performance measures general terms algorithms, experimentation, performance. 
moreover, we can significantly improve search ranking results in document retrieval by using the extracted titles.
other important new findings in this work include that we can train models in one domain and apply them to another domain, and more surprisingly we can even train models in one language and apply them to another language.
precision and recall for title extraction from word is 0.810 and 0.837 respectively, and precision and recall for title extraction from powerpoint is 0.875 and 0.895 respectively in an experiment on intranet data.
it turns out that the use of formatting information can lead to quite accurate extraction from general documents.
our method is unique in that we mainly utilize formatting information such as font size as features in the models.
in our approach, we annotate titles in sample documents (for word and powerpoint respectively) and take them as training data, train machine learning models, and perform title extraction using the trained models.
as a case study, we consider extraction from office including word and powerpoint.
it has not been clear whether it could be possible to conduct automatic title extraction from general documents.
previously, methods have been proposed mainly for title extraction from research papers.
by general documents, we mean documents that can belong to any one of a number of specific genres, including presentations, book chapters, technical papers, brochures, reports, and letters.
in this paper, we propose a machine learning approach to title extraction from general documents.
