we implemented the  decomposed milp and the results are shown in the following section. 
we can therefore solve this equivalent linear integer program with efficient integer programming packages which can handle  problems with thousands of integer variables.
this shows that the transformation preserves the objective function value, completing the proof.
effectively, constraint 6 ensures that all the adversaries are calculating their best responses against a particular fixed policy of the agent.
this last equality is because both are 0 when j = jl.
therefore xiql j = zl ijl ql j = zl ij.
in particular this implies that xi = x j∈q z1 ij = z1 ij1 = zl ijl , the last equality from constraint 6 of (8).
to see that the objectives match, notice for each l one ql j must equal 1 and the rest equal 0. let us say that ql jl = 1, then the third constraint in (8) implies that p i∈x zl ijl = k, which means that zl ij = 0 for all i ∈ x and all j = jl.
in fact all constraints of (7) are readily satisfied by construction.
we will show that ql , al and xi = p j∈q z1 ij are feasible for (7) with the same  objective value.
constraint 3 of (8) is satisfied  because p i∈x zl ij = kql j. lets now consider ql , zl , al feasible for (8).
the fact that p j∈q zl ij = xi as p j∈q ql j = 1 explains constraints 1, 2, 5 and 6 of (8).
the equivalence of the objective functions, and constraints 4, 7 and 8 of (8) are satisfied by  construction.
we will show that ql , al , zl ij = xiql j is a feasible solution of (8) of same objective function value.
proof: consider x, ql , al with l ∈ l a feasible solution of (7).
p i∈x p j∈q zl ij = k p j∈q zl ij ≤ k kql j ≤ p i∈x zl ij ≤ k p j∈q ql j = 1 0 ≤ (al − p i∈x 1 k cl ij( p h∈q zl ih)) ≤ (1 − ql j)m p j∈q zl ij = p j∈q z1 ij zl ij ∈ {0, 1, ...., k} ql j ∈ {0, 1} (8) proposition 2. problems (7) and (8) are equivalent.
5.2 decomposed milp we can linearize the quadratic programming problem 7 through the change of variables zl ij = xiql j, obtaining the following  problem maxq,z p i∈x p l∈l p j∈q pl k rl ijzl ij s.t.
these relations between a pure strategy in the equivalent normal form game and pure strategies in the individual games with each followers are key in showing these problems are equivalent.
the same  relation holds between c and cl .
in fact, every pure strategy j in problem (5) corresponds to a sequence of pure  strategies jl, one for each follower l ∈ l. this means that qj = 1 if and only if ql jl = 1 for all l ∈ l. in addition, given the a  priori probabilities pl of facing player l, the reward in the harsanyi transformation payoff table is rij = p l∈l pl rl ijl .
(7) problem (7) for a bayesian game with multiple follower types is indeed equivalent to problem (5) on the payoff matrix obtained from the harsanyi transformation of the game.
p i xi = kp j∈q ql j = 1 0 ≤ (al − p i∈x 1 k cl ijxi) ≤ (1 − ql j)m xi ∈ {0, 1, ...., k} ql j ∈ {0, 1}.
on autonomous agents and multi-agent systems (aamas 07) 315 maxx,q x i∈x x l∈l x j∈q pl k rl ijxiql j s.t.
therefore, given a priori  probabilities pl , with l ∈ l of facing each follower, the leader solves the following problem: the sixth intl.
joint conf.
we incorporate these constraints on the leader"s problem that  selects the optimal k-uniform policy.
using this modified notation, we characterize the optimal  solution of follower l"s problem given the leaders k-uniform policy x, with the following optimality conditions: x j∈q ql j = 1 al − x i∈x 1 k cl ijxi ≥ 0 ql j(al − x i∈x 1 k cl ijxi) = 0 ql j ≥ 0 again, considering only optimal pure strategies for follower l"s problem we can linearize the complementarity constraint above.
we also index the payoff matrices on each follower l, considering the  matrices rl and cl .
we also denote by x and q the index sets of leader and follower l"s pure strategies, respectively.
we denote by x the vector of strategies of the leader and ql the vector of strategies of follower l, with l denoting the  index set of follower types.
5.1 decomposed miqp to admit multiple adversaries in our framework, we modify the notation defined in the previous section to reason about multiple follower types.
since our security scenario contains multiple follower (robber) types, we change the response function for the follower from a pure strategy into a weighted combination over various pure follower strategies where the weights are probabilities of  occurrence of each of the follower types.
adversaries the milp developed in the previous section handles only one follower.
