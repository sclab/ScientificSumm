if the distribution of different robber types is known or inferred from historical data, then the game can be modeled as a bayesian game [6]. 
• plcx +(1−pl)(−vl,x), −plcq +(1−pl)(vl,q), for j = l ∈ i. with this structure it is possible to model many different types of robbers who have differing motivations; for example, one robber may have a lower cost of getting caught than another, or may value the goods in the various houses differently.
m. the payoffs (security agent, robber) for pure strategies i, j are: • −vl,x, vl,q, for j = l /∈ i.
the robber"s set of possible pure strategies (houses to rob) is denoted by q and includes all integers j = 1 .
m where no two elements are equal (the agent is not allowed to return to the same house).
wd = 1 .
the security agent"s set of possible pure strategies (patrol routes) is denoted by x and includes all d-tuples i =< w1, w2, ..., wd > with w1 .
• pl: probability that the security agent can catch the robber at the lth house in the patrol (pl < pl ⇐⇒ l < l).
• cq: cost to the robber of getting caught.
• cx: reward to the security agent of catching the robber.
• vl,q: value of the goods in house l to the robber.
we model the payoffs for this game with the following variables: • vl,x: value of the goods in house l to the security agent.
otherwise, if it is on the security agent"s route, then the earlier the house is on the route, the easier it is for the security agent to catch the robber before he finishes robbing it.
if the house chosen by the robber is not on the security agent"s route, then the robber successfully robs it.
we assume that the  robber generally takes a long time to rob a house.
with this knowledge, the robber must choose a single house to rob.
for example, the robber can observe over time how often the security agent patrols each area.
the security agent can choose a mixed strategy so that the robber will be unsure of exactly where the security agent may  patrol, but the robber will know the mixed strategy the security agent has chosen.
m. the security agent"s set of pure strategies consists of possible routes of d houses to patrol (in an order).
the most basic version of our game consists of two players: the security agent (the leader) and the robber (the follower) in a world consisting of m houses, 1 .
to demonstrate the utility of our algorithm, we use a simplified version of such a domain, expressed as a game.
it is usually beneficial for this policy to be nondeterministic so that robbers cannot safely rob certain locations, knowing that they will be safe from the security agents [14].
instead, they must choose a policy by which they patrol various routes at different times, taking into account factors such as the likelihood of crime in different areas, possible targets for crime, and the security agents" own resources (number of security agents, amount of available time, fuel, etc.).
in most security patrolling domains, the security agents (like uavs [1] or security robots [16]) cannot feasibly patrol all areas all the time.
