dynamics based control provides a natural approach to solving these problems. 
in fact, any search problem with randomized motion, the  socalled class of area sweeping problems, can be described through specification of such target system dynamics.
in this paper, instead of formulating a reward function, we use emt to solve the problem, by directly specifying the target  dynamics.
due to the intractable complexity of determining the optimal policy, the action policy computed in that paper was essentially an approximation.
a  reward function was defined, to reflect the desire to tag the quarry, and an action policy was computed to optimize the reward  collected over time.
in [11], the hunter modeled the problem using a pomdp.
tag is an instance of a family of area-sweeping (pursuit-evasion) problems.
the hunter knows the quarry"s probabilistic law of motion, but does not know its current location.
the quarry seeks to avoid the hunter agent, and is always aware of the hunter"s position, but does not know how the hunter will behave, which opens up the possibility for a hunter to surprise the prey.
one agent (the hunter) seeks to move into a cell  occupied by the other (the quarry), such that they are co-located (this is a successful tag).
the grid may have blocked cells (holes) into which no agent can move.
there are two agents that can move about an area, which is divided into a grid.
[11].
it was introduced in the work by pineau et al.
the game of tag is another example of the applicability of the approach.
our focus differs from this work in that dbc does not optimize expected rewards-indeed we do not  consider rewards at all-but instead maintains desired dynamics  (including, but not limited to, randomization).
the goal in that work was to generate policies that provide a measure of action-selection randomization, while maintaining rewards within some acceptable levels.
[10] has addressed such  randomization in the context of single-agent and distributed pomdps.
recent work by paruchuri et al.
it is thus advisable to make the guards" motion dynamics appear irregular and random.
cunning thieves will attempt to track these sweeps, and time their operation to key points of the guards" motion.
for example, security guards perform persistent sweeps of an area to detect any sign of intrusion.
many real-life scenarios naturally have a stochastic target  dynamics specification, especially those domains where there exists no ultimate goal, but rather system behavior (with specific  properties) that has to be continually supported.
