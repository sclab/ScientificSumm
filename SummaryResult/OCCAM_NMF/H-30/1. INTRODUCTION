finally, section 5 concludes the paper and  summarizes the major results. 
in section 4 we evaluate our proposed model and analyze the results.
section 3 provides an overview of the mrf model and  details our proposed latent concept expansion technique.
in section 2 we describe related query expansion approaches.
the remainder of this paper is laid out as follows.
our approach is both formally motivated and a natural  extension of the underlying model.
there have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].
most previous techniques, by default, generate terms  independently.
finally, our proposed approach seamlessly provides a  mechanism for generating both single and multi-term concepts.
by using more robust feature sets, it is possible to produce better expansion terms that  discriminate between relevant and non-relevant documents better.
query expansion  techniques in the past have implicitly only made use of term occurrence features.
next, as we will show, the mrf model allows arbitrary features to be used within the model.
therefore, by performing query expansion using the mrf model, we are able to study the dynamics between term dependence and query expansion.
previous query expansion techniques are based on bag of words models.
first, lce provides a mechanism for combining term  dependence with query expansion.
there are three primary contributions of our work.
in this work, we show how the model can be extended and used for query  expansion using a technique that we call latent concept expansion (lce).
until now, the model has been solely used for ranking  documents in response to a given query.
the mrf model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and japanese language web search [6].
most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].
the mrf model generalizes the unigram, bigram, and other various dependence models [14].
recently, a markov random field (mrf) model for  information retrieval was proposed that goes beyond the  simplistic bag of words assumption that underlies bm25 and the (unigram) language modeling approach to information  retrieval [20, 22].
query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].
such  techniques are used to augment the original query to produce a representation that better reflects the underlying  information need.
for this reason, there has been a strong interest in query expansion techniques.
a great deal of information is lost during the process of translating from the information need to the actual query.
users of information retrieval systems are required to  express complex information needs in terms of boolean  expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.
