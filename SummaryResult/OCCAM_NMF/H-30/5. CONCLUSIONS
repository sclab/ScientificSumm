any opinions, findings and conclusions or  recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 
acknowledgments this work was supported in part by the center for intelligent  information retrieval, in part by nsf grant #cns-0454018, in part by arda and nsf grant #ccf-0205575, and in part by microsoft live labs.
future work will look at incorporating document-side dependencies, as well.
finally, we reiterated the importance of choosing  expansion terms that model relevance, rather than the relevant documents and showed how lce captures both syntactic and query-side semantic dependencies.
this reconfirms previous observations that modeling  dependencies via the use of proximity features within the mrf has more of an impact on larger, noisier collections than smaller, well-behaved ones.
it was also shown the mrf model itself, without any query expansion, outperforms relevance models on large web data sets.
in fact, it achieves  significant improvements in mean average precision over relevance models across a selection of trec data sets.
we also showed that the model is highly effective.
the concepts generated can be used in an alternative query suggestion module.
we showed that the technique can be used to produce high quality, well formed, topically relevant multi-term  expansion concepts.
lce is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary  features, whereas previous work has been based on the bag of words assumption and term occurrence features.
the technique was shown to be a natural extension of the markov random field model for information retrieval and a generalization of  relevance models.
in this paper we proposed a robust query expansion  technique called latent concept expansion.
