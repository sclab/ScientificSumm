this work is supported in part by nsf grant  iis0238147. 
acknowledgements we would like to thank debasis mishra for helpful  discussions.
finally, it would be useful to determine whether the orâˆ— bidding language [11] can be efficiently learned (and hence elicited), given this language"s expressiveness and  succinctness for a wide variety of valuation classes.
we conjecture that information revelation is reduced when moving from maximal to minimal lindahl prices, namely as we move demand queries further away from equivalence  queries.
an interesting question here is: which lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?
we also plan to implement the algorithms for learning  polynomials and xor bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].
in the learning setting, we usually assume that oracles will provide honest responses to queries; in the  elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.
in future work we plan to address the issue of  incentives when converting learning algorithms to elicitation  algorithms.
[5] provide such an example when considering membership/value queries only (theorem 4).
blum et al.
it would be interesting to find  examples of valuation classes for which elicitation is easier than learning.
theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning  algorithms" complexity.
this is the  preference elicitation problem.
equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.
we do not require that agent valuations can be learned with value and demand queries.
the resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the  original learning algorithms are efficient.
if the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents"  valuations and integrate them into an elicitation scheme.
a learning approach to elicitation also motivates a  different approach to designing elicitation algorithms that  decomposes neatly across agent types.
our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.
at the heart of this result is the fact that demand queries may be viewed as modified equivalence queries,  specialized to the problem of preference elicitation.
we have shown that exact learning algorithms with  membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand  queries.
