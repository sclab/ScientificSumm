this issue needs more investigation in the future. 
in this situation, it is difficult for an agent to efficiently gather historical information about all remote servers.
in the worst case, by the time for exploring all servers, historical information of some servers could be already outdated and the exploration starts again.
this  process of acquiring resource load information about all servers can take a long time in the case that no not enough shared resources for all tasks are provided.
in the case that more resources are requested by agents than shared resources are provided by all servers, all agents will randomly explore all known servers.
we are aware of the long learning phase in environments with a large number of shared resources known by each agent.
in contrast, a dynamic environment with varying capacities requires more up-to-date information to make more reliable predictions.
a large number of shared resources requires older historical information to avoid a too frequently resources exploration.
the decay rate is currently predefined and must be altered manually depending on the environment.
in the near future we will investigate if an automatic  adaptation of the decay rate of historical information our  algorithm is possible and can improve the resource allocation performance.
the evolution would be very slow and selective and will not influence the system behaviour in a short-term period that is covered by our experimental results.
on autonomous agents and multi-agent systems (aamas 07) investigated in the future.
joint conf.
in fact, we believe that this could further improve the system"s behaviour over a long term period and could be 80 the sixth intl.
the set of predictors stays the same over the whole life.
there is no discovery of new strategies by the agents.
our approach adapts to changes in the environment but it is not evolutionary.
this approach can be easily extended or supported by resource balancing/queuing mechanisms provided by  resources.
a simple decision mechanism based on different beliefs of the agent creates an emergent behaviour that leads to effective resource  allocation.
all control is implemented in the agents.
it is a distributed, scalable and easy-to-understand  policy for the regulation of supply and demand of resources.
the presented results for this new approach for strategic migration  optimisation are very promising and justify further investigation in a real multi-agent system environment.
our self-organising resource allocation approach was  evaluated with a number of simulation experiments in a dynamic environment of agents and server resources.
especially in dynamic and scalable environments such as grid systems, a robust and distributed mechanism for resource allocation is required.
in the case of a server becomes  unavailable, the agents can adapt quickly to this new situation by exploring new resources or remain at the home server if an allocation is not possible.
this mechanism was inspired by inductive reasoning and bounded rationality principles which enables the agents"  adaptation of their strategies to compete effectively in a  dynamic environment.
neither do they need coordination or information from a higher authority nor is an additional direct communication between agents required.
our mechanism demonstrates that resource allocation can be done by the effective  competition of individual and autonomous agents.
the resource allocation is a purely emergent effect.
this process is adaptive and has a strong feedback as allocation decisions influence  indirectly decisions of other agents.
agents sense their server  environment and adopt their action to compete more efficient in the new created environment.
available shared resource.
in our  approach the agents compete for an allocation at one of the 0 500 1,000 1,500 2,000 time 0 2,500 5,000 7,500 resourceload (a) total resource load  versus total shared resource  capacity 0 500 1,000 1,500 2,000 time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 resourceload (b) resource load server 1 0 500 1,000 1,500 2,000 time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 resourceload (c) resource load server 2 0 500 1,000 1,500 2,000 time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 resourceload (d) resource load server 3 figure 5: results of experiment 2 in a dynamic server environment averaged over 100 repetitions.
we enable agents to select the execution platform for their tasks themselves before each execution at run-time.
in this paper a self-organising distributed resource  allocation technique for multi-agent systems was presented.
