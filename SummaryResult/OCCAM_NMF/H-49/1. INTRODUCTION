3. the first large-scale experiments of zero-judgment,  single run performance prediction (sections 5 and 6). 
2. a theoretical treatment of the similarities and  motivations behind several state-of-the-art performance  prediction techniques (section 4).
in this work, we provide the following contributions, 1. a general, robust method for predicting the  performance of retrievals with zero relevance judgments  (section 3).
if this connection is  reasonable, in section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.
because of this, we interpret  autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.
as we shall see, a retrieval function"s spatial autocorrelation  measures the degree to which closely-related documents receive similar scores.
the cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].
the discussion up to this point is reminiscent of the  cluster hypothesis.
in this paper, we demonstrate a strong correlation between im and retrieval performance.
score  consistency can be measured by the spatial version of  autocorrelation known as the moran coefficient or im [5, 10].
if documents are embedded in a space, proximity correlates with topical relationships.
spatial analysis is appropriate since many retrieval models embed documents in some vector space.
our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.
we would be more comfortable with a retrieval where scores are consistent between related documents.
we might become more worried as we find more differences between scores of related documents.
that is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.
take two topically-related  documents from the set and call them a and b. if the scores of a and b are very different, we may be concerned about the  performance of our system.
if we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.
the system retrieves n documents each receiving a  realvalued score indicating the predicted degree of relevance.
in information retrieval, a user poses a query to a system.
