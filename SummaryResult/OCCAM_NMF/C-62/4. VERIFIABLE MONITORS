in the extreme, the cheater may use such a strategy to drive neighbors out of business, and thereby gain a monopoly on some routes. 
this may give the cheater a strategic advantage against its competitors.
by cheating, the node will save money to some extent, so the cheater is likely to emerge from the punishment phase better off than the innocent nodes.
because of this, a node might deliberately cheat, in order to trigger punishment for itself and its neighbors.
from the perspective of other source-destination pairs, however, these same firms are likely to be horizontal competitors.
when isps lie in sequence along a data path, they contribute complementary services, and their relationship is vertical.
the effects are not so benign in the real world.
in our abstract model, this doesn"t cause trouble since the punishment falls off the equilibrium path.
effectively, innocent nodes will be punished along with the guilty.
the final reason not to accept this monitoring system is that when a cheater is punished, the path will often be routed around not just the offender, but around other nodes as well.
the required discounted time for punishment may increase exponentially in the number of coalition members, just as in the previous section!
alternately, a node may bribe its successor to cheat, if the punishment phase is profitable, and so forth.
a coalition node may pretend to punish its successor, but instead enjoy a secret payment from the cheating node.
the third reason is that lemma 2 does not apply to cheating by coalitions.
this will make nodes less motivated to administer punishments.
since punishment phases are generally characterized by a drop in quality, real world end-users may take this opportunity to shop for a new access provider.
real world users are less likely to act collectively, and may simply search for the best service currently offered.
the second, and more serious reason is that we have always given our source the ability to commit to any punishment.
of course, if t0 is small, this effect is minimal.
each node along a route must extract some positive profit unless the next hop is also the cheapest.
the first, and weakest reason is that the maximum temptation remains finite, causing some distortion in routes or payments.
unfortunately, there are at least four reasons not to be satisfied with this improved monitoring system.
with this lemma in mind, it is easy to construct counterexamples to claim 1 and claim 2 in this new environment.
only that node must be punished in equilibrium, and the preceding node does not lose any payoff in administering the punishment.
this lemma follows because nodes can share proofs to identify who the cheater is.
for example, the following lemma stands in contrast to lemma 1. lemma 2. with monitors e2ev, ropv, and prc, and provided that the node before each potential cheater has an alternate next hop that isn"t more expensive, it is possible to enforce any data path in spe so long as the maximum temptation is less than what can be deterred in finite time, − ≤ 0 0 max 1 t rt er y π (5) proof.
this means that the negative results of the previous section no longer hold.
the cheater is the node that cannot produce proof that the rest of path quality decreased.
189 by adding verifiability to our monitors, identifying a single cheater is straightforward.
with these monitors, each node observes the quality of the rest of the path and can also convince other players of these observations by giving them a proof.
we will label these e2ev and ropv.
along these lines, we can imagine verifiable counterparts to e2e and rop.
a verifiable monitor is a distributed algorithmic mechanism that runs on the network graph, and outputs, to specific nodes, proofs about current or past network behavior.
the monitor"s output in this case can be thought of as a statement accompanied by a proof, a string that can be processed by any player to determine that the statement is true.
if a monitor"s informational signal can be credibly conveyed to others, we will call it a verifiable monitor.
what would happen if they could?
recall that in the previous section, we assumed that players couldn"t convince each other of their private information.
in this section, we begin to introduce more accountability into the network.
