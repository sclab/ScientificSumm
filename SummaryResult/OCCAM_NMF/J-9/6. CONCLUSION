we thank robin hanson and the anonymous reviewers for useful  insights and pointers. 
acknowledgments we thank joe kilian for many helpful discussions.
what is the  relationship between machine learning (e.g., neural-network learning) and information-market design?
are there ways to define and configure securities to speed up convergence to equilibrium?
what configuration of  securities can best approximate a given function?
this is exactly the problem of minimizing the size of a neural network, a well-studied problem known to be np-hard [15].
what is the minimum number of threshold securities required to implement a given function?
• information market design: non-threshold functions can be implemented by layering two or more  threshold functions together.
it is interesting to ask whether we would get very different results for generic prior distributions.
• average-case analysis: our negative results (theorems 3 and 5) examine worst-case scenarios, and thus  involve very specific prior probability distributions.
• the common-prior assumption: can we say anything about the market behavior when agents" priors are only approximately the same or when they differ  greatly?
a more satisfying approach would be to  assume only rationality and solve for the resulting  gametheoretic solution strategy, either in our current  computational model or another model of an information market.
• strategic market models: for reasons of simplicity and tractability, we have directly assumed that agents bid truthfully.
• agents" computation: we have not accounted for the complexity of the computations that agents must do to accurately update their beliefs after each round.
for example, can we find a good distributed-computational model of a decentralized market?
in a sense, some of the computation  itself is distributed among the participating agents, but can the market computation also be distributed?
• distributed computation: in our model, distributed  information is aggregated through a centralized market 163 computation.
• incremental updates: if the agents have computed the value of the function and a small number of input bits are switched, can the new value of the function be computed incrementally and quickly?
it is interesting to ask what  aggregates can be computed even in the presence of noisy prices.
further, we have neglected influences on the market price other than from rational traders; the market price may also be influenced by other factors such as misinformed or irrational traders.
some  interesting and important next steps include gaining a better understanding of the following: • the effect of price accuracy and precision: we have  assumed that the clearing price is known with unlimited precision; in practice, this will not be true.
6.2 future work we view this paper as a first step towards understanding the computational power of information markets.
we show that this bound is tight within a factor of two.
we prove that the process whereby agents reveal their  information over time and learn from the resulting announced prices takes at most n rounds to converge to the correct full-information price in the worst case.
specifically, we show that the market is guaranteed to converge to the true rational expectations equilibrium if and only if the  security payoff function is a weighted threshold function.
within this model, we prove several results characterizing precisely what the market can compute and how quickly.
we have developed a simplified model of an information  market that we believe captures many of the important aspects of real agent interaction in an information market.
6.1 summary we have framed the process of information aggregation in markets as a computation on distributed information.
