categories and subject descriptors: h.3.3 [information  systems]: information search and retrieval general terms: algorithms, experimentation 
in the experiments, the proposed method is compared with state-of-the-art methods and demonstrates an excellent accuracy in hypertext classification on the webkb and cora benchmarks.
further  analysis can be performed based on the compact representation of web pages.
being practically attractive for its great simplicity, this paper aims to design an  algorithm that exploits both the content and linkage information, by  carrying out a joint factorization on both the linkage adjacency matrix and the document-term matrix, and derives a new representation for web pages in a low-dimensional factor space, without explicitly separating them as content, hub or authority factors.
though a few methods exploit both the link  structure or the content information, some of them combine the only authority information with the content information, and the others first decompose the link structure into hub and authority features, then apply them as additional document features.
the research in this direction has recently received considerable attention but are still in an early stage.
it is thus difficult to apply traditional mining or learning methods for solving web mining problems, e.g., web page classification, by  exploiting both the content and the link structure.
this huge database violates the  assumption held by most of conventional statistical methods that each web page is considered as an independent and identical sample.
the world wide web contains rich textual contents that are  interconnected via complex hyperlinks.
