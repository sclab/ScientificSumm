0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 meanaverageprecision(inex-2002) b strict generalized sog figure 4: impact of b on inex-2002 mean average precision with k1 = 10 (inex 2003 co topics). 
after tuning over a wide range of  values under several quantization functions, we selected values of k = 10.0 and b = 0.80 for our inex 2004 experiments, and these values are used for the experiments reported in section 7.
in contrast, our default value of b = 0.75 works well under all quantization functions (figure 4).
similar improvements are seen  under the generalized and sog quantizations.
between k1 = 1.0 and k1 = 6.0 map increases by over 15% under the strict quantization.
in our experience, optimal  values for k1 are typically in the range 0.0 to 2.0. in this case, large values are required for good performance.
figure 3 shows the result of varying k1 with b = 0.75 on the map values under three quantization functions.
the results were surprising.
as a starting point we used the values b = 0.75 and k1 = 1.2, which perform well on trec adhoc collections and are used as default values in our system.
prior to inex 2004, we trained the multitext system using the inex 2003 queries.
in our experience, the performance of bm25 typically  benefits from tuning the b and k1 parameters to the  collection, whenever training queries are available for this  purpose.
nonetheless, we plan to examine this issue again in the future.
the score computed for an element is  essentially the score it would receive if it were added to the collection as a new document, ignoring the minor  adjustments needed to the document-level statistics.
this approach may be justified by  viewing the collection as a set of articles to be searched using standard document-oriented techniques, where only articles may be returned.
the use of article statistics for all element types might be questioned.
[10], the retrieval  results are filtered to eliminate very short elements, those less than 25 words in length.
following the suggestion of kamps et al.
these statistics are used for ranking all element types.
for the purposes of computing document-level statistics (d, dt and lavg) a document is defined to be an article.
prior to inex 2004, the inex 2003 topics and judgments were used to tune the b and k1 parameters, and the impact of this tuning is discussed later in this section.
given a term set q, an element x is assigned the score   t∈q w(1) qt (k1 + 1)xt k + xt (1) where w(1) = log ¡ d − dt + 0.5 dt + 0.5 ¢ d = number of documents in the corpus dt = number of documents containing t qt = frequency that t occurs in the topic xt = frequency that t occurs in x k = k1((1 − b) + b · lx/lavg) lx = length of x lavg = average document length 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 8 10 12 14 16 meanaverageprecision(inex-2002) k1 strict generalized sog figure 3: impact of k1 on inex-2002 mean average precision with b = 0.75 (inex 2003 co topics).
[21] by setting parameters k2 = 0 and k3 = ∞.
our implementation of okapi bm25 is derived from the formula of robertson et al.
for example, keyword field of topic 166 +"tree edit distance" + xml -image became the four-term query "$tree" "$edit" "$distance" "$xml" where the $ operator within a quoted string stems the term that follows it.
for inex 2004, the term vector y was derived from the topic by splitting phrases into individual words, eliminating stopwords and negative terms (those starting with -), and applying a stemmer.
automating this selection process is planned as future work.
tag names were selected on the basis of their frequency in the collection, the average size of their  associated elements, and the relative number of positive relevance judgments they received.
prior to inex 2004, the inex collection and the inex 2003 relevance judgments were manually analyzed to select these tag names.
for our inex 2004 runs, the sub-query x specified a list of retrievable elements as those with tag names as follows: abs app article bb bdy bm fig fm ip1 li p sec ss1 ss2 vt this list includes bibliographic entries (bb) and figure  captions (fig) as well as paragraphs, sections and subsections.
to support retrieval from xml and other structured  document types, the system provides generalized queries of the form: rank x by y where x is a sub-query specifying a set of document elements to be ranked and y is a vector of sub-queries specifying individual retrieval terms.
the  multitext system performed respectably at inex 2004, placing in the top ten under all of the quantization functions, and placing first when the quantization function emphasized  exhaustivity.
this retrieval method results from the adaptation and tuning of the okapi bm25  measure [21] to the xml information retrieval task.
this section provides an overview of baseline xml  information retrieval method currently used in the multitext ir system, developed by the information retrieval group at the university of waterloo [3].
