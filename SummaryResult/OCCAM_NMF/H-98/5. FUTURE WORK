by analogy to the log-odds, the operative score that  appears promising is log weight perceptrons voting + weight perceptrons voting âˆ’ . 
we are currently evaluating the appropriateness of these methods for the output of a voted  perceptron [11].
finally, extending these methods to the outputs of other  discriminative classifiers is an open area.
this approach may provide more power since it retains the  asymmetry assumption but not the assumption that the class-conditional densities are from an asymmetric laplace.
just as logistic regression allows the log-odds of the posterior distribution to be fit directly with a line, we could directly fit the log-odds of the posterior with a three-piece line (a spline) instead of indirectly doing the same thing by fitting the asymmetric laplace.
from the empirical evidence presented in [22], the expectation is that such a distribution might allow more emphasis of the probability mass around the modes (as with the exponential) while still providing more accurate estimates toward the tails.
a promising extension to the work presented here is a hybrid distribution of a gaussian (on the outside slopes) and exponentials (on the inner slopes).
