to the best of our knowledge we are the first to use this approach for static caching of posting lists. 
similar ideas have been used in the context of file caching [17], web caching [5], and even caching of posting lists [9], but in all cases in a dynamic setting.
finally, our static caching algorithm for posting lists in section 5 uses the ratio frequency/size in order to evaluate the goodness of an item to cache.
these last two papers are related to ours in that they exploit different caching strategies at different levels of the memory hierarchy.
the  intermediate level contains frequently occurring pairs of terms and stores the intersections of the corresponding inverted lists.
long and suel propose a caching system structured according to three different levels [9].
baeza-yates and saint-jean propose a three-level index  organization [2].
they find that the second-level cache can effectively reduce disk traffic, thus increasing the overall throughput.
in their architecture, both levels use an lru eviction  policy.
their goal for such systems has been to improve response time for hierarchical engines.
propose a new architecture for web search engines using a two-level dynamic caching system [13].
saraiva et al.
as systems are often hierarchical, there has also been some effort on multi-level architectures.
different from our work, they consider caching and prefetching of pages of results.
follow markatos" work by showing that combining static and dynamic caching policies together with an adaptive prefetching policy achieves a high hit ratio [7].
fagni et al.
based on the observations of markatos, lempel and moran propose a new caching policy, called probabilistic driven caching, by attempting to estimate the probability distribution of all possible queries submitted to a search engine [8].
markatos [10] shows the existence of temporal  locality in queries, and compares the performance of different caching policies.
raghavan and sever [12], in one of the first papers on  exploiting user query history, propose using a query base, built upon a set of persistent optimal queries submitted in the past, to improve the retrieval effectiveness for similar future queries.
they may be considered separate and complementary to a cache-based approach.
although these approaches seek to improve query processing efficiency, they differ from our  current work in that they do not consider caching.
more recent examples demonstrate that the top k documents for a query can be returned without the need for evaluating the complete set of posting lists [1, 4, 15].
buckley and lewit [3], in one of the earliest works, take a term-at-a-time approach to deciding when inverted lists need not be further examined.
there is a large body of work devoted to query  optimization.
