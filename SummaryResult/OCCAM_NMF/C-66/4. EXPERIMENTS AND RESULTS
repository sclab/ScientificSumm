however, we feel that the benefit of finding much higher business value scores justifies the running time of the ga; further we would expect that the running time will improve with both software tuning as well as with a computer faster than our off-the-shelf pc. 
we note that the round-robin, random-proportional, and greedy algorithms all finished within 1 second even for the largest workflow configuration.
for completeness, we show the performance of the genetic  algorithm itself in figure 11. the algorithm scales linearly with an increasing number of workflows.
on the other hand, the random-proportional  algorithm uses many service providers, but because business processes are proportionally assigned with more assignments going to the better providers, there is a tendency for a smaller percentage of providers to become saturated.
for example, in the greedy algorithm only one service provider is utilised, and this one provider quickly  becomes saturated.
figure 10 is the percentage of accessed service providers (that is, the percentage of service providers represented in figure 9) that had more assigned business processes than their advertised maximum concurrency.
although useful, the makespan does not take into consideration the  business value scoring in our problem domain.
this value is the makespan metric used in traditional scheduling research.
0 50 100 150 200 250 300 0 200 400 600 800 1000 makespan[seconds] number of workflows maximum completion time for all workflows genetic algorithm round robin random proportional greedy figure 8: maximum completion time for all workflows.
failed acceptable (completed but not within qos) successful (completed within qos) 0% 20% 40% 60% 80% 100% roundrobinrandproportionalgreedygeneticalg percentageofallworkflows workflow behaviour, 500 workflows figure 7: workflow behaviour for 900 workflows.
failed acceptable (completed but not within qos) successful (completed within qos) 0% 20% 40% 60% 80% 100% roundrobinrandproportionalgreedygeneticalg percentageofallworkflows workflow behaviour, 500 workflows figure 6: workflow behaviour for 500 workflows.
as expected, the greedy algorithm always hits one service provider; on the other hand, the round-robin algorithm is the fastest to spread the business 33 experimental parameter comment workflows 5 to 1000 business processes per workflow uniform random: 1 - 10 service types 10 service providers per service type uniform random: 1 - 10 workflow qos goal uniform random: 10-30 seconds service provider completion time (α) uniform random: 1 - 12 seconds service provider maximum concurrency (β) uniform random: 1 - 12 service provider degradation coefficient (γ) uniform random: 0.1 - 0.9 business value for successful workflows uniform random: 10 - 50 points business value for acceptable workflows uniform random: 0 - 10 points business value for failed workflows uniform random: -10 - 0 points ga: number of parents 20 ga: number of children 80 ga: number of generations 1000 table 1: experimental parameters failed acceptable (completed but not within qos) successful (completed within qos) 0% 20% 40% 60% 80% 100% roundrobinrandproportionalgreedygeneticalg percentageofallworkflows workflow behaviour, 100 workflows figure 5: workflow behaviour for 100 workflows.
figure 9 shows the percentage of services providers that were accessed while the workflows ran.
we also looked at the effect of the scheduling algorithms on balancing the load.
the ga produces better business values (as shown in figure 3) because it is able to search the solution space to find  better mappings that produce more successful workflows (as shown in figures 5 to 7).
for completeness, we note that the ga  provides the fastest makespan, but it is matched by the round robin algorithm.
indeed, the makespan is oblivious to the fact that we provide multiple levels of  completion (successful, acceptable, and failed) and assign business value scores accordingly.
while useful, it does not capture the high-level business value metric that we are optimising against.
makespan is a traditional metric from the job scheduling community measuring elapsed time for the last job to complete.
further, the round-robin scheme produces better results than the random-proportional for a large number of workflows but does not perform as well as the ga. in figure 8 we graph the makespan resulting from the same experiments above.
the ga consistently produces the highest percentage of successful workflows (resulting in higher business values for the aggregate set of workflows).
these figures show the percentage of workflows that are successful (can complete with their qos limit), acceptable (can complete within κ=3 times their qos limit), and failed (cannot complete within κ=3 times their qos limit).
to better understand the behaviour resulting from the scheduling assignments, we show the workflow completion results in figures 5, 6, and 7 for 100, 500, and 900 workflows, respectively.
for a very large number of workflows, the round-robin scheme is able to better  balance the load across all service providers.
-500 0 500 1000 1500 2000 2500 3000 3500 4000 0 50 100 150 200aggregatebusinessvalueacrossallworkflows total number of workflows business value scores of scheduling algorithms genetic algorithm round robin random proportional greedy figure 4: magnification of the left-most region in figure 3. number of workflows that we are considering.
the reason is that although the random-proportional scheme assigns business processes to providers proportionally  according to the advertised completion times (which is a measure of the power of the service provider), even the best providers will eventually reach a real-world maximum concurrency for the large -2000 -1000 0 1000 2000 3000 4000 5000 6000 7000 0 200 400 600 800 1000 aggregatebusinessvalueacrossallworkflows total number of workflows business value scores of scheduling algorithms genetic algorithm round robin random proportional greedy figure 3: net business value scores of different scheduling algorithms.
the round-robin scheme is initially outperformed by the  randomproportional scheme up to around 120 workflows (as shown in the magnified graph of figure 4), but as the number of workflows  increases, the round-robin scheme consistently wins over  randomproportional.
as expected, the greedy algorithm performs very poorly because it does the worst job at balancing load: all business processes for a given service type are assigned to only one server (the one  advertised to have the fastest completion time), and as more  business processes arrive, the provider"s performance degrades linearly.
(note that although we are optimising against the business value metric we defined earlier, genetic algorithms are able to converge towards the optimal value of any metric, as long as the evaluation function can consistently measure a chromosome"s value with that metric.)
as can be seen, the ga consistently produces the highest business value even as the number of  workflows grows; at 1000 workflows, the ga produces a 115%  improvement over the next-best alternative.
the x-axis shows the number for  workflows scaled up to 1000, and the y-axis shows the aggregate  business value for all workflows.
in figure 3 we show the results of running our ga against the three candidate alternatives.
in table 1 we list our experimental parameters.
in the experiments that follow, all results were averaged across 20 trials, and to help normalise the effects of randomisation used during the ga, each trial started by reading in pre-initialised data from disk.
this algorithm represents a naive  approach based on greedy, local observations of each workflow without taking into consideration all workflows.
• a strawman greedy algorithm that always assigns business processes to the service provider that has the fastest  guaranteed completion time.
(we also tried a proportionality scheme based on both the completion times and maximum concurrency but attained the same results, so only the former scheme"s results are shown here.)
• a random-proportional algorithm that proportionally assigns business processes to the service providers; that is, for a given service type, the service providers are ranked by their guaranteed completion time, and business processes are  assigned proportionally to the providers based on their  completion time.
this approach provides the simplest scheme for load-balancing.
we compared our algorithm against alternative candidates: • a well-known round-robin algorithm that assigns each  business process in circular fashion to the service providers for a particular service type.
the simulator was written in standard c++ and was run on a linux (fedora core) desktop computer running at 2.8 ghz with 1gb of ram.
because we wanted to scale the scenarios up to a large number of workflows (up to 1000 in our experiments), we implemented a simulation program that allowed us to vary parameters and to  measure the results with different metrics.
in this section we show the benefit of using our ga-based  scheduler.
