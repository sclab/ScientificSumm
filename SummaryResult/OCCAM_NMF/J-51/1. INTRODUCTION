finally, in section 6, we study dominance and iterated dominance in bayesian games. 
in section 5, we study dominance and iterated dominance when the  dominating strategy can only place probability on a few pure strategies.
in section 4, we study iterated dominance.
in section 3, we study one-shot (not iterated) dominance.
in the remaining sections, we study  computational aspects of dominance and iterated dominance.
in section 2, we briefly review definitions and basic properties of normal form games, strict and weak dominance, and iterated strict and weak dominance.
the rest of the paper is organized as follows.
in this paper, we study some fundamental computational questions concerning dominance and iterated dominance,  including how hard it is to check whether a given strategy can be eliminated by each of the variants of these notions.
computing solutions  according to (iterated) dominance is important for at least the following reasons: 1) it can be computationally easier than computing (for instance) a nash equilibrium (and therefore it can be useful as a preprocessing step in computing a nash equilibrium), and 2) (iterated) dominance requires a weaker rationality assumption on the players than (for instance) nash equilibrium, and therefore solutions derived according to it are more likely to occur.
in iterated dominance, the elimination proceeds in rounds, and becomes easier as more strategies are eliminated: in any given round, the dominating  strategy no longer needs to perform better than or as well as the dominated strategy against opponent strategies that were eliminated in earlier rounds.
the idea is that dominated strategies can be eliminated from consideration.
(after an early short paper on an easy case [11], the main  computational study of these concepts has actually taken place in a paper in the game theory community [7].1 ) a strategy strictly dominates another strategy if it performs strictly 1 this is not to say that computer scientists have ignored 88 better against all vectors of opponent strategies, and weakly dominates it if it performs at least as well against all vectors of opponent strategies, and strictly better against at least one.
the problem of computing solutions according to the  perhaps more elementary solution concepts of dominance and iterated dominance has received much less attention.
recently, numerous papers have  studied computing nash equilibria in various settings [9, 4, 12, 3, 13, 14], and the complexity of constructing a nash  equilibrium in normal form games has been labeled one of the two most important open problems on the boundary of p today [20].
a nash  equilibrium specifies a strategy for each player, in such a way that no player has an incentive to (unilaterally) deviate from the prescribed strategy.
probably the best-known (and certainly the most-studied) solution concept is that of nash equilibrium.
game theory offers various formal models of strategic settings-the best-known of which is a game in normal (or matrix) form, specifying a utility (payoff) for each agent for each  combination of strategies that the agents choose-as well as  solution concepts, which, given a game, specify which outcomes are reasonable (under various assumptions of rationality and common knowledge).
in such settings, the agents require tools from game theory to rationally decide on an action.
in multiagent systems with self-interested agents, the  optimal action for one agent may depend on the actions taken by other agents.
