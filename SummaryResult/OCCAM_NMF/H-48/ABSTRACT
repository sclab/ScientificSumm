categories and subject descriptors h.3.3 [information storage and retrieval]: information search and retrieval general terms measurement, experimentation 
the proposed approach is  attractive because it provides an estimate of system  performance under varying degrees of query-document term  mismatch, it makes use of readily available test collections, and it does not require any additional relevance judgments or any form of manual processing.
in this paper, we propose a new approach for evaluating query expansion techniques.
while this measures an overall change in performance, it does not directly measure the  effectiveness of ir systems in overcoming the inherent issue of term mismatch between the query and relevant documents, nor does it provide any insight into how such systems would behave in the presence of query-document term mismatch.
ir systems implementing query expansion are typically evaluated by executing each query twice, with and without query expansion, and then  comparing the two result sets.
query expansion (qe) is one method for  dealing with term mismatch.
query-document term mismatch, whether partial or total, is a fact that must be dealt with by ir systems.
the effectiveness of information retrieval (ir) systems is  influenced by the degree of term overlap between user queries and relevant documents.
