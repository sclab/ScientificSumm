random walk has been shown to provide similar  convergence bounds as uniform gossip in problems of similar context [8, 12]. 
this process repeats until the aggregate has converged in the network.
in each time-step, each designated node sends its data to a random neighbor, which becomes designated for the subsequent  timestep (much like passing a token).
at startup, k nodes are randomly elected as designated nodes.
• random walk: in random walk, only a subset of the nodes (termed designated nodes) communicate in a particular time-step.
uniform gossip provides exponentially fast convergence, with low network overhead [10].
this process repeats for o(log(n)) steps (where n is the number of nodes in the network).
14 two types of gossip protocols are: • uniform gossip: in uniform gossip, at each  timestep, each node chooses a random neighbor and sends its data to it.
2 convergence refers to the state in which all nodes have the most up-to-date view of the network.
these protocols can therefore easily scale to very dense  environments.
gossip protocols have been shown to provide exponentially fast convergence2 , on the order of o(log n) [10], where n is the number of nodes (or radios).
we  emphasize that this characteristic of the protocol also allows it to operate without relying on any underlying network structure.
the  randomized propagation of information provides fault-tolerance and resilience to network failures and outages.
at every time-step, each node having something to send randomly selects one or more neighboring nodes and transmits its data to them.
4.2 gossip protocols gossip-based protocols operate in discrete time-steps; a time-step is the required amount of time for all  transmissions in that time-step to complete.
transmitting fm bit vectors between nodes is done using randomized gossiping, discussed next.
queries other than count can also be computed using  variants of this basic counting algorithm, as discussed in [3] (and shown in figure 2).
this decreases the error to within o(1/ √ m), where m is the number of such bit vectors.
more accurate aggregates can be computed by maintaining multiple bit vectors at each node, as explained in [7].
although such aggregates are very compact in nature,  requiring only o(logn) state space (where n is the number of nodes), they may not be very accurate as they can only approximate values to the closest power of 2, potentially causing errors of up to 50%.
the actual value of the count aggregate is then computed using the following formula, aggf m = 2j−1 /0.77351, where j represents the bit position of the least significant zero in the aggregate bit vector [7].
at the end of the aggregation process, every node, with high probability, has the same bit vector.
when a node receives a bit vector, it updates its local bit vector by bitwise or-ing it with the received vector (as shown in figure 2 which computes average).
these bit vectors are then exchanged among nodes.
the  intuition is that as the number of nodes doing coin toss  experiments increases, the probability of a more significant bit being set in one of the nodes" bit vectors increases.
the node then sets the ith bit in a bit vector (initially filled with zeros), where i is the number of coin tosses it performed.
to do so, each node  performs a coin toss experiment as follows: toss an unbiased coin, stopping after the first head is seen.
the count query.
suppose we want to compute the number of nodes in the network, i.e.
next we outline the fm approach; for full details, see [7].
we adopt the odi approach pioneered by flajolet and martin (fm) for the purposes of aggregation.
order and duplicate  insensitive (odi) techniques have been proposed in the literature [10, 15].
however, this approach is not scalable.
intuitively, nodes can tag the aggregate value they transmit with  information about which nodes have contributed to it.
double-counting is a well known problem in this process, where nodes may contribute more than once to the aggregate, causing inaccuracy in the final result.
the global  aggregate.
this  aggregate is then communicated to other nodes in the  network and this process repeats until the aggregate at all nodes has converged to the same value, i.e.
4.1 fm aggregation aggregation is the process where nodes in a distributed network combine data received from neighboring nodes with their local value to generate a combined aggregate.
we also discuss randomized gossiping techniques for disseminating aggregates in a cognitive radio network.
we present the fm aggregation scheme that we use to  generate spectrum summaries and perform in-network  aggregation.
this section provides the background for our approach.
