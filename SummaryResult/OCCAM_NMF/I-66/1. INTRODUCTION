822 978-81-904262-7-5 (rps) c 2007 ifaamas 
we finally demonstrate a key feature of spider: by utilizing the approximation enhancements it enables principled tradeoffs in run-time versus solution quality.
furthermore, we demonstrate that abstraction improves the performance of spider significantly (while providing optimal solutions).
in our experiments, we illustrate that spider dominates an existing global optimal approach called goa [10], the only known global optimal algorithm with demonstrated experimental results for more than two agents.
[10], a domain representative of an important class of problems with networks of agents working in uncertain  environments.
we experimented with the sensor network domain presented in nair et al.
the third enhancement is again based on bounding the search for efficiency, however with a  tolerance parameter that is provided as a percentage of optimal.
the second  enhancement obtains speedups by sacrificing solution quality, but within an input parameter that provides the tolerable expected value  difference from the optimal solution.
in  particular, it initially performs branch and bound search on abstract  policies and then extends to complete policies.
the first enhancement uses  abstractions for speedup, but does not sacrifice solution quality.
we then provide three enhancements to improve the  efficiency of the basic spider algorithm while providing guarantees on the quality of the solution.
there are two key novel features in spider: (i) it is a branch and bound heuristic search technique that uses a mdp-based heuristic function to search for an optimal joint policy; (ii) it exploits network structure of agents by organizing agents into a depth first search (dfs) pseudo tree and takes advantage of the independence in the different branches of the dfs tree.
we first propose the basic spider (search for policies in distributed environments) algorithm.
to address these problems with the existing approaches, we  propose approximate techniques that provide guarantees on the  quality of the solution while focussing on a network of more than two agents.
furthermore, they fail to exploit structure in the interactions of the agents and hence are severely hampered with respect to scalability when considering more than two agents.
though these approaches obtain optimal solutions, they typically consider only two agents.
in contrast, the second less popular category of  approaches has focused on a global optimal result [13, 5, 10].
the key problem with these techniques has been their inability to provide any guarantees on the quality of the solution.
the first category consists of highly efficient approximate techniques, that may not reach globally  optimal solutions [2, 9, 11].
researchers have attempted two different types of approaches towards solving these models.
[3], the problem of finding the optimal joint policy for general distributed pomdps is nexp-complete.
unfortunately, as shown by bernstein et al.
the uncertainty arises on account of  nondeterminism in the outcomes of actions and because the world state may only be partially (or incorrectly) observable.
distributed partially observable markov decision problems  (distributed pomdps) are emerging as a popular approach for  modeling sequential decision making in teams operating under  uncertainty [9, 4, 1, 2, 13].
