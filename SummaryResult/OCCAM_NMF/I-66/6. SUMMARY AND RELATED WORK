the views and  conclusions contained in this document are those of the authors, and should not be interpreted as representing the official policies, either expressed or implied, of the defense advanced research projects agency or the u.s. government. 
this material is based upon work  supported by the defense advanced research projects agency (darpa), through the department of the interior, nbc, acquisition services division under contract no.
this aspect of quality bounds differentiates spider from all the above techniques.
though all the above techniques improve the efficiency of policy  computation considerably, they are unable to provide error bounds on the quality of the solution.
[2] are examples of policy search techniques that search for locally optimal policies.
[11] and bernstein et al.
peshkin et al.
[9]"s jesp algorithm uses dynamic programming to reach a local optimum solution for finite horizon decentralized pomdps.
nair et al.
[4] approximate posgs as a series of one-step bayesian games using heuristics to approximate future value,  trading off limited lookahead for computational efficiency, resulting in locally optimal policies (with respect to the selected heuristic).
emerymontemerlo et al.
the second set of techniques seek approximate policies.
however, spider has been illustrated for networks of agents; and (c)  spider explores the joint policy one agent at a time, while maa*  expands it one time step at a time (simultaneously for all the agents).
the key differences between spider and maa* are: (a) enhancements to spider (vax and pax) provide for quality guaranteed approximations, while maa* is a global optimal algorithm and hence involves significant  computational complexity; (b) due to maa*"s inability to exploit  interaction structure, it was illustrated only with two agents.
this algorithm is based on the combination of a classical heuristic search algorithm, aâˆ— and decentralized control theory.
[13] provide an optimal heuristic search method for solving decentralized pomdps.
szer et al.
[5] present an  algorithm based on dynamic programming and iterated elimination of dominant policies, that provides optimal solutions for distributed pomdps.
hansen et al.
the first set of techniques  compute global optimal solutions.
researchers have typically employed two types of techniques for solving distributed pomdps.
experimental results show orders of magnitude  improvement in performance over previous global optimal algorithms.
these features allow for systematic tradeoff of solution quality for run-time in networks of agents operating under  uncertainty.
easier scale-up to larger number of agents); (ii) using branch and bound search with an mdp based heuristic function; (iii) utilizing abstraction to improve  runtime performance without sacrificing solution quality; (iv)  providing a priori percentage bounds on quality of solutions using pax; and (v) providing expected value bounds on the quality of solutions using vax.
this paper presents four algorithms spider, spider-abs, pax and vax that provide a novel combination of features for  policy search in distributed pomdps: (i) exploiting agent interaction structure given a network of agents (i.e.
