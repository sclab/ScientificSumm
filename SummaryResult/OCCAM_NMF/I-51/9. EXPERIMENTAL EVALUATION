finally, the fact that both data sets show a significant improvement points out the adaptive nature of the argumentation-based approach to learning from  communication: the useful cases are selected as counterexamples (and no more than those needed), and they have the intended effect. 
in the soybean data set more counterexamples are learnt to significantly improve individual accuracy, namely they  retain 87.16 cases in average (compared to 55.27 cases retained if they do not learn from communication).
the number of cases learnt from communication depends on the properties of the data set: in the sponges data set, agents have retained only very few additional cases, and significantly  improved individual accuracy; namely they retain 59.96 cases in  average (compared to the 50.4 cases retained if they do not learn from communication).
for instance, in the soybean data set, individual agents have achieved an accuracy of 70.62% when they also learn from communication versus an  accuracy of 59.93% when they only learn from their individual  experience.
figure 6 shows that if an agent ai learns also from  communication, ai can significantly improve its individual performance with just a small number of additional cases (those selected as relevant counterexamples for ai during argumentation).
they learn both from training examples and counterexamples).
figure 6 contains three plots, where nl (not learning) shows accuracy of an agent with no learning at all; l (learning), shows the evolution of the individual classification accuracy when agents learn by retaining the training cases they individually  receive (notice that when all the training cases have been retained at 100%, the accuracy should be equal to that of figure 5 for  individual agents); and finally lfc (learning from communication) shows the evolution of the individual classification accuracy of learning agents that also learn by retaining those counterexamples received during argumentation (i.e.
figure 6 shows the result of that experiment for the two data sets.
concerning h2 (learning from communication in argumentation processes improves individual prediction ), we ran the following experiment: initially, we distributed a 25% of the training set among the five agents; after that, the rest of the cases in the training set is sent to the agents one by one; when an agent receives a new  training case, it has several options: the agent can discard it, the agent can retain it, or the agent can use it for engaging an argumentation process.
these  experimental results show that amal effectively exploits the opportunity for improvement: the accuracy is higher only because more agents have changed their opinion during argumentation (otherwise they would achieve the same result as voting).
the  reason is that the soybean data set is more difficult (in the sense that agents need more data to produce good predictions).
moreover, the improvement achieved by amal over voting is even larger in the soybean data set.
for instance, the joint accuracy for 2 agents in the sponge data set is of 87.57% for amal and 86.57% for voting (while individual accuracy is just 80.07%).
we can also see that amal always outperforms standard voting, proving that joint decisions are based on better information as provided by the argumentation process.
moreover, as we expected, the accuracy improves as more agents collaborate, since more  information is taken into account.
figure 5 shows that collaboration (voting and amal)  outperforms individual problem solving.
the results shown are the average of 5 10-fold cross validation runs.
the individual bar shows the average accuracy of individual agents  predictions; the voting bar shows the average accuracy of the joint prediction achieved by voting but without any argumentation; and finally the amal bar shows the average accuracy of the joint  prediction using argumentation.
for each number of agents, three bars are shown: individual, voting, and amal.
classification accuracy is plotted in the  vertical axis, and in the horizontal axis the number of agents that took part in the argumentation processes is shown.
figure 5 shows the result of those experiments in the sponge and soybean data sets.
concerning h1 (argumentation is a useful framework for joint deliberation), we ran 4 experiments, using 2, 3, 4, and 5 agents respectively (in all experiments each agent has a 20% of the training data, since the training is always distributed among 5 agents).
moreover, we also expect that the improvement achieved from  argumentation will increase as the number of agents participating in the  argumentation increases (since more information will be taken into account).
the experiments are designed to test two hypotheses: (h1) that argumentation is a useful framework for joint deliberation and can improve over other typical methods such as voting; and (h2) that learning from communication improves the individual performance of a learning agent participating in an argumentation process.
in the testing stage, problems in the test set arrive randomly to one of the agents, and their goal is to predict the correct solution.
there is no example shared by two agents.
the training set examples are distributed among 5 different agents without replication, i.e.
in an experimental run, the data set is divided in 2 sets: the training set and the test set.
the soybean data set has 307 examples and 19 solution classes, while the sponge data set has 280 examples and 3 solution classes.
we have made experiments in two different data sets: soybean (from the uci machine learning repository) and sponge (a relational data set).
in this section we empirically evaluate the amal argumentation framework.
on autonomous agents and multi-agent systems (aamas 07) sponge 75 77 79 81 83 85 87 89 91 2 3 4 5 amal voting individual soybean 55 60 65 70 75 80 85 90 2 3 4 5 amal voting individual figure 5: individual and joint accuracy for 2 to 5 agents.
joint conf.
980 the sixth intl.
