3. if no counterexamples are found, then ai cannot rebut the argument α. 
2. if not found, then ai searches for a counterexample c ∈ ci of α. if a case c is found, then c is sent to the other agent as a counterexample of α.
specifically, in our experiments, when an agent ai wants to rebut an argument α, uses the following policy: 1. agent ai uses lid to try to find a counterargument β more specific than α; if found, β is sent to the other agent as a counterargument of α.
on autonomous agents and multi-agent systems (aamas 07) solution: hadromerida justification: d1 sponge spikulate skeleton external features external features gemmules: no spikulate skeleton megascleres uniform length: no megascleres smooth form: tylostyle case base of a1 lid new sponge p figure 3: example of a real justification generated by lid in the marine sponges data set.
joint conf.
moreover, figure 4 shows the generation of a counterargument β1 2 for the argument α0 1 (in figure 3) that is a specialization of α0 1.
978 the sixth intl.
figure 4 shows how an agent a2 that disagreed with the argument shown in  figure 3, generates a counterargument using lid.
in this way, the justification provided by lid will always be subsumed by α.d, and thus the resulting counterargument will be more specific than α. however, notice that lid may sometimes not be able to generate counterarguments, since lid may not be able to specialize the description α.d any further, or because the agent ai has no case inci that is subsumed by α.d.
to generate a counterargument to an argument α lid just has to use as starting point the description α.d instead of starting from scratch.
when the description covers only (or almost only) cases of a  single solution class lid terminates and predicts that solution class.
thus, at every step, the description is made more specific than in the previous step, and the number of cases that are subsumed by that description is reduced.
for instance, lid is an algorithm that generates a description starting from scratch and heuristically adding features to that term.
the generation of counterarguments using the specificity  criterion imposes some restrictions over the learning method, although lid or id3 can be easily adapted for this task.
α.d < β.d).
thus, in our framework, when an agent wants to generate a  counterargument β to an argument α, β has to be more specific than α (i.e.
thus, the agent generating the  counterargument should constantly communicate with the other agents at each step of the induction algorithm used to generate  counterarguments (presently one of our future research lines).
moreover, one may think that it would be better that the agents generate counterarguments based on the joint confidence preference relation; however it is not obvious how to generate counterarguments based on joint  confidence in an efficient way, since collaboration is required in order to evaluate joint confidence.
however, there is no guarantee that such counterarguments will always win, since, as we have stated in section 5, agents in our framework use a  preference relation based on joint confidence.
thus, counterarguments generated based on the specificity criterion are expected to be preferable (since they are more informed) to the arguments they try to rebut.
the specificity criterion is widely used in deductive frameworks for argumentation, and states that between two conflicting  arguments, the most specific should be preferred since it is, in  principle, more informed.
moreover, while generating such counterargument β, ai  expects that β is preferred over α. for that purpose, we will present a specific policy to generate counterarguments based on the  specificity criterion [10].
an agent ai wants to generate a counterargument β to rebut an argument α when α is in contradiction with the local case base of ai.
let us  explain how they can be generated.
6.1 generation of counterarguments as previously stated, agents may try to rebut arguments by  generating counterargument or by finding counterexamples.
thus, the argument generated will be α = a1, p, hadromerida, d1 .
the justification shown in figure 3 can be  interpreted saying that the predicted solution is hadromerida  because the smooth form of the megascleres of the spiculate  skeleton of the sponge is of type tylostyle, the spikulate skeleton of the sponge has no uniform length, and there is no gemmules in the  external features of the sponge.
in particular, figure 3 shows how when an agent receives a new problem to solve (in this case, a new sponge to determine its order), the agent uses lid to generate an argument (consisting on a justified prediction) using the cases in the case base of the agent.
thus, when an agent wants to generate an argument  endorsing that a specific solution class is the correct solution for a problem p, it generates a justified prediction as explained in section 3.1. for instance, figure 3 shows a real justification generated by lid after solving a problem p in the domain of marine sponges identification.
specifically, in the experiments reported in this paper agents use lid.
for instance, decision trees and lid [2] are suitable learning methods.
any learning method able to  provide a justified prediction can be used to generate arguments.
in our framework, arguments are generated by the agents from cases, using learning methods.
