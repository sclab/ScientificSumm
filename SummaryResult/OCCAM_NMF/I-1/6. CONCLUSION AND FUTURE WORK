any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of darpa or the department of interior-national business center. 
the work of the two authors at sri international was supported by the defense advanced research projects agency (darpa) under contract no.
the first author acknowledges the support of the australian research  council and agent oriented software under grant lp0453486.
acknowledgements we thank lin padgham and the anonymous reviewers for their comments.
for such goals a different  operational semantics for abort is necessary than for achievement goals, to match the difference in semantics of the goals themselves.
a further item of interest is extending our approach to failure and abort to maintenance goals [1].
however, this is an issue worthy of further  exploration, either to develop weaker assumptions that are also  practical, or to analyze conditions under which our assumption is  realistic.
our assumption that abort-methods do not fail, as discussed above, is a pragmatic one.
this would in particular influence the commitment the agent has towards a  particular task: the higher the cost, the greater the commitment.
related to this is determining the cost of aborting a task or plan, and using this as an input to the deliberation process.
future work is to place our approach in service of more dynamic agent reasoning, such as the introspection that an agent capable of  reasoning over task interaction effects and resource requirements can accomplish [19, 12].
we have assumed the default  behaviour of a bdi-style agent, according to its nature: for instance, to retry alternatives to a failed plan until one succeeds or until no alternative plans remain (in which case to fail the task).
an intelligent agent will not only gracefully handle unsuccessful tasks and plans, but also will deliberate over its cognitive attitudes to decide its next course of action.
we are also developing an analysis tool for our extended version of can as a basis for experimentation.
we are planning to implement an instance of our approach in the spark agent system [9]; in particular, the work of this paper will be the basis for spark"s abort handling mechanism.
our primary contribution is an analysis of the requirements on the operation of the agent for aborting tasks and plans, and a corresponding operational semantics for aborting in the abstract agent language can.
in this paper we have presented a procedure-based approach that incorporates aborting tasks and plans into the  deliberation cycle of a bdi-style agent, thus providing a unified approach to failure and abort.
the tasks and plans of an agent may not successfully reach  completion, either by the choice of the agent to abort them (perhaps at the request of another agent to do so), or by unbidden factors that lead to failure.
