we could, for example, allow the user to dynamically modify terms in a  language model learned from feedback documents. 
we are also interested in studying how to combine term feedback with relevance feedback or implicit feedback.
third, we have plans to incorporate term feedback into our ucair toolbar[20], an internet explorer plugin, to make it work for web search.
the presented terms should be selected dynamically to maximize learning benefits at any moment.
we could instead consider  iterative term feedback, by presenting a small number of terms first, and show more terms after receiving user feedback or stop when the refined query is good enough.
second, currently all terms are presented to the user in a single batch.
first, we want to study whether the use of various contexts can help the user to better identify term relevance, while not sacrificing the simplicity and compactness of term feedback.
we propose to extend our work in several ways.
we regarded term feedback as a viable alternative to traditional relevance feedback, especially when there are no relevant documents in the top.
finally, we compared term feedback to document-level relevance  feedback, and found that tcfb3c"s performance is on a par with the latter with 5 feedback documents.
when we reduced the number of presentation terms, term feedback is still able to keep much of its performance gain over the baseline.
we found the best-performing algorithm to be tcfb, which  benefits from the combination of directly observed term evidence with tfb and indirectly learned cluster relevance with cfb.
we saw significant improvement in retrieval  accuracy brought by term feedback, in spite of the fact that a user often makes mistakes in relevance judgment that hurts its performance.
we proposed a cluster-based method for selecting presentation terms as well as algorithms to estimate refined query models from user term feedback.
in this paper we studied the use of term feedback for  interactive information retrieval in the language modeling approach.
