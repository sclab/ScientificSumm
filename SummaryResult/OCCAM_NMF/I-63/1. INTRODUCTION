following the discussion of our experimental results on a job-scheduling problem in  section 5, we conclude in section 6 with a discussion of possible extensions and generalizations of our method. 
in the rest of the paper, we first lay down the necessary groundwork in section 2 and then introduce our model and formal problem statement in section 3. in section 4.2, we describe our main result, the optimization program for  globally optimal resource scheduling.
we analyze and empirically compare two flavors of the scheduling problem: one, where agents have static resource assignments within their finite-horizon mdps, and another, where resources can be dynamically reallocated between agents at every time step.
in this context, our main contribution is a  mixed-integerprogramming formulation of the scheduling problem that chooses globally optimal resource assignments, starting times, and execution horizons for all agents (within their  arrival1220 978-81-904262-7-5 (rps) c 2007 ifaamas departure intervals).
we address the problem of globally optimal resource scheduling, where the objective is to find an allocation of resources to the agents across time that maximizes the sum of the expected rewards that they obtain.
in particular, agents arrive and depart at arbitrary (predefined) times and within these intervals use resources to execute tasks in finite-horizon mdps.
in this paper, we extend the work on resource allocation under mdp-induced preferences to discrete-time scheduling problems, where agents are present in the system for finite time intervals and can only use resources within these  intervals.
this assumption that no reallocation of resources is possible can be limiting in domains where agents arrive and depart dynamically.
however, this existing work on resource allocation with preferences induced by resource-parameterized mdps makes an assumption that the resources are only allocated once and are then utilized by the agents independently within their infinite-horizon mdps.
this representation can then be used to construct very efficient resource-allocation algorithms that lead to an exponential speedup over a straightforward  optimization problem with flat representations of combinatorial preferences [6, 7, 8].
in particular, if an agent uses resources to act in a stochastic environment, its utility function can be naturally modeled with a markov decision process, whose action set is parameterized by the available resources.
a way of accomplishing this is to model the processes by which an agent might utilize the resources and define the utility function as the payoff of these processes.
an alternative is to directly model the mechanisms that define the agents" utility functions and perform resource allocation directly with these models [9].
one idea is to use any structure present in utility functions to represent them compactly, via, for example,  logical formulas [15, 10, 4, 3].
such computational issues have recently spawned several threads of work in using compact models of agents"  preferences.
further, even when each agent has a utility function that is nonzero only on a small subset of the possible resource bundles, obtaining optimal allocation is still computationally prohibitive, as the problem becomes np-complete [14].
in particular, when the value of a set of resources to an agent is not additive (as is often the case with resources that are substitutes or complements), the utility function might have to be defined on an exponentially large space of resource bundles, which very quickly becomes  computationally intractable.
the tasks of optimal resource allocation and scheduling are ubiquitous in multiagent systems, but solving such  optimization problems can be computationally difficult, due to a number of factors.
