analogous to dids, i-dids may be used to compute the policy of an agent online as the agent acts and observes in a setting that is populated by other interacting agents. 
solution to the i-did is a policy that prescribes what the agent should do over time, given its beliefs over the physical state and others" models.
we show how  idids may be used to model an agent"s uncertainty over others" models, that may themselves be i-dids.
the net result is a representation of i-did that is significantly more transparent, semantically clear, and capable of being implemented using the standard algorithms for solving dids.
we explicate the semantics of this link by  showing how it can be implemented using the traditional dependency links between the chance nodes that constitute the model nodes.
in the previous representation of the i-did, the update of the agent"s belief over the models of others as the agents act and receive observations was denoted using a  special link called the model update link that connected the model nodes over time.
furthermore, we clarify the semantics of the special purpose policy link introduced in the representation of i-did by [15], and show that it could be replaced by traditional dependency links.
thus, we may utilize nid-specific language constructs such as multiplexers to represent the model node, and subsequently the i-id, more transparently.
in this paper, we improve on the previous preliminary  representation of the i-did shown in [15] by using the insight that the static i-id is a type of nid.
both, other agents" models and the original agent"s beliefs over these models are updated over time using special-purpose implementations.
i-dids address this gap by allowing the representation of other agents" models as the values of a special model node.
matters are more complex when we consider interactions that are extended over time, where predictions about others" future actions must be made using models that change as the agents act and observe.
however, maids provide an analysis of the game from an external viewpoint and the  applicability of both is limited to static single play games.
graphical formalisms such as maids and nids open up a promising area of research that aims to represent  multiagent interactions more transparently.
each model is a maid and the network of maids is collapsed, bottom up, into a single maid for  computing the equilibrium of the game keeping in mind the different  models of each agent.
nids extend maids to include agents" uncertainty over the game being played and over models of the other agents.
maids objectively  analyze the game, efficiently computing the nash equilibrium profile by exploiting the independence structure.
maids provide an alternative to normal and extensive game forms using a graphical formalism to represent games of imperfect information with a decision node for each agent"s actions and chance nodes capturing the agent"s private information.
these formalisms seek to explicitly model the structure that is often present in real-world problems by decomposing the situation into chance and decision variables, and the dependencies between the variables.
i-dids contribute to a growing line of work [19] that includes multi-agent influence diagrams (maids) [14], and more recently, networks of influence diagrams (nids) [8].
i-dids generalize dids [12], which may be viewed as computational counterparts of pomdps, to  multiagents settings in the same way that i-pomdps generalize pomdps.
in [15], polich and gmytrasiewicz introduced interactive  dynamic influence diagrams (i-dids) as the computational  representations of i-pomdps.
i-pomdps adopt a subjective approach to  understanding strategic behavior, rooted in a decision-theoretic framework that takes a decision-maker"s perspective in the interaction.
the models encompass all information  influencing the agents" behaviors, including their preferences,  capabilities, and beliefs, and are thus analogous to types in bayesian games [11].
they generalize pomdps [13] to multiagent settings by including the other agents" computable models in the state space along with the states of the physical environment.
interactive partially observable markov decision processes  (ipomdps) [9] provide a framework for sequential decision-making in partially observable multiagent environments.
