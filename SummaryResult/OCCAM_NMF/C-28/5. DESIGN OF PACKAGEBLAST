this flow continues until all segments are processed. 
then, the master sends a xml message to the slave  informing its new segments to process.
the slave processes τ database segments and notifies the master, which uses the last ω notifications to compute the next allocation block size based on the  selected allocation strategy and the weight provided by pss.
after receiving connections from the slaves, the master notifies them about their initial  segments to compare.
to start processing, a minimum number of slaves must register into the master node, by  calling a master grid service.
the master node starts execution and waits for slave connections.
the user specifies the sequence to be compared and chooses the allocation strategy.
in general, the following execution flow is executed.
finally, the module generate reports obtains the  intermediary outputs sent by the slave nodes through file transfer and merges them into a single blast output report.
it distributes the work units generated by the previous module and collects the notifications.
distribute work units is the module responsible for the communication between the master and slaves nodes.
it calculates the weight of each slave node and decides how many work units will be assigned to a particular slave node, according to the chosen allocation policy.
the module generate work units is the core of the pss mechanism.
the module allocation strategies contains  implementations for the pre-defined allocation policies (fixed, ss, gss, tss and fac2) and also makes possible the creation of new allocation strategies.
blast receives master strategies allocation work units generate work units distribute reports generate work units (to slaves)reports searches figure 3: packageblast architecture.
figure 3 presents the packageblast architecture.
γ(m, pi, ω) = min(ω,k) j=1 t e(m, pi, τ) min(ω, k) (13) 5.3 packageblast"s general architecture packageblast was designed as a grid service over globus 3, based on web services and java.
at the moment of computation of γ, if there is not enough notifications of te, the calculation is done with total k notifications already received.
φ(m, pi, p ) = p ∗ p i=1 γ(m,pi,ω) γ(m,pi,ω) p i=1 p i=1 γ(m,pi,ω) γ(m,pi,ω) (12) γ(m, pi, ω) (equation 13) specifies the average computing time of a segment in a node pi, considering the last ω  notifications of te(m, pi, τ), which is the average computation time of τ work units (database segments) assigned by the master m to a slave pi.
the expression used is φ(m, pi, p) (equation 12), defined as the weighted mean from the last ω notifications sent by each pi slave node.
158 allocate(m, pi, n, p ) = a(n, p ) ∗ φ(m, pi, p ) (11) to distribute database segments to nodes, the master  analyzes periodic slave notifications.
a(n, p) can be a pre-defined allocation policy or a user-defined one.
the expression used for work unit allocation is shown in equation 11, where a(n, p) is the allocation policy for a  system with n workload units and p nodes and φ(m, pi, p) is the weight calculated by pss.
considering the heterogeneity and dynamic characteristics of the grid, pss is able to modify the length of the work units during execution, based on average processing time of each node.
besides that, we propose pss (package weighted  adaptive self-scheduling), a new strategy that adapts the chosen allocation policy to a grid with local workload.
by now, our framework contains five allocation policies: fixed, ss, gss, tss, fac2, all described in  section 3. so, the user can choose or even create the allocation policy which is the most appropriate to his/her environment and his/her blast parameters.
thus, we propose the use of a framework where many allocation policies can be  incorporated.
5.2 task allocation as [13], we think that no allocation policy will produce the best results for every situation.
figure 2 illustrates this.
we opted to replicate the segmented database in every slave grid node to improve data accesses times and to  provide a potential for fault tolerance.
just as in mpiblast (section 4), we decided to use database segmentation in packageblast with an ncbi tool called formatdb, which was modified to generate more database segments of smaller size.
also, a single query sequence can be compared against all segments in parallel.
it enables grid nodes to search smaller parts of a sequence database, reducing the number of disk accesses and hence improving blast performance.
5.1 database segmentation and replication segmentation consists in the division of a database archive in many portions of smaller size, called segments, that can be processed independently.
we also propose a strategy to compute grid nodes execution weight which distributes work units (database segments) to grid nodes according to their current computational power.
the framework, called  packageblast, provides an infrastructure to choose or incorporate allocation strategies in a master/slave application.
we propose an adaptive task allocation framework which is a grid service to perform blast searches against  sequence database segments.
