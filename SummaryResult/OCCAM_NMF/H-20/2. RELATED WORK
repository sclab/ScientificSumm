we use statistical analysis to reveal the fact and use it to improve ned performance.
in their work, effectiveness of different kinds of names (or terms with different pos) for ned in different news classes are not investigated.
for example, word election does not help identify different elections.
in [10] frequent terms for each class are removed from document representation.
in [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for ned for each class.
both [10] and [13] used text categorization technique to classify news stories in advance.
and it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.
umass [13] research group split document representation into two parts: named entities and non-named entities.
doremi research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].
gave location named entities four times weight than other terms and named entities [10].
yang et al.
some efforts have been done on how to utilize named entities to improve ned.
a marginal increase in effectiveness was achieved when the combined representation was used.
then the two representations are combined in a linear fashion.
one of the representations was the usual free text vector, the other made use of lexical chains (created using wordnet) to build another term vector.
[9] utilized a combination of evidence from two distinct representations of a document"s content.
stokes et al.
good improvements on tdt bench-marks were shown.
[8] extended a basic incremental tf-idf model to include  sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.
brants et al.
recent years, most work focus on proposing better methods on comparison of stories and document representation.
in this manner comparisons happen between stories and clusters.
lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].
if the document did not trigger any queries by exceeding a threshold, it was marked as a new event.
then it was compared with all the previous queries.
when a new story was encountered, it was processed immediately to extract term features and a query representation of the story"s content is built up.
proposed single-pass clustering on ned [6].
papka et al.
