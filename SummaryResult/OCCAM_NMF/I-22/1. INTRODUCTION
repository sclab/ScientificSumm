section 4 describes the key concept shared belief map as implemented in smmall, and section 5 reports the experiments for evaluating the cognitive models and their impacts on the evolving of shared mental models. 
a hmm-based cognitive load model is given in section 3 to support resource-bounded teamwork among  human-agentpairs.
in section 2 we review cognitive load theories and measurements.
the rest of the paper is organized as follows.
if agents could make recommendations in ways that humans appreciate, it would be easier to establish trust relationships between agents and humans; this in turn, will encourage humans" automation uses.
many studies have documented that human choices and behaviors do not agree with predictions from rational models.
when its  human peer is underloaded, an agent can take the chance to observe the human"s operations to refine its cognitive model of the human.
when its human peer is  becoming overloaded, an agent can take over resource-consuming tasks, shifting the human"s limited cognitive resources to tasks where a human"s role is indispensable.
with a realistic human cognitive model, an agent can also better adjust its automation level.
it is feasible to develop agents as cognitive aids to  alleviate humans" biases, as long as an agent can be trained to obtain a model of a human"s cognitive inclination.
for example, although humans" use of cognitive simplification mechanisms (e.g., heuristics) does not always lead to errors in judgment, it can lead to predictable biases in responses [8].
although an agent"s cognitive model of its human peer is not necessarily to be descriptively accurate, having at least a realistic model can be beneficial in offering unintrusive help, bias  reduction, as well as trustable and self-adjustable autonomy.
the last point is on the modeling itself.
ideally, being able to predict the  cognitive/processing capacity curves of teammates could allow a team member to help the right party at the right time, avoiding unbalanced work/cognitive loads among the team.
in particular, we argue that to favor  humanagent collaboration, an agent system should be designed to allow the estimation and prediction of human teammates" (relative) cognitive loads, and use that to offer improvised, unintrusive help.
while the long-term goal of our research is to understand how shared cognitive structures can enhance human-agent team performance, the specific objective of the work reported here is to develop a computational cognitive 395 978-81-904262-7-5 (rps) c 2007 ifaamas capacity model to facilitate the establishment of shared  expectations.
it has to be noted that the concept of shared expectation can broadly include role assignment and its dynamics,  teamwork schemas and progresses, communication patterns and intentions, etc.
we agree on this and believe that the establishment of shared  expectations among human and agent team members is a critical step to advance human-centered teamwork research.
[14] explicitly argue that team members should hold compatible models that lead to common expectations.
cannon-bowers et al.
cognitive studies suggested that teams which have shared mental models are expected to have  common expectations of the task and team, which allow them to predict the behavior and resource needs of team  members more accurately [14, 6].
one of the drawbacks is that, although both have a deep philosophical and  cognitive root, they do not accommodate the modeling of  human team members.
for instance, joint intention [3] and sharedplans [5] are two theoretical frameworks for specifying agent collaborations.
there are lines of research on multi-agent teamwork, both theoretically and empirically.
therefore, there is a clear demand for investigations to broaden and deepen our understanding on the principles of shared mental  modeling among members of a mixed human-agent team.
although groups also can create additional costs centered on communication, resolution of conflict, and social acceptance, it is suggested that such limitations can be overcome if people have shared cognitive structures for  interpreting task and social requirements [8].
many informational processing limitations of individuals can be alleviated by having a group perform tasks.
moreover, human-agent relationships can go beyond partners to teams.
in particular, few researchers look beyond to assess the principles of modeling shared mental constructs between a human and his/her  assisting agent.
however, the foundation of human-agent collaboration keeps being challenged because of nonrealistic modeling of mutual awareness of the state of affairs.
in short, humans and agents can team together to achieve better  performance, given that they could establish certain mutual awareness to coordinate their mixed-initiative activities.
humans and autonomous systems (agents) are generally thought to be  complementary: while humans are limited by their cognitive capacity in information processing, they are superior in spatial,  heuristic, and analogical reasoning; autonomous systems can  continuously learn expertise and tacit problem-solving  knowledge from humans to improve system performance.
human-centered  multiagent teamwork has thus attracted increasing attentions in multi-agent systems field [2, 10, 4].
the entire movement of agent paradigm was spawned, at least in part, by the perceived importance of fostering human-like adjustable autonomy.
