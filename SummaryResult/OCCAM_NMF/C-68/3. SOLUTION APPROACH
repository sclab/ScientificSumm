in such cases, even though a car may meet a requesting client earlier than other servers, if its local storage  contains data items with only a single copy in the system, then such a car is not chosen as a zebroid. 
in other words, at least one replica of every data item is maintained in the ad-hoc network at all times.
note that the dispatchers with the help of the control plane may ensure that no data item is lost from the system.
the metrics considered in this study are aggregate availability  latency, δagg, percentage improvement in δagg with zebroids as  compared to the no-zebroids case and average number of replacements incurred per client request which is an indicator of the overhead incurred by zebroids.
note that in the no-zebroids case neither overhead is incurred.
third, the average number of replacements incurred by the zebroids.
second, the bandwidth used to transfer a copy of a data item from a server to the zebroid.
first, the complexity associated with the implementation of a policy.
the replacement policies incur the following overheads.
we have considered local and global variants of the lru/lfu policies which determine whether local or global knowledge of contents of the cars known at the dispatcher is used for the eviction decision at a zebroid (see [9] for more details).
the carrier-based replacement policies employed in our study are least recently used (lru), least frequently used (lfu) and random (where a eviction candidate is chosen  uniformly at random).
this decision process is analogous to that encountered in operating system paging where the goal is to maximize the cache hit ratio to prevent disk access  delay [18].
for this purpose, the zebroid must  select an appropriate candidate for eviction.
when the local storage of a zebroid is completely occupied, it needs to replace one of its existing items to carry the client requested data item.
3.2 carrier-based replacement policies the replacement policies considered in this paper are reactive since a replacement occurs only in response to a request issued for a certain data item.
eventually, majority of the storage capacity of a car will be  exhausted.
new replicas are created as long as a car has a certain threshold of its storage unoccupied.
the selection procedure may be to choose the data items uniformly at random.
when the cars encounter one another they construct new replicas of some selected data items to occupy the empty slots.
many storage slots of the cars may be unoccupied.
one may assume a cold start phase, where initially only one or few copies of every data item exist in the system.
we quantify the performance of the various replacement policies with reference to this base-line that does not employ zebroids.
hence, this is referred to as the  ‘nozebroids" environment.
it is static because number of replicas in the system do not change and no replacements are performed.
initially, number of replicas for each data item replicas might be computed using equation 1. this scheme computes the number of data item replicas as a function of their popularity.
this remains a future research  direction.
large data items may be divided into smaller chunks enabling the dispatcher to schedule one or more zebroids to deliver each chunk to a client in a timely manner.
with small data items, it is reasonable to assume that this transfer time is small, especially in the presence of the high bandwidth data plane.
the time required to transfer a data item from a server to a  zebroid depends on its size and the available link bandwidth.
this may incur additional overhead due to redundant resource utilization to obtain the same latency improvements.
to minimize the likelihood of such scenarios, the dispatcher may schedule  multiple zebroids.
hence, a zebroid scheduled on the basis of this inaccurate information may not rendezvous with its target client.
in some cases, the dispatcher might have inaccurate information about the routes of the cars.
such a  zebroid is termed one-instantaneous zebroid.
a simple instantiation of z-relay zebroids occurs when z = 1 and the client"s request triggers a transfer of a copy of the requested data item from a server to a zebroid in its vicinity.
note that the latency along the quickest delivery path that employs a relay team of z zebroids is similar to that obtained with epidemic routing [19] under the assumptions of infinite storage and no interference.
hence, it determines the optimal set of forwarding decisions 76 that will enable the data item to be delivered to the client in the minimum amount of time.
using this  information, the dispatcher schedules the quickest delivery path from any of the servers to the client using any other cars as intermediate  carriers.
next, the dispatcher obtains the future routes of all cars for a finite time duration equivalent to the maximum time the client is willing to wait for its request to be serviced.
3.1 zebroids when a client references a data item missing from its local  storage, the dispatcher identifies all cars with a copy of the data item as servers.
