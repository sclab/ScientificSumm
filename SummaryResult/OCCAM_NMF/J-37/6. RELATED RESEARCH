promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed.
third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.
second, a large amount of expert knowledge and effort was used in constructing the abstraction.
first, it is highly specialized for texas hold"em.
however, this approach has significant drawbacks.
most notably, billings et al [4] describe a manually constructed abstraction for texas hold"em poker, and include promising results against expert players.
there has been some research on the use of abstraction for imperfect information games.
however, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of  imperfect information, such as poker.8 another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.
partition search can lead to substantial speed improvements over α-β-search.
(typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)
in contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar.
one of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind gib, the world"s first  expertlevel computer bridge player [17, 18].
however, a significant difference to our work is that sprouts is a game of perfect information.
a notable exception is the use of abstraction to compute optimal strategies for the game of sprouts [2].
furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield  optimal solutions.
[20, 32]).
in contrast to our work, most (but not all) research involving abstraction has been for  singleagent problems (e.g.
abstraction techniques have been used in artificial  intelligence research before.
also, their paper does not provide algorithms.
our focus is totally  different: we find strategically equivalent smaller games.
however, that definition requires that the games to be tested for weak isomorphism are of the same size.
indeed, the author shows, among other things, that many solution concepts, including nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.
the motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.
the recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game  isomorphism.
6], [10].
modern treatments of this prior work on game transformations exist [38, ch.
an extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].
the pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of  strategies [27].
the main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.
in contrast to our work, those  approaches were not for making the game smaller and easier to solve.
functions that transform extensive form games have been introduced [50, 11].
