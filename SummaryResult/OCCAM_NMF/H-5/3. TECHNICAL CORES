the anti-redundancy threshold t is tuned on a training set. 
after applying the above-mentioned algorithm, each passage in the new list is sufficiently dissimilar to others, thus favoring diversity rather than redundancy in the new ranked list.
3. repeat step 2 until all the passages in the current list have been examined.
2. add the next passage x in the current list to the new list only if far(x) > t where far(x) = 1 − max pi∈lnew {cos(x, pi)} and lnew is the set of passages already selected in the new list.
our procedure starts with the current list of passages sorted by relevance (section 3.2), filtered by novelty detection component (section 3.3), and generates a new non-redundant list as follows: 1. take the top passage in the current list as the top one in the new list.
we use a simplified version of the maximal marginal relevance method [5], originally developed for combining relevance and novelty in text retrieval and summarization.
hence, a ranked list should also be made non-redundant with respect to its own contents.
however, multiple news sources would report this news and we might end up showing (redundant) articles from all these sources in a ranked list.
a new piece of news that the award has been increased to $200,000 is novel since the user hasn"t read about it yet.
suppose, for example, that the user has already read about a $100,000 reward for information about the escaped convicts.
3.4 anti-redundant ranking component although the novelty detection component ensures that only novel (previously unseen) information remains in the relevance list, this list might still contain the same novel information at multiple positions in the ranked list.
the novelty score of each passage is compared to a  prespecified threshold (also tuned on a training set), and any passage with a score below this threshold is removed from the relevance list.
3.3 novelty detection component caf´e maintains a user history h(t), which contains all the spans of text hi that the user highlighted (as feedback) during his or her past interactions with the system, up to the current time t. denoting the history as h(t) = n h1, h2, ..., ht o , (2) the novelty score of a new candidate passage x is computed as: fnd(x) = 1 − max i∈1..t {cos(x, hi)} (3) where both candidate passage x and highlighted spans of text hi are represented as tf-idf vectors.
the logistic regression solution w∗ as described in section 3.1, the system computes the posterior probability of relevance for each passage x as frl(x) ≡ p(y = 1|x, w∗ ) = 1 (1 + e−w∗·x) (1) passages are ordered by their relevance scores, and the ones with scores above a threshold (tuned on a training set) comprise the relevance list that is passed on to the novelty detection step.
given a query profile, i.e.
each passage is represented using a vector of tf-idf (term  frequencyinverse document frequency) weights, where term can be a word or a named entity.
then the documents are segmented into passages, which can be a whole document, a paragraph, a sentence, or any other continuous span of text, as preferred.
we use a state-of-the-art named entity identifier and tracker [8, 12] to identify person and location names, and merge them with co-referent named entities seen in the past.
for each incoming document, corpus statistics like the idf (inverted document frequency) of each term are updated.
incoming documents are processed in chunks, where each chunk can be defined as a fixed span of time or as a fixed number of documents, as preferred by the user.
3.2 passage retrieval component we use standard ir techniques in this part of our system.
a temporally decaying weight can be applied to each training example, as an option, to emphasize the most recent user feedback.
the query profile is updated whenever a new piece of user feedback is received.
the class model w∗ learned by logistic regression, or the query profile, is a vector whose dimensions are individual terms and whose elements are the regression coefficients, indicating how influential each term is in the query profile.
the details of using logistic regression for adaptive filtering (assigning different weights to positive and negative training instances, and regularizing the objective function to prevent over-fitting on training data) are presented in [21].
to address the cold start issue in the early stage before any user feedback is obtained, the system uses a small sample from a retrospective corpus as the initial negative examples in the training set.
for training the model, we use the query itself as the initial positive training example of the class, and the user-highlighted pieces of text (marked as relevant or not-relevant) during feedback as additional training examples.
in adaptive filtering, each query is considered as a class and the probability of a passage belonging to this class corresponds to the degree of relevance of the passage with respect to the query.
(see [21] and [23] for computational complexity and implementation issues).
its performance as well as efficiency in terms of training time makes it a good candidate when frequent updates of the class model are required, as is the case in adaptive filtering, where the system must learn from each new feedback provided by the user.
based on a training set of labeled instances, it learns a class model which can then by used to predict the labels of unseen instances.
logistic regression (lr) is a supervised learning algorithm for statistical classification.
3.1 adaptive filtering component we use a state-of-the-art algorithm in the field - the regularized logistic regression method which had the best results on several benchmark evaluation corpora for af [21].
the core components of caf´e are - 1) af for incremental learning of query profiles, 2) ir for estimating relevance of passages with respect to query profiles, 3) nd for assessing novelty of passages with respect to user"s history, and 4) anti-redundancy component to remove redundancy from ranked lists.
