Poisson distribution has been previously studied in the document generation models [16, 22, 3, 24], leading to the development of one of the most effective retrieval formula BM25 [23].
We show that  Poisson language model is natural to accommodate the per-term smoothing without heuristic twist of the semantics of a  generative model, and is able to efficiently better model the mixture background, both analytically and empirically. 
[24] studies the parallel derivation of three  different retrieval models which is related to our comparison of Poisson and multinomial.
Poisson mixtures [ 3 ] such as 2-Poisson [ 22 ] , Negative multinomial 