An ND-POMDP is similar to an n-ary Distributed Constraint Optimization Problem (DCOP)[8, 12] where the variable at each node represents the policy selected by an individual agent, πi with the domain of the variable being the set of all local policies, Πi.
, ωn ∈ Ω is the observation received in state s. This implies that each agent"s observation depends only on the  unaffectable state, its local action and on its resulting local state.
Si refers to the set of local states of agent i and Su is the set of unaffectable states.
Ω = ×1≤i≤nΩi is the 