In the case of learning a ranked retrieval function, X  denotes a space of queries, and Y the space of (possibly weak) rankings over some corpus of documents C = {d1, .
For instance, with h1(q), a threshold  between documents 1 and 2 gives 4 errors (documents 6-9  incorrectly classified as non-relevant), yielding an accuracy of 0.64.
Table 3 shows the predictions of the two hypotheses on a single query x. Hypothesis MAP Best Acc.
We can define average precision loss as ∆map ( y , ˆy ) = 1 − MAP ( rank ( y ) , rank ( ˆy 