The approach here is to sum the difference between the real value of a state to the maximal Q-value of this state if resource res cannot be used for all states in a trajectory given by the  policy of task ta.
As discussed by Singh and Cohn [10], this type of  algorithm has a number of desirable anytime characteristics: if an action has to be picked in state s before the algorithm has converged (while multiple competitive actions remains), the action with the highest lower bound is picked.
The global Q-value is the sum of the Q-values produced by 