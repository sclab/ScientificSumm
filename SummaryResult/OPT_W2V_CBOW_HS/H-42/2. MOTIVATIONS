If we could identify a relatively small number of topics which were really good at distinguishing effective and ineffective systems, we could save considerable effort in evaluating systems.
The first of these hypotheses needs no further justification - every reported significant difference between any two  systems supports it.
The third might be regarded as being of purely academic interest;  however, the fourth has the potential for being of major  practical importance in evaluation studies.
However, in the present paper, we seek instead to explore the  relationships suggested by the hypotheses, between what different topics tell us about systems and what different systems tell us about topics.
There is now also quite a lot of evidence for the second, centered on the TREC Robust Track [14].
We seek methods of building and analysing a matrix of system-topic normalised performances, with a view to giving insight into the issue and confirming or  refuting the third and fourth hypotheses.
Some systems are better than others at distinguishing easy and difficult topics; 4.
One possible direction from this point would be to attempt direct identification of such small sets of topics.
It turns out that the obvious symmetry implied by the above formulation of the hypotheses is a property worth investigating, and the investigation does indeed give us valuable insights. 
Some topics are easier than others; 3.
Our primary interest is in the third and fourth.
Some topics are better than others at distinguishing more or less effective systems.
We are interested in the following hypotheses: 1.
Some systems are more effective than others; t1 · · · tn MAP s1 AP(s1, t1) · · · AP(s1, tn) MAP(s1) ... ... ... sm AP(sm, t1) · · · AP(sm, tn) MAP(sm) AAP AAP(t1) · · · AAP(tn) (a) t1 t2 · · · MAP s1 0.5 0.4 · · · 0.6 s2 0.4 · · · · · · 0.3 ... ... ... ... AAP 0.6 0.3 · · · (b) Table 1: AP, MAP and AAP 2.
