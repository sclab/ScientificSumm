The  possibility to make commitments distinguishes cooperative from  noncooperative game theory [4, 6].
On a more formal level, threats have also figured in bargaining theory.
Commitments have by no means gone unnoticed (see, ⎡ ⎢⎢⎢⎢⎣ (1, 3) (3, 2) (0, 0) (2, 1) ⎤ ⎥⎥⎥⎥⎦ Figure 1: Committing to a dominated strategy can be  advantageous.
Also, commitments have played a  significant role in the theory of equilibrium selection (see, e.g., [13].
Informally, Schelling [9] has emphasized the importance of promises, threats and the like for a proper understanding of social interaction.
Commitment is a central concept in game theory.
Leadership games, as mentioned in the introduction, analyze commitments to pure or mixed  strategies in what is essentially a two-player setting [15, 16].
Recently, also the strategic aspects of commitments have attracted the attention of computer scientists.
Thus, Conitzer and Sandholm [2] have studied the computational complexity of computing the optimal strategy to commit to in normal form and Bayesian games.
Sandholm and Lesser [8] employ levelled  commitments for the design of multiagent systems in which  contractual agreements are not fully binding.
Another connection  between commitments and computer science has been pointed out by Samet [7] and Tennenholtz [12].
We, however, consider a number of different commitment types, among which conditional commitments, and propose a generic solution concept. 
Nash"s threat game [5] and Harsanyi"s rational threats [3] are two important early examples.
Our approach is similar to the Stackleberg setting in that we  assume an order in which the players commit.
Over the last few years, game theory has become almost  indispensable as a research tool for computer science and (multi)agent research.
Their point of departure is the observation that programs can be used to formulate commitments that are conditional on the programs of other systems.
e.g., [1, 11]).
