They mainly used linguistic features in the model.1 In this paper, we consider metadata extraction from general documents.
(1) Comparison between models: among the models above, which model performs best for title extraction; (2) Generality of model: whether it is possible to train a model on one domain and apply it to another domain, and whether it is possible to train a model in one language and apply it to another language; (3) Usefulness of extracted titles: whether extracted titles can improve document processing such as search.
As a case study, we consider title extraction in this paper.
Thus, how to automatically extract metadata from the bodies of documents turns out to be an important research issue.
We annotate titles in sample documents (for Word and PowerPoint respectively) and take them as training data to train several types of models, and perform title extraction using any one type of the trained models.
(2) We have empirically verified that the models trained with our approach are generic in the sense that they can be trained on one domain and applied to another, and they can be trained in one language and applied to another.
Our method can significantly outperform the baselines: one that always uses the first lines as titles and the other that always uses the lines in the largest font sizes as titles.
We conclude that we can indeed conduct reliable title extraction from general documents and use the extracted results to improve real applications.
However, the focus was mainly on extraction from research papers.
Ideally, metadata is defined by the authors of documents and is then used by various systems.
Experimental results indicate that our approach works well for title extraction from general documents.
As a case study, we consider extraction from Office including Word and PowerPoint.
It turns out that the use of format features is the key to successful title extraction.
[10] proposed a machine learning based method to conduct extraction from research papers.
Metadata of documents is useful for many kinds of document processing such as search, browsing, and filtering.
In section 4, we describe our method of title extraction, and in section 5, we describe our method of document retrieval using extracted titles.
(3) We have found that using the extracted titles we can significantly improve precision of document retrieval (by 10%).
General documents are more widely available in digital libraries, intranets and the internet, and thus investigation on extraction from them is sorely needed.
In the models, we mainly utilize formatting information such as font size as features.
In this paper, we also investigate the following three problems, which did not seem to have been examined previously.
They formalized the problem as that of classification and employed Support Vector Machines as the classifier.
However, people seldom define document metadata by themselves, even when they have convenient metadata definition tools [26].
(1) We have observed that Perceptron based models perform better in terms of extraction accuracies.
There are many types of metadata: title, author, date of creation, etc.
Precision and recall for title extraction from Word are 0.810 and 0.837 respectively, and precision and recall for title extraction from PowerPoint are 0.875 and 0.895 respectively.
It has not been clarified whether a machine learning based approach can work well for this task.
By general documents, we mean documents that may belong to any one of a number of specific genres.
In contrast, the styles of general documents can vary greatly.
General documents can be in many different file formats: Microsoft Office, PDF (PS), etc.
In section 2, we introduce related work, and in section 3, we explain the motivation and problem setting of our work.
The rest of the paper is organized as follows.
Research papers usually have well-formed styles and noticeable characteristics.
Methods for performing the task have been proposed.
We take a machine learning approach.
Section 6 gives our experimental results.
We make concluding remarks in section 7. 
We employ the following models: Maximum Entropy Model, Perceptron with Uneven Margins, Maximum Entropy Markov Model, and Voted Perceptron.
For instance, Han et al.
