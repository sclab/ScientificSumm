Lam et al build up previous query representations of story clusters, each of which corresponds to a topic [7].
And it was found that some classes of news could achieve better performance using named entity representation, while some other classes of news could achieve better performance using non-named entity representation.
In [10] frequent terms for each class are removed from document representation.
[8] extended a basic incremental TF-IDF model to include  sourcespecific models, similarity score normalization based on document-specific averages, similarity score normalization based on source-pair specific averages, term reweighting based on inverse event frequencies, and segmentation of documents.
Some efforts have been done on how to utilize named entities to improve NED.
When a new story was encountered, it was processed immediately to extract term features and a query representation of the story"s content is built up.
In [13] news stories are classified automatically at first, and then test sensitivities of names and non-name terms for NED for each class.
In their work, effectiveness of different kinds of names (or terms with different POS) for NED in different news classes are not investigated.
[9] utilized a combination of evidence from two distinct representations of a document"s content.
Yang et al.
proposed Single-Pass clustering on NED [6].
Then it was compared with all the previous queries.
Good improvements on TDT bench-marks were shown.
Both [10] and [13] used text categorization technique to classify news stories in advance.
In this manner comparisons happen between stories and clusters.
Recent years, most work focus on proposing better methods on comparison of stories and document representation.
We use statistical analysis to reveal the fact and use it to improve NED performance.
One of the representations was the usual free text vector, the other made use of lexical chains (created using WordNet) to build another term vector.
Stokes et al.
A marginal increase in effectiveness was achieved when the combined representation was used.
DOREMI research group combined semantic similarities of person names, location names and time together with textual similarity [11][12].
Brants et al.
Then the two representations are combined in a linear fashion.
Papka et al.
UMass [13] research group split document representation into two parts: named entities and non-named entities.
If the document did not trigger any queries by exceeding a threshold, it was marked as a new event.
gave location named entities four times weight than other terms and named entities [10].
For example, word election does not help identify different elections.
