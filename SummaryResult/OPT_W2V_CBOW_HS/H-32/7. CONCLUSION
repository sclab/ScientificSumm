Using this perspective, we have shown that using a combination of a carefully selected external corpus, matching against multiple centroids and taking into consideration rare but highly topic  specific terms, we can build a definitional question answering  module that is more focused on identifying nuggets that are of interest to human beings.
Our approach may also provide some insight into a few anomalies in past definitional question answering"s trials.
As a result, we are currently only able to achieve a  hybrid system that has the same level of performance as our proposed Human Interest Model.
Naval Academy, OPEC, NATO, International Bureau of  Universal Postal Union (UPU), Organization of Islamic Conference (OIC), PBGC PERSON Bing Crosby, George Foreman, Akira  Kurosawa, Sani Abacha, Enrico Fermi, Arnold Palmer, Woody Guthrie, Sammy Sosa, Michael Weiss, Paul Newman, Jesse  Ventura, Rose Crumb, Rachel Carson, Paul  Revere, Vicente Fox, Rocky Marciano, Enrico Caruso, Pope Pius XII, Kim Jong Il THING F16, Bollywood, Viagra, Howdy Doody Show, Louvre Museum, meteorites,  Virginia wine, Counting Crows, Boston Big Dig, Chunnel, Longwood Gardens, Camp David, kudzu, U.S. Medal of Honor, tsunami, genome, Food-for-Oil Agreement, Shiite, Kinmen Island EVENT Russian submarine Kursk sinks, Miss  Universe 2000 crowned, Port Arthur  Massacre, France wins World Cup in  soccer, Plane clips cable wires in Italian  resort, Kip Kinkel school shooting, Crash of EgyptAir Flight 990, Preakness 1998, first 2000 Bush-Gore presidential debate , 1998 indictment and trial of Susan  McDougal, return of Hong Kong to Chinese sovereignty, 1998 Nagano Olympic Games, Super Bowl XXXIV, 1999 North American International Auto Show, 1980 Mount St. Helens eruption, 1998 Baseball World  Series, Hindenburg disaster, Hurricane Mitch Table 3: TREC 2005 Topics Grouped by Entity Type is Google"s PageRank algorithm, which mainly consider the  number of linkages, has an indirect effect of ranking web documents by the degree of human interest.
Thus we feel that a good definitional question answering system would need to pick up both informative and interesting nugget types in order to provide a complete definitional coverage on all  important aspects of the topic.
Indeed, this is natural as the two models have been designed to identify two very different types of definition answers using very different types of features.
This is very different from the lexico-syntactic pattern  approach where the context of a human reader is not even considered when finding answers for definitional question answering.
The notion of an average human reader is an important consideration in our  approach.
What seems to be a good set of definition answers is some general information that provides a quick informative overview mixed together with some novel or interesting aspects about the topic.
We approached the problem of definitional question answering from a novel perspective, with the notion that interest factor plays a role in identifying definitional answers.
Although the methods we used are simple, they have been shown experimentally to be  effective.
"s Soft Pattern Bigram Model, the inherent differences between both types of nuggets seemingly caused by the low agreement rates between both models have made this a difficult task.
In our future work, we seek to further improve on the combined system by incorporating more evidence in support of correct  definitional answers or to filter away obviously wrong answers. 
While we have attempted to build such a system by combining our proposed Human Interest Model with Cui et al.
We further showed that at least two different types of answer nuggets are required to form a more thorough set of definitional answers.
This paper has presented a novel perspective for answering  definitional questions through the identification of interesting nuggets.
For  instance, the top definitional system at the recent TREC 2006  evaluation was able to significantly outperform all other systems using relatively simple unigram probabilities extracted from Google  snippets.
Experimental results has shown this approach can significantly outperform state-of-the-art definitional question answering systems.
Interesting nuggets are uncommon pieces of information about the topic that can evoke a human reader"s curiosity.
We suspect the main contributor to the system"s performance Entity Type Topics ORGANIZATION DePauw University, Merck & Co.,  Norwegian Cruise Lines (NCL), United  Parcel Service (UPS), Little League  Baseball, Cliffs Notes, American Legion, Sony Pictures Entertainment (SPE),  Telefonica of Spain, Lions Club  International, AMWAY, McDonald"s Corporation, Harley-Davidson, U.S.
