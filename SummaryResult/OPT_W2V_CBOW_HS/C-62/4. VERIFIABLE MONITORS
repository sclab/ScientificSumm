The final reason not to accept this monitoring system is that when a cheater is punished, the path will often be routed around not just the offender, but around other nodes as well.
The second, and more serious reason is that we have always given our source the ability to commit to any punishment.
With these monitors, each node observes the quality of the rest of the path and can also convince other players of these observations by giving them a proof.
Only that node must be punished in equilibrium, and the preceding node does not lose any payoff in administering the punishment.
The monitor"s output in this case can be thought of as a statement accompanied by a proof, a string that can be processed by any player to determine that the statement is true.
With monitors E2Ev, ROPv, and PRc, and provided that the node before each potential cheater has an alternate next hop that isn"t more expensive, it is possible to enforce any data path in SPE so long as the maximum temptation is less than what can be deterred in finite time, − ≤ 0 0 max 1 t rt er y π (5) Proof.
From the perspective of other source-destination pairs, however, these same firms are likely to be horizontal competitors.
This means that the negative results of the previous section no longer hold.
The cheater is the node that cannot produce proof that the rest of path quality decreased.
By cheating, the node will save money to some extent, so the cheater is likely to emerge from the punishment phase better off than the innocent nodes.
Alternately, a node may bribe its successor to cheat, if the punishment phase is profitable, and so forth.
Along these lines, we can imagine verifiable counterparts to E2E and ROP.
Recall that in the previous section, we assumed that players couldn"t convince each other of their private information.
A verifiable monitor is a distributed algorithmic mechanism that runs on the network graph, and outputs, to specific nodes, proofs about current or past network behavior.
This lemma follows because nodes can share proofs to identify who the cheater is.
Each node along a route must extract some positive profit unless the next hop is also the cheapest.
The required discounted time for punishment may increase exponentially in the number of coalition members, just as in the previous section!
The first, and weakest reason is that the maximum temptation remains finite, causing some distortion in routes or payments.
What would happen if they could?
A coalition node may pretend to punish its successor, but instead enjoy a secret payment from the cheating node.
When ISPs lie in sequence along a data path, they contribute complementary services, and their relationship is vertical.
Because of this, a node might deliberately cheat, in order to trigger punishment for itself and its neighbors.
Of course, if t0 is small, this effect is minimal.
In our abstract model, this doesn"t cause trouble since the punishment falls off the equilibrium path.
The effects are not so benign in the real world.
This will make nodes less motivated to administer punishments.
We will label these E2Ev and ROPv.
This may give the cheater a strategic advantage against its competitors.
Effectively, innocent nodes will be punished along with the guilty.
For example, the following lemma stands in contrast to Lemma 1.
In the extreme, the cheater may use such a strategy to drive neighbors out of business, and thereby gain a monopoly on some routes. 
Real world users are less likely to act collectively, and may simply search for the best service currently offered.
If a monitor"s informational signal can be credibly conveyed to others, we will call it a verifiable monitor.
In this section, we begin to introduce more accountability into the network.
The third reason is that Lemma 2 does not apply to cheating by coalitions.
189 By adding verifiability to our monitors, identifying a single cheater is straightforward.
Since punishment phases are generally characterized by a drop in quality, real world end-users may take this opportunity to shop for a new access provider.
Unfortunately, there are at least four reasons not to be satisfied with this improved monitoring system.
With this lemma in mind, it is easy to construct counterexamples to Claim 1 and Claim 2 in this new environment.
Lemma 2.
