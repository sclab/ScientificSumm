• Recovery mechanisms: The DS allows i to revert to an earlier semantic state after having undone a change in expectations by a further, later change of behaviour (e.g.
The main strength of our framework is that it allows us to exploit the three main elements of reciprocity: • Reputation-based adaptation: The DS adapts the  expectations toward agent i according to i"s previous  behaviour by modifying the semantic state to better  reflect this behaviour (based on the assumption that it will repeat itself in the future).
Forgiveness: After initial deviance, further compliant behaviour of an agent should lead to a semantic state that predicts compliant behaviour for that agent again.
Equality: Unless this is required by domain-specific constraints, the same dynamics of semantics should apply to all parties involved.
• Mutuality of expectations: The DS adapts the  expectations toward j"s behaviour according to i"s previous behaviour toward j to better reflect j"s response to i"s observed behaviour (in particular, allowing j to behave toward i as i behaved toward j earlier).
Non-redundancy: No two dialogue operators in O should have identical pre- and post-conditions, and any two semantic variants of an operator must differ in terms of pre- and/or post-conditions: ∀o, o ∈ O .
whether it is a reward or punishment), the other the degree of adaptation (reputation-based mechanisms, for example, need not realistically reflect the behaviour of the culprit, but may instead utilise immediate (exaggerated) stigmatisation of agents as a deterrent).
Compliance/deviance realisability: It must be  possible for agents in principle to comply with normative commitments or deviate from them in principle: ∃r ∈ R(Env, A) .expected(CS(r)) = ∅∧ compliant(CS(r)) = ∅ While not absolutely essential, these constitute desiderata for the design of DS-ACLs as they add to the simplicity and clarity of a given semantics specification.
Under contradictory  commitments, no possible behaviour can be  compliantit is up to the designer to decide to which extent this should be permitted.
Many of the above  properties are debatable, as we have to trade off cautiousness against the provision of incentives for cooperative behaviour.
(action(o) = action(o ) ⇒ pre(o) = pre(o ) ∨ post(o) = post(o)) 2.
Reachability of all semantic states: Any constraint causing a transition must be satisfiable in principle when using the dialogue operators and physical actions that are provided: ∀(s, c, A, s ) ∈ Δ ∃r ∈ R(Env, A).CS(r) ∩ c = ∅ 3.
Unprejudiced judgement: Expected behaviour  prediction must not deviate from compliant behaviour  prediction if deviant behaviour has not been observed so far (in particular this must hold for the initial semantic state).
Here, we have to trade off cautiousness against the  provision of incentives to resume cooperative behaviour.
While in some cases some agents should be able to enforce commitments upon others, this should generally be avoided to ensure agent autonomy.
social rules that do not presuppose ability to direct punishment or reward through physical actions) in real-world applications. 
In open systems in which we cannot enforce certain  behaviours, these are effectively the only available means for indirect sanctions and rewards.
Distinction between expected and compliant  behaviour: The content of expectations must differ from that of normative commitments at least for some  semantic variants (giving rise to non-compliant  expectations for some runs): ∃r ∈ R(Env, A) .expected(CS(r)) = compliant(CS(r)) 4.
Albeit simple, our example DS described above makes use of all these aspects, and apart from consistency and  completeness, it also satisfies some other useful properties: 1.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 105 There are two further dimensions that affect DS-based sanctioning and reward mechanisms and are orthogonal to the above: One concerns the character of the semantic state changes (i.e.
(pre(o) = pre(o )∧post(o) = post(o ) ⇒ o = o ) ∀o, o ∈ O .
This might not always be desirable as initial distrust is necessary in some systems, but it increases the chances that agents will agree to participate in communication.
Trusting an agent makes others vulnerable to  exploitation - blacklisting an agent forever, though, might lead that agent to keep up its unpredictable and  potentially malicious behaviour.
Our simple example semantics satisfies all these  properties apart from convergence.
If this property holds, this would imply that agents can stop tracking semantic state transitions  after some amount of initial interaction.
Respect for commitment autonomy: The semantics must not allow an agent to create a pending  commitment for another agent or to violate a commitment on behalf of another agent.
The advantage of this is reduced complexity, which of course comes at the price of giving up adaptiveness.
9 This is actually only a lower bound on the complexity for commitment processing which could become even worse if dominated by the complexity of verifying entailment |=; however, this would also hold for a static ACL semantics.
Our  framework raises interesting questions regarding further potential properties of DS such as: 1.
While we cannot make any general statements here  regarding optimal DS-ACL design, our framework provides the tools to test and evaluate the performance of different such communication-inherent sanctioning and rewarding  mechanisms (i.e.
The Sixth Intl.
Convergence: The semantic state of each of the  dialogue operators will remain stable after a finite  number of transitions, regardless of any further agent  behaviour11 .
Avoiding commitment inconsistency: The ACL must either disallow commitment to contradictory actions or beliefs, or at least provide operators for rectifying such contradictory claims.
by means of redemption).
10 For example, this could be useful if we want to discard commitments whose status was last modified more than k time steps ago (this is problematic, as it might force us to discard certain unset/pending commitments before they  become pending/active).
Joint Conf.
