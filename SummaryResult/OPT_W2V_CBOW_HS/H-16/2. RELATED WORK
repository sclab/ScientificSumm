To the best of our knowledge we are the first to use this approach for static caching of posting lists. 
Although these approaches seek to improve query processing efficiency, they differ from our  current work in that they do not consider caching.
Raghavan and Sever [12], in one of the first papers on  exploiting user query history, propose using a query base, built upon a set of persistent optimal queries submitted in the past, to improve the retrieval effectiveness for similar future queries.
They may be considered separate and complementary to a cache-based approach.
Similar ideas have been used in the context of file caching [17], Web caching [5], and even caching of posting lists [9], but in all cases in a dynamic setting.
Long and Suel propose a caching system structured according to three different levels [9].
Based on the observations of Markatos, Lempel and Moran propose a new caching policy, called Probabilistic Driven Caching, by attempting to estimate the probability distribution of all possible queries submitted to a search engine [8].
Different from our work, they consider caching and prefetching of pages of results.
Markatos [10] shows the existence of temporal  locality in queries, and compares the performance of different caching policies.
Baeza-Yates and Saint-Jean propose a three-level index  organization [2].
In their architecture, both levels use an LRU eviction  policy.
follow Markatos" work by showing that combining static and dynamic caching policies together with an adaptive prefetching policy achieves a high hit ratio [7].
Buckley and Lewit [3], in one of the earliest works, take a term-at-a-time approach to deciding when inverted lists need not be further examined.
Finally, our static caching algorithm for posting lists in Section 5 uses the ratio frequency/size in order to evaluate the goodness of an item to cache.
These last two papers are related to ours in that they exploit different caching strategies at different levels of the memory hierarchy.
More recent examples demonstrate that the top k documents for a query can be returned without the need for evaluating the complete set of posting lists [1, 4, 15].
propose a new architecture for Web search engines using a two-level dynamic caching system [13].
Their goal for such systems has been to improve response time for hierarchical engines.
There is a large body of work devoted to query  optimization.
Saraiva et al.
As systems are often hierarchical, there has also been some effort on multi-level architectures.
Fagni et al.
They find that the second-level cache can effectively reduce disk traffic, thus increasing the overall throughput.
The  intermediate level contains frequently occurring pairs of terms and stores the intersections of the corresponding inverted lists.
