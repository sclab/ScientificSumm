More accurate aggregates can be computed by maintaining multiple bit vectors at each node, as explained in [7].
The  intuition is that as the number of nodes doing coin toss  experiments increases, the probability of a more significant bit being set in one of the nodes" bit vectors increases.
In each time-step, each designated node sends its data to a random neighbor, which becomes designated for the subsequent  timestep (much like passing a token).
This process repeats until the aggregate has converged in the network.
• Random Walk: In random walk, only a subset of the nodes (termed designated nodes) communicate in a particular time-step.
Although such aggregates are very compact in nature,  requiring only O(logN) state space (where N is the number of nodes), they may not be very accurate as they can only approximate values to the closest power of 2, potentially causing errors of up to 50%.
These bit vectors are then exchanged among nodes.
To do so, each node  performs a coin toss experiment as follows: toss an unbiased coin, stopping after the first head is seen.
Double-counting is a well known problem in this process, where nodes may contribute more than once to the aggregate, causing inaccuracy in the final result.
We also discuss randomized gossiping techniques for disseminating aggregates in a cognitive radio network.
14 Two types of gossip protocols are: • Uniform Gossip: In uniform gossip, at each  timestep, each node chooses a random neighbor and sends its data to it.
When a node receives a bit vector, it updates its local bit vector by bitwise OR-ing it with the received vector (as shown in Figure 2 which computes AVERAGE).
4.2 Gossip Protocols Gossip-based protocols operate in discrete time-steps; a time-step is the required amount of time for all  transmissions in that time-step to complete.
We adopt the ODI approach pioneered by Flajolet and Martin (FM) for the purposes of aggregation.
This  aggregate is then communicated to other nodes in the  network and this process repeats until the aggregate at all nodes has converged to the same value, i.e.
Random walk has been shown to provide similar  convergence bounds as uniform gossip in problems of similar context [8, 12]. 
The node then sets the ith bit in a bit vector (initially filled with zeros), where i is the number of coin tosses it performed.
At every time-step, each node having something to send randomly selects one or more neighboring nodes and transmits its data to them.
At startup, k nodes are randomly elected as designated nodes.
4.1 FM Aggregation Aggregation is the process where nodes in a distributed network combine data received from neighboring nodes with their local value to generate a combined aggregate.
The actual value of the count aggregate is then computed using the following formula, AGGF M = 2j−1 /0.77351, where j represents the bit position of the least significant zero in the aggregate bit vector [7].
At the end of the aggregation process, every node, with high probability, has the same bit vector.
We  emphasize that this characteristic of the protocol also allows it to operate without relying on any underlying network structure.
the global  aggregate.
2 Convergence refers to the state in which all nodes have the most up-to-date view of the network.
Gossip protocols have been shown to provide exponentially fast convergence2 , on the order of O(log N) [10], where N is the number of nodes (or radios).
Uniform gossip provides exponentially fast convergence, with low network overhead [10].
Suppose we want to compute the number of nodes in the network, i.e.
We present the FM aggregation scheme that we use to  generate spectrum summaries and perform in-network  aggregation.
Intuitively, nodes can tag the aggregate value they transmit with  information about which nodes have contributed to it.
Transmitting FM bit vectors between nodes is done using randomized gossiping, discussed next.
The  randomized propagation of information provides fault-tolerance and resilience to network failures and outages.
These protocols can therefore easily scale to very dense  environments.
This process repeats for O(log(N)) steps (where N is the number of nodes in the network).
the COUNT query.
Queries other than count can also be computed using  variants of this basic counting algorithm, as discussed in [3] (and shown in Figure 2).
This section provides the background for our approach.
This decreases the error to within O(1/ √ m), where m is the number of such bit vectors.
Order and Duplicate  Insensitive (ODI) techniques have been proposed in the literature [10, 15].
However, this approach is not scalable.
Next we outline the FM approach; for full details, see [7].
