Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.
The content model is then interpolated with the original query model to form the  expanded query.
The other technique, relevance models, is more closely  related to our work.
One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].
The concepts used in their work are more general than those used in LCA, and include InQuery query  language structures, such as #UW50(white house), which  corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.
The only difference  between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.
Rocchio"s  approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.
This separates the content model from the background model.
Both approaches  attempt to use pseudo-relevant or relevant documents to  estimate a better query model.
However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.
It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or  pseudorelevant to query Q.
Given a query Q, a relevance model is a multinomial  distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.
There has been relatively little work done in the area of query expansion in the context of dependence models [9].
Instead, they model a more generalized notion of relevance, as we now show.
Unfortunately, it is not possible to formally apply Rocchio"s approach to a statistical retrieval model, such as language modeling for information retrieval.
After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).
Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.
Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document  routing [19].
Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.
However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 
This can be thought of as expanding the original query by k weighted terms.
Much like model-based feedback, relevance models estimate an improved query model.
This clipped distribution is then  interpolated with with the original, maximum likelihood query model [1].
Therefore, we go into the details of the model.
However, there have been several attempts to expand using multi-term concepts.
A number of formalized query expansion techniques have been developed for the language modeling framework,  including Zhai and Lafferty"s model-based feedback and Lavrenko and Croft"s relevance models [12, 29].
In the pseudo-relevant case, these are the top ranked documents for query Q.
Xu and Croft"s local context  analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].
Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.
These mild assumptions make computing the Bayesian posterior more practical.
Furthermore, it is assumed that P(D) is uniform over this set.
