The results indicate that the relevance and usefulness of the terms chosen by IRF is affected by the complexity of the search task; the terms chosen are more relevant and useful when the search task is more complex.
Search experience appears to affect how subjects use the terms recommended as a result of the RF process.
We use subject opinions of terms recommended by the systems as a measure of the effectiveness of IRF with respect to the terms generated for different search tasks.
In this section we use data gathered from interaction logs and subject opinions to investigate the extent to which RF was used and the extent to which it appeared to benefit our experimental subjects at different stages in their search 3.3.1 Feedback The interaction logs for all searches on the Explicit RF and Implicit RF were analysed and each search is divided up into nine equal length time slices.
It appears from these results that experienced subjects found ERF more useful and were more at ease with the ERF process.
In our experiment subjects were divided into two groups based on their level of search experience, the frequency with which they searched and the types of searches they performed.
The results indicate that inexperienced subjects found IRF more easy and effective than experienced subjects, who in turn found the terms chosen as a result of IRF more relevant and useful.
In the same way as in Section 3.1.2, we analysed the number of query modification terms recommended by the system that were used by experimental subjects.
In Figure 2 we plot the measure of precision described in Section 3.1.1 (i.e., the proportion of all possible representations that were provided as RF) at each of the 22 IRF: U(24) = 403, p = .009, ERF: U(24) = 396, p = .013 nine slices, per search task, averaged across all subjects; this allows us to see how the provision of RF was distributed during a search.
Figure 2 also shows the proportion of feedback for tasks of different complexity.
Task complexity did not affect the proportion of terms accepted in either RF method, despite there being a difference in how relevant and useful subjects perceived the terms to be for different complexities; complexity may affect term selection in ways other than the proportion of terms accepted.
A correlation analysis between the proportion of terms accepted at each search stage and cumulative RF (i.e., the sum of all precision at each slice in Figure 2 up to and including the end of the search stage) suggests that in both types of RF the quality of system terms improves as more RF is provided28 .
In the  postsearch questionnaire subjects were asked about how RF was conveyed using differentials to elicit their opinion on: 1. the value of the feedback technique: How you conveyed relevance to the system (i.e.
In this section we use their perceptions and logging to address the next research question; the relationship between the usefulness and use of IRF and the search experience of experimental subjects.
Subject responses suggested that 3 Since this analysis involved many differentials, we use a Bonferroni correction to control the experiment-wise error rate and set the alpha level (α) to .0167 and .0250 for both statements 1. and 2. respectively, i.e., .05 divided by the number of differentials.
Therefore, when task complexity increases the ERF system has fewer examples of relevant documents and the expansion terms generated may be poorer.
In Table 5 we show the mean average responses for inexperienced and experienced subject groups on ERF and IRF; 24 subjects per cell.
In ERF this is the proportion of all possible representations that were marked relevant by the searcher, i.e., those representations explicitly marked relevant.
Table 2 shows proportion of representations provided as RF by subjects.
The average proportion of the top six recommended terms that were accepted at each stage are shown in Table 8; each cell contains data from all 48 subjects.
This may be a natural consequence of their being less time to view documents in a time constrained task environment but as we will show as complexity changes, the nature of information searchers interact with also appears to change.
Explicit RF Implicit RFProportion of terms HC MC LC HC MC LC Accepted 65.31 67.32 68.65 67.45 67.24 67.59 The average number of terms accepted from IRF is approximately the same across all search tasks and generally the same as that of ERF14 .
Explicit RF Implicit RF Differential HC MC LC HC MC LC Easy 2.78 2.47 2.12 1.86 1.81 1.93 Effective 2.94 2.68 2.44 2.04 2.41 2.66 Useful 2.76 2.51 2.16 1.91 2.37 2.56 All (1) 2.83 2.55 2.24 1.94 2.20 2.38 Comfortable 2.27 2.28 2.35 2.11 2.15 2.16 In control 2.01 1.97 1.93 2.73 2.68 2.61 All (2) 2.14 2.13 2.14 2.42 2.42 2.39 IRF was most effective and useful for more complex search tasks4 and that the differences in all pair-wise comparisons between tasks were significant5 .
Each cell in Table 1 summarises the subject responses for 16  tasksystem pairs (16 subjects who ran a high complexity (HC) task on the ERF system, 16 subjects who ran a medium complexity (MC) task on the ERF system, etc).
The total amount of feedback for a single RF method/task complexity pairing across all nine slices corresponds to the value recorded in the first row of Table 2 (e.g., the sum of the RF for IRF/HC across all nine slices of Figure 2 is 21.50%).
In Table 4 we show the proportion of the top six terms 9 r = −0.696, p = .001 (Pearson"s Correlation Coefficient) 10 relevant: χ2 (2) = 13.82, p = .001; useful: χ2 (2) = 11.04, p = .004; α = .025 11 all χ2 (2) ≤ 2.28, all p ≥ .32 (Kruskal-Wallis Test) 12 all T(16) ≥ 102, all p ≤ .021, (Wilcoxon Signed-Rank Test) 13 that were shown to the searcher that were added to the search query, for each type of task and each type of RF.
There are a maximum of 14 representations per document: 4  topranking sentences, 1 title, 1 summary, 4 summary sentences and 4 summary sentences in document context.
It also means that the amount of 4 effective: χ2 (2) = 11.62, p = .003; useful: χ2 (2) = 12.43, p = .002 5 Dunn"s post-hoc tests (multiple comparison using rank sums); all Z ≥ 2.88, all p ≤ .002 6 all χ2 (2) ≤ 2.85, all p ≥ .24 (Kruskal-Wallis Tests) 7 effective: all r ≥ 0.644, p ≤ .002; useful: all r ≥ 0.541, p ≤ .009 8 effective: χ2 (2) = 7.01, p = .03; useful: χ2 (2) = 6.59, p = .037 (Kruskal-Wallis Test); all pair-wise differences significant, all Z ≥ 2.34, all p ≤ .01 (Dunn"s post-hoc tests) feedback varies based on the complexity of the search task.
Experienced subjects generally reacted to the query modification terms chosen by the system more positively than inexperienced 16 easy: U(24) = 391, p = .016; effective: U(24) = 399, p = .011; α = .0167 (Mann-Whitney Tests) 17 all T(24) ≥ 231, all p ≤ .001 (Wilcoxon Signed-Rank Test) 18 U(24) = 390, p = .018; α = .0250 (Mann-Whitney Test) 19 T(24) = 222, p = .020 (Wilcoxon Signed-Rank Test) 20 ERF: all U(24) ≤ 319, p ≥ .26, IRF: all U(24) ≤ 313, p ≥ .30  (MannWhitney Tests) 21 ERF: all U(24) ≥ 388, p ≤ .020, IRF: all U(24) ≥ 384, p ≤ .024 Explicit RF Implicit RF Differential Inexp.
14 all T(16) ≥ 80, all p ≤ .31, (Wilcoxon Signed-Rank Test) 15 ERF: χ2 (2) = 3.67, p = .16; IRF: χ2 (2) = 2.55, p = .28  (KruskalWallis Tests) Table 5.
0 1 2 3 4 5 6 7 8 9 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 Slice Search"precision"(%oftotalrepsprovidedasRF) Explicit RF/HC Explicit RF/MC Explicit RF/LC Implicit RF/HC Implicit RF/MC Implicit RF/LC Figure 2.
For ERF, the results indicate that the terms generated are perceived to be more relevant and useful for less complex search tasks; although differences between tasks were not significant11 .
When using the IRF system, the data indicates that at the start of the search subjects are providing little relevance information24 , which corresponds to interacting with few document representations.
This suggests that subject perceptions of the terms chosen for query modification are affected by task complexity.
The results appear to show a difference25 in how IRF is used that relates to the complexity of the search task.
3.2.2 Terms We used questionnaire responses to gauge subject opinion on the relevance and usefulness of the terms from the perspective of experienced and inexperienced subjects.
3.3 Search Stage From our observations of experimental subjects as they searched we conjectured that RF may be used differently at different times during a search.
To do this we use a measure of search precision that is the proportion of all possible document representations that a searcher assessed, divided by the total number they could assess.
Relevant 2.58 2.44 2.33 2.21 Useful 2.88 2.63 2.33 2.23 The differences between subject groups were significant21 .
In this section we use the data derived from the experiment to answer our research questions about the effect of search task complexity, search experience and stage in search on the use and effectiveness of IRF.
The further into a search a searcher progresses, the more likely they are to accept terms recommended via IRF (significantly more than ERF27 ).
To determine whether a relationship exists between the effectiveness and usefulness of the IRF process and task complexity we applied Spearman"s Rank Order Correlation Coefficient to participant responses.
In IRF this is the proportion of representations viewed by a searcher over all possible representations that could have been viewed by the searcher.
Search stage affects term acceptance in IRF but not in ERF26 .
This number of slices gave us an equal number per stage and was a sufficient level of granularity to identify trends in the results.
Explicit RF Implicit RF Measure HC MC LC HC MC LC Proportion Feedback 2.14 2.39 2.65 21.50 19.36 15.32 Documents Viewed 10.63 10.43 10.81 10.84 12.19 14.81 For IRF there is a clear pattern: as complexity increases the subjects viewed fewer documents but viewed more representations for each document.
2. the process of providing the feedback: How you conveyed relevance to the system made you feel: comfortable/uncomfortable, in control/not in control.
Further, trends in the data suggest that the complexity of the task affects how subjects provide IRF and the proportion of system terms accepted. 
As well as using data on relevance and utility of the terms chosen, we used data on term acceptance to measure the perceived value of the terms suggested.
This finding was supported by the proportion of query modification terms these subjects accepted.
As such, levels of search experience may affect searchers" use and perceptions of IRF.
In the next section we investigate the effect of task complexity on the terms chosen as a result of IRF.
In tasks of lower complexity the subjects felt they were better able to provide feedback on whether or not documents were relevant to the task.
Comparison between ERF and IRF shows that subject perceptions also vary for different types of RF12 .
Implicit relevance information is generally offered extensively in the middle of the search as they interact with results and it then tails off towards the end of the search.
Correlation analysis revealed a strong negative correlation between the number of documents viewed and the amount of feedback searchers provide9 ; as the number of documents viewed increases the proportion of feedback falls (searchers view less representations of each document).
To simplify the statistical analysis and comparison we use the grouping of start, middle and end.
Since the interface shows document representations from the top-30 documents, there are 420 representations that a searcher can assess.
In this section we investigate whether the amount of RF provided by searchers or the proportion of terms accepted are affected by how far through their search they are.
Accepted 63.76 70.44 64.43 71.35 Our analysis of the data show that differences between subject groups for each type of RF are significant; experienced subjects accepted more expansion terms regardless of type of RF.
We present our findings in terms of the RF provided by subjects and the terms recommended by the systems.
The data are the same as that analysed in the previous section, but here we focus on search experience rather than the search task.
Our analysis suggested that search experience does not affect the amount of feedback subjects provide20 .
3.2 Search Experience Experienced searchers may interact differently and give different types of evidence to RF than inexperienced searchers.
Table 3 presents average responses grouped by search task.
As Table 2 shows, subjects marked fewer documents relevant for highly complex tasks .
Since IRF is based on the interaction of the searcher, the more they interact, the more feedback they provide.
This proportion measures the searcher"s level of interaction with a document, we take it to measure the user"s interest in the document: the more document representations viewed the more interested we assume a user is in the content of the document.
Table 7 shows the average number of accepted terms per subject group.
Figure 2 appears to show the existence of a relationship between the stage in the search and the amount of relevance information provided to the different types of feedback algorithm.
The results of this analysis suggest that the effectiveness of IRF and usefulness of IRF are both related to task complexity; as task complexity increases subject preference for IRF also increases7 .
This could explain the difference in the proportion of recommended terms accepted in ERF as task complexity increases.
3.2.3 Summary In this section we have analysed data gathered from two subject groups - inexperienced searchers and experienced searchers - on how they perceive and use IRF.
Subject perceptions of IRF elicited using the other differentials did not appear to be affected by the complexity of the search task6 .
In a similar way to Section 3.1.1 we analysed the proportion of feedback that searchers provided to the experimental systems.
That is,  nonstopword, non-query terms occurring frequently in search results regarded as relevant are likely to be recommended to the searcher for query modification.
(i.e., How you conveyed relevance to the system was… and How you conveyed relevance to the system made you feel…).
Kruskal-Wallis Tests were applied to each differential for each type of RF3 .
10 Relevant here, was explained as being related to their task whereas useful was for terms that were seen as being helpful in the search task.
25 Although not statistically significant; χ2 (2) = 3.54, p = .17 (Friedman Rank Sum Test) 3.3.2 Terms The terms recommended by the system are chosen based on the frequency of their occurrence in the relevant items.
Table 6 shows the average differential responses obtained from both subject groups.
In the case of ERF subjects provide explicit relevance assessments throughout most of the search, but there is generally a steep increase in the end phase towards the completion of the search23 .
ticking boxes or viewing information) was: easy / difficult, effective/ ineffective, useful"/not useful.
At this stage the subjects are perhaps concentrating more on reading the retrieved results.
As these subjects have less search experience they may be less able to understand RF processes and may be more comfortable with the system gathering feedback implicitly from their interaction.
3.1.3 Summary In this section we have presented an investigation on the effect of search task complexity on the utility of IRF.
3.1.1 Feedback We use questionnaires and system logs to gather data on subject perceptions and provision of RF for different search tasks.
We also showed that inexperienced subjects generally accepted less recommended terms than experienced subjects, perhaps because they were less comfortable with RF or generally submitted shorter search queries.
For IRF there is little difference in how many of the recommended terms were chosen by subjects for each level of task complexity15 .
16 The differences for all other IRF differentials were not statistically significant.
In this section we analysed the average number of terms from the top six terms recommended by Explicit RF and Implicit RF over the course of a search.
The value corresponding to the differential All represents the mean of all differentials for a particular attitude statement.
13 This was the smallest number of query modification terms that were offered in both systems.
3.1 Search Task Searchers attempted three search tasks of varying complexity, each on a different experimental system.
Subjects may have perceived IRF terms as more useful for high complexity tasks but this was not reflected in the proportion of IRF terms accepted.
The results demonstrate a strong preference in inexperienced subjects for IRF; they found it more easy and effective than experienced subjects.
Subject perceptions of system terms (lower = better).
On the other hand, subjects felt ERF was more effective and useful for low complexity tasks8 .
Since there is a direct association between the RF and the terms selected we use the number of terms accepted by searchers at different points in the search as an indication of how effective the RF has been up until the current point in the search.
Distribution of RF provision per search task.
Explicit and Implicit RF systems made recommendations about which terms could be added to the original search query.
The average obtained differential values are shown in Table 1 for IRF and each task category.
This has no effect on the number of RF terms chosen, but may affect the quality of the terms selected.
Explicit RF Implicit RF Differential HC MC LC HC MC LC Relevant 2.50 2.46 2.41 1.94 2.35 2.68 Useful 2.61 2.61 2.59 2.06 2.54 2.70 Kruskal-Wallis Tests were applied within each type of RF.
However, the differences between the same groups for different types of RF are not significant; subjects chose roughly the same percentage of expansion terms offered irrespective of the type of RF22 .
Subject perceptions of system terms (lower = better).
3.3.3 Summary The results from this section indicate that the location in a search affects the amount of feedback given by the user to the system, and hence the amount of information that the RF mechanism has to decide which terms to offer the user.
To test this, our third research question concerned the use and usefulness of IRF during the course of a search.
We do not divide tasks based on this limit as subjects often terminated their search in less than 15 minutes.
Feedback and documents viewed.
To test this, subjects were asked to complete two semantic differentials that completed the statement: The words chosen by the system were: relevant/irrelevant and useful/not useful.
These are essentially differences in the way users are assessing documents.
We use the method proposed by [12] to determine the significance of differences in multiple comparisons and that of [9] to test for interaction effects between experimental variables, the occurrence of which we report where appropriate.
In this section we present an analysis on the use and usefulness of IRF for search tasks of different complexities.
More specifically, as complexity increases it appears as though subjects take longer to reach their most interactive point.
Experienced subjects tended to like ERF more than inexperienced subjects and felt more comfortable with this feedback method19 .
The values for ERF are included for reference in this table and all other tables and figures in the Findings section.
Their verbal reporting of ERF, where perceived utility and effectiveness increased as task complexity decreased, supports this finding.
From the results there appears to be a strong relation between the complexity of the task and the subject interaction: subjects preferring IRF for highly complex tasks.
Due to the ordinal nature of much of the data non-parametric statistical testing is used in this analysis and the level of significance is set to p < .05, unless otherwise stated.
For the purposes of this analysis a search begins when a subject poses the first query to the system and progresses until they terminate the search or reach the maximum allowed time for a search task of 15 minutes.
For all differentials, apart from in control, inexperienced subjects generally preferred IRF over ERF17 .
Subject perceptions of RF method (lower = better).
This suggests that task complexity affects how IRF is distributed during the search and that they may be spending more time initially interpreting search results for more complex tasks.
We analyse interaction logs generated by both interfaces to investigate the amount of RF subjects provided.
Explicit RF Implicit RFProportion of terms Inexp.
Explicit RF Implicit RFProportion of terms start middle end start middle end Accepted 66.87 66.98 67.34 61.85 68.54 73.22 The results show an apparent association between the stage in the search and the number of feedback terms subjects accept.
Subject perceptions of RF method (lower = better).
These differentials elicited opinion from experimental subjects about the RF method used.
This gives some overall understanding of the subjects" feelings which can be useful as the subjects may not answer individual differentials very precisely.
3.2.1 Feedback We analyse the results from the attitude statements described at the beginning of Section 3.1.1.
This would appear to correspond to stages of initial exploration, detailed analysis of document representations and storage and presentation of findings.
This correction reduces the number of Type I errors i.e., rejecting null hypotheses that are true.
The highest, or most positive, values in each table are shown in bold.
Since the aim of the paper is to investigate situations in which IRF might perform well, not a direct comparison between IRF and ERF, we make only limited comparisons between these two types of feedback.
Term Acceptance (proportion of top six terms).
This suggests a pattern where users are investigating retrieved documents in more depth.
23 IRF: all Z ≥ 1.87, p ≤ .031, ERF: start vs. end Z = 2.58, p = .005 (Dunn"s post-hoc tests).
The category labels HC, MC and LC are used to denote the high, moderate and low complexity tasks respectively.
Inexperienced subjects also felt that IRF was more difficult to control than experienced subjects18 .
24 Although increasing toward the end of the start stage.
3.1.2 Terms The same RF algorithm was used to select query modification terms in all systems [16].
Slices 1 - 3 correspond to the start of the search, 4 - 6 to the middle of the search and 7 - 9 to the end.
Term Acceptance (percentage of top six terms).
All Likert scales and semantic differentials were on a 5-point scale where a rating closer to 1 signifies more agreement with the attitude statement.
Term Acceptance (percentage of top six terms).
Our analysis uses data from questionnaires, post-experiment interviews and background system logging on the ERF and IRF systems.
We present our findings per research question.
Differences may reside in the nature of the terms accepted; future work will investigate this issue.
Explicit RF Implicit RF Differential Inexp.
Easy 2.46 2.46 1.84 1.98 Effective 2.75 2.63 2.32 2.43 Useful 2.50 2.46 2.28 2.27 All (1) 2.57 2.52 2.14 2.23 Comfortable 2.46 2.14 2.05 2.24 In control 1.96 1.98 2.73 2.64 All (2) 2.21 2.06 2.39 2.44 subjects.
Table 4.
Table 6.
Table 3.
Table 8.
Table 2.
Table 7.
Table 1.
