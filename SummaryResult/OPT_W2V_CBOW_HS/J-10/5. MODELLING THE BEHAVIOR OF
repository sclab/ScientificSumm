vi f is assumed normally distributed around some value vf ; • δf ∈ [0, 1] can be seen as a measure of the bias when reporting feedback.
For a given hotel, we make the assumption that the quality experienced by the users is normally distributed around some value vf , which represents the objective quality offered by the hotel on the feature f. The rating submitted by user i on feature f is: ˆri f = δf vi f + (1 − δf ) · sign vi f − ef (i) c + d(vi f , ef (i)|wi f ) (2) where: • vi f is the (unknown) quality actually experienced by the user.
We compare this estimator with the one obtained by simply averaging the ratings over all hotels and features: i.e., ¯rf = j,r j f =0 rj f j,r j f =0 1 ; Table 7 presents the ratio between the root mean square error (RMSE) when using ˆri f and ¯rf to estimate the actual ratings.
Table 7: Average of RMSE(ˆrf ) RMSE(¯rf ) City O R S C V Boston 0.987 0.849 0.879 0.776 0.913 Sydney 0.927 0.817 0.826 0.720 0.681 Las Vegas 0.952 0.870 0.881 0.947 0.904 As a second experiment, we try to distinguish the sets Bf = {i|ri f ∈ B} and Gf = {i|ri f ∈ G} of bad, respectively good ratings on the feature f. For example, we compute the set Bf using the following classifier (called σ): ri f ∈ Bf (σf (i) = 1) ⇔ ˆri f ≤ 4; Tables 8, 9 and 10 present the Precision(p), Recall(r) and s = 2pr p+r for classifier σ, and compares it with a naive  majority classifier, τ, τf (i) = 1 ⇔ |Bf | ≥ |Gf |: We see that recall is always higher for σ and precision is usually slightly worse.
For the s metric σ tends to add a 140 Table 8: Precision(p), Recall(r), s= 2pr p+r while  spotting poor ratings for Boston O R S C V p 0.678 0.670 0.573 0.545 0.610 σ r 0.626 0.659 0.619 0.612 0.694 s 0.651 0.665 0.595 0.577 0.609 p 0.684 0.706 0.647 0.611 0.633 τ r 0.597 0.541 0.410 0.383 0.562 s 0.638 0.613 0.502 0.471 0.595 Table 9: Precision(p), Recall(r), s= 2pr p+r while  spotting poor ratings for Las Vegas O R S C V p 0.654 0.748 0.592 0.712 0.583 σ r 0.608 0.536 0.791 0.474 0.610 s 0.630 0.624 0.677 0.569 0.596 p 0.685 0.761 0.621 0.748 0.606 τ r 0.542 0.505 0.767 0.445 0.441 s 0.605 0.607 0.670 0.558 0.511 1-20% improvement over τ, much higher in some cases for hotels in Sydney.
For every hotel we take the sequence of reports, and for each report (regardless of it value) we classify it as being good or bad However, to perform these tests, we need to estimate the objective value, vf , that is the average of the true quality observations, vi f .
The value of δf may depend on various factors; we fix one value for each feature f; • c is a constant between 1 and 5; • wi f is the weight of feature f in the textual comment of review i, computed according to Eq.
The higher the distance between the true  observation vi f and the function ef , the higher the bias.
The distance function satisfies the following properties: - d(y, z|w) ≥ 0 for all y, z ∈ [0, 5], w ∈ [0, 1]; - |d(y, z|w)| < |d(z, x|w)| if |y − z| < |z − x|; - |d(y, z|w1)| < |d(y, z|w2)| if w1 < w2; - c + d(vf , ef (i)|wi f ) ∈ [1, 5]; The second term of Eq.
For every hotel, we take the  sequence of reports, and whenever we encounter a rating that is either good or bad (but not indifferent) we try to predict it using Eq.
The algorithm we are using is based on the intuition that the amount of conformity rating is minimized.
Formally, we define the sets: Γ1 = {i|ef (i) < vf and ri f ∈ B}; Γ2 = {i|ef (i) > vf and ri f ∈ G}; that correspond to irregularities where even though the expectation at point i is lower than the delivered value, the rating is poor, and vice versa.
We split for convenience the rating values in three ranges: bad (B = {1, 2}),  indifferent (I = {3, 4}), and good (G = {5}), and perform the following two tests: • First, we will use our model to predict the ratings that have extremal values.
(3), and use the following distance function: d(vf , ef (i)|wi f ) = |vf − ef (i)| vf − ef (i) |vf 2 − ef (i)2 | · (1 + 2wi f ); The constant c ∈ I was set to min{max{ef (i), 3}}, 4}.
In other words, the value vf should be such that as often as possible, bad ratings follow expectations above vf and good ratings follow expectations below vf .
As a first experiment, we take the sets of extremal  ratings {ri f |ri f /∈ I} for each hotel and feature.
For every such rating, ri f , we try to estimate it by computing ˆri f using Eq.
(2) we replace vi f by the value vf computed in Eq.
(1); • d(vi f , ef (i)|wi f ) is a distance function between the  expectation and the observation of user i.
Replacing the test algorithm with one that plays a 1 with probability equal to the proportion of bad reviews improves its results for this city, but it is still outperformed by around 80%. 
High values reflect the fact that users rate objectively, without being influenced by prior expectations.
We define vf as the value that minimize these union of the two sets: vf = arg min vf |Γ1 ∪ Γ2| (3) In Eq.
(2) • Second, instead of predicting the value of extremal  ratings, we try to classify them as either good or bad.
(2) encodes the bias of the rating.
This is likely because Sydney reviews are more positive than those of the American cities and cases where the number of bad reviews exceeded the number of good ones are rare.
In all cases the estimate produced by our model is better than the simple average.
RATERS To account for the observations described in the previous sections, we propose a model for the behavior of the users when submitting online reviews.
The values for δf were fixed at {0.7, 0.7, 0.8, 0.7, 0.6} for the  features {Overall, Rooms, Service, Cleanliness, Value}  respectively.
The weights are computed as described in Section 3.
5.1 Model Validation We use the data set of TripAdvisor reviews to validate the behavior model presented above.
