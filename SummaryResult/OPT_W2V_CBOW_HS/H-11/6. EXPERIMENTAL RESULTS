For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.
Clearly, the points selected by our LOD algorithm can better represent the original data set.
This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.
One is active learning which selects the most informative  samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.
It is more reasonable for the users to provide feedback information only on the 10 images selected by the system.
It is clear that the use of active learning is beneficial in the image retrieval domain.
To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.
In this section, we evaluate the performance of our  proposed algorithm on a large image database.
As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks.
6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.
In general, it is appropriate to present 20 images on a screen.
There is a significant increase in performance from using the active learning methods.
Specifically, we incorporate a locality preserving  regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.
The work presented in this paper is  focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].
By iteratively adding the user"s feedbacks, the  corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.
Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.
It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.
As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.
The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.
Clearly, the points selected by our LOD algorithm can better represent the original data set.
Both of these two algorithms make use of the unlabeled images.
For all the five algorithms, the retrieval  performance improves with more feedbacks provided by the user. 
SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.
Note that, the images which have been selected at previous  iterations are excluded from later selections.
This is because that the LRR algorithm makes  efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.
Both SVMactive, AOD, and LOD are active  learning algorithms, while LRR and SVM are standard  classification algorithms.
In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier.
We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points.
(a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval.
In many real world applications like relevance  feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.
Note that, SVMactive can only be  ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.
We list different aspects of the experimental design below.
The numbers beside the selected points denote their orders to be selected.
10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.
It is important to note that the automatic relevance  feedback scheme used here is different from the ones described in [8], [11].
As can be seen, our LOD algorithm outperforms the other four algorithms on the  entire scope.
Therefore, the retrieval performance at the first two rounds are especially important.
6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.
To demonstrate the effectiveness of our proposed LOD algorithm, we  compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).
Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points.
The  precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation.
The numbers beside the selected points denote their orders to be selected.
After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.
At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.
We begin with a simple synthetic example to give some intuition about how LOD works.
It applies the ordinary SVM to build the initial classifier.
The LOD algorithm performs the best on the entire scope.
The retrieval  performance after the first two rounds of feedbacks (especially the first round) is more important.
In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).
In order to reduce the time complexity of active learning algorithms, we didn"t select the most informative images from the whole database but from the top 500  images.
For each query, the automatic relevance feedback mechanism is performed for four iterations.
It is a large and heterogeneous image set.
To simulate such  environment, we use five-fold cross validation to evaluate the  algorithms.
Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best.
Also, the LRR algorithm performs better than SVM.
Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.
While for LRR and SVM, we use the top 10 images as training data.
Thus, it is difficult for the user to find both four relevant and irrelevant images.
In real world image retrieval systems, the query image is usually not in the image database.
As can be seen, our LOD algorithm consistently outperforms the other four algorithms.
For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.
(a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.
Note that, at the first round of feedback, the SVMactive algorithm can not be applied.
Eight points are selected by AOD and LOD.
plied when the classifier is already built.
As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.
For each submitted query, our system  retrieves and ranks the images in the database.
The relevance feedback technique is crucial to image retrieval.
Thus, there are 20 images per category in each subset.
6.4 Discussion Several experiments on Corel database have been  systematically performed.
scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.
For both LRR and LOD algorithms, we use the same graph structure (see Eq.
For LRR and SVM, the user is required to label the top 10 images.
In real world, the user may not be willing to provide too many relevance feedbacks.
Each image is represented as a 128-dimensional vector as described in Section 5.1.
The scope is specified by the number (N) of top-ranked  images presented to the user.
The AOD algorithm performs the worst.
6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.
As the scope gets larger, the performance difference between these algorithms gets smaller.
Figure 2 shows some sample images.
At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.
6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.
Therefore, the precision at top 20 (N = 20) is especially important.
On the other hand, the  precision rate emphasizes the precision at a particular value of scope.
In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.
Both of these two  strategies have been studied extensively in the past [14], [7], [5], [8].
We would like to highlight several  interesting points: 1.
More precisely, we divide the whole image database into five subsets with equal size.
Putting more images on a screen may affect the quality of the presented images.
4) and set the value of p (number of  nearest neighbors) to be 5.
The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.
6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.
(a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship.
The data set contains two circles.
However, this may not be practical.
