In statistics, the problem of selecting samples to label is typically referred to as experimental design.
Based on the observation that the closer to the SVM  boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.
Unlike the standard classification problems where the labeled samples are  pregiven, in relevance feedback image retrieval the system can actively select the images to label.
Thus active learning can be naturally introduced into image retrieval.
However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.
Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we  propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).
Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.
Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.
In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.
Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.
Rather than describe an image  using text, in these systems an image query is described using one or more example images.
In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.
In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are  expensive.
In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.
The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.
The new loss function aims to find a classifier which is locally as smooth as possible.
However, in general the top returned images may not be the most informative ones.
Some other SVM based active learning algorithms can be found in [7], [9].
Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].
All of these approaches are based on a least squares regression model.
The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.
It would be important to note that the most informative images may not be the top returned images.
are automatically extracted to represent the images.
The intent of optimal experimental design is  usually to maximize confidence in a given model, minimize  parameter variances for system identification, or minimize the model"s output variance.
The major disadvantage of SVM active learning is that the  estimated boundary may not be accurate enough.
Many real world applications can be casted into active learning framework.
Unlike  traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.
The rest of the paper is organized as follows.
Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.
Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.
This problem is typically called active learning [4].
In Section 2, we provide a brief description of the related work.
In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.
Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data  collection.
It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.
Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.
The study of optimal experimental  design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.
Content-Based Image Retrieval has attracted substantial interests in the last decade [13].
However, the low level features may not accurately characterize the high level semantic concepts.
Classical experimental design  approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.
The sample x is referred to as experiment, and its label y is referred to as measurement.
To narrow down the semantic gap, relevance feedback is  introduced into CBIR [12].
Finally, we provide some  concluding remarks and suggestions for future work in Section 5. 
The low level visual features (color, texture, shape, etc.)
