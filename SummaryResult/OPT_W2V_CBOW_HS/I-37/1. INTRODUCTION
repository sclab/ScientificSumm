Our hypothesis is a very simple one: If we can devise a sufficiently general, abstract view of describing learning processes, we will be able to utilise the whole range of methods for (i) rational reasoning and (ii) communication and coordination offered by agent technology so as to build effective autonomous learning agents.
Various techniques have been suggested in this respect, ranging from the low-level integration of  independently derived learning hypotheses (e.g.
Despite the autonomy and self-directedness of learning agents, many of these systems exhibit a sufficient overlap in terms of individual learning goals so that beneficial  cooperation might be possible if a model for flexible  interaction between autonomous learners was available that allowed agents to 1. exchange information about different aspects of their own learning mechanism at different levels of detail without being forced to reveal private information that should not be disclosed, 2. decide to what extent they want to share information about their own learning processes and utilise  information provided by other learners, and 3. reason about how this information can best be used to improve their own learning performance.
combining  different classifiers to make optimal classification decisions [4, 7], model averaging of Bayesian classifiers [8], or  consensusbased methods for integrating different clusterings [11]), to the high-level combination of learning results obtained by heterogeneous learning agents using meta-learning (e.g.
Viewing learners as autonomous, self-directed agents is the only appropriate view one can take in modelling these distributed learning environments: the agent metaphor  becomes a necessity as oppossed to preferences for scalability, dynamic data selection, interactivity [13], which can also be achieved through (non-agent) distribution and  parallelisation in principle.
An example for this is that of  fraudulent agents on eBay which may try to prevent  reputationlearning agents from the construction of useful models for detecting fraud.
Our model is based on the simple idea that autonomous learners should maintain meta-descriptions of their own learning processes (see also [3]) in order to be able to  exchange information and reason about them in a rational way (i.e.
Therefore, the techniques they suggest are not applicable in societies of autonomous learners interacting in open systems.
To test this hypothesis, we introduce such an abstract  architecture (section 2) and implement a simple, concrete  instance of it in a real-world domain (section 3).
[14, 17] for overviews), it has long been recognised that  parallelisation and distribution can be used to improve learning performance.
In such systems,  learners (agents) may not be able to integrate their datasets or learning results (because of different data formats and  representations, learning algorithms, or legal restrictions that prohibit such integration [11]) and cannot always be  guaranteed to interact in a strictly cooperative fashion (discovered knowledge and collected data might be economic assets that should only be shared when this is deemed profitable;  malicious agents might attempt to adversely influence others" learning results, etc.).
We report on empirical results obtained with this implemented system that demonstrate the viability of our approach (section 4).
Many  distributed learning domains involve the use of sensitive data and prohibit the exchange of this data (e.g.
All of these approaches assume homogeneity of agent  design (all agents apply the same learning algorithm) and/or agent objectives (all agents are trying to cooperatively solve a single, global learning problem).
Finally, we review related work (section 5) and conclude with a summary, discussion of our approach and outlook to future work on the subject (section 6). 
Examples for applications of this kind abound.
exchange of  patient data in distributed brain tumour diagnosis [2]) -  however, they may permit the exchange of local learning  hypotheses among different learners.
with the overall objective of improving their own  learning results).
In the areas of machine learning and data mining (cf.
Furthermore, agents might have a vested interest in negatively affecting other agents" learning performance.
In other areas, training data might be commercially valuable, so that agents would only make it available to others if those agents could  provide something in return (e.g.
in remote ship surveillance and tracking, where the different agencies involved are  commercial service providers [1]).
[3, 10, 21]).
