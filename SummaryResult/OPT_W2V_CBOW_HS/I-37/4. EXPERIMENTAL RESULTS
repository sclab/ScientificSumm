The Single Agent is learning from the whole dataset.
Apart from these obvious performance benefits,  integrating partial learning results can also have other advantages: The m-filter operation, for example, decreases the number of learning samples and thus can speed up the learning  process.
k-means k-medoids filtering 30-40 % 10-20 % m-filtering 20-30 % 5-15 % The overall conclusion we can draw from these initial  experiments with our architecture is that since a very  simplistic application of its principles has proven capable of  improving the performance of individual learning agents, it is worthwhile investigating more complex forms of  information exchange about learning processes among autonomous learners. 
To generate sufficiently realistic properties for fake ships, their individual attribute values are taken from randomly selected ships in the validation set (so that each fake sample is a combination of attribute values of several existing ships).
As can be seen from the performance plots in Figure 3 (homogeneous case) and 4 (heterogeneous case, two agents use the same method and one agent uses the other) this is clearly the case for the (unrestricted) join and filter  integration operations (m = k) in both cases.
For m-join and m-filter we assume m = 3 to limit the extent to which models increase over time.
Each ship is described using width, length, draught and speed attributes with the goal of learning to detect which vessels have provided fake descriptions of their own properties.
This nicely  illustrates how different learning or data mining algorithms can specialise on different parts of the problem space and then integrate their local results to achieve better individual  performance.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 683 Figure 4: Performance results obtained for  different integration operations in heterogeneous societies with the majority of learners using the k-means (top) and k-medoids (bottom) methods namely that these perform similarly to the isolated learner case in homogeneous agent groups but better than isolated learners in more heterogeneous societies.
The relative number of filtered examples measured in our experiments is shown in the following table.
Thereby, we distinguish between homogeneous learner societies where all agents use the same clustering algorithm and  heterogeneous ones where different agents use different algorithms.
For m-select we assume m = k which achieves a constant Figure 3: Performance results obtained for different integration operations in homogeneous learner  societies using the k-means (top) and k-medoids  (bottom) methods model size.
In these experiments, we are mainly interested in  investigating whether a simple form of knowledge sharing between self-interested learning agents could improve agent  performance compared to a setting of isolated learners.
For the restricted (m < k) m-join, m-filter and m-select methods we can also observe an interesting distinction, The Sixth Intl.
We can see that the quality of these operations is very close to the Single Agent that has access to all training data.
During each experiment the learning agents receive ship descriptions in batches of 10 samples.
Figure 3 shows results obtained from simulations with three learning agents in the above system using the k-means and k-medoids clustering methods respectively.
Between these batches, there is enough time to exchange the models among the agents and recompute the models if necessary.
This suggests that heterogeneous learners are able to benefit even from rather limited knowledge sharing (and this is what using a rather small m = 3 amounts to given that k = 10) while this is not always true for homogeneous agents.
We  partition the total dataset of 300 ships into three disjoint sets of 100 samples each and assign each of these to one learning agent.
The parameter k is set to 10 as this is the optimal value for the total dataset according to the Davies-Bouldin index [9].
This is quite natural, as these operations amount to sharing all available model knowledge among agents (under appropriate constraints  depending on how beneficial the exchange seems to the agents).
The validation set contains 100 real and 100 randomly generated fake ships.
Joint Conf.
