We are aware of the long learning phase in environments with a large number of shared resources known by each agent.
A simple decision mechanism based on different beliefs of the agent creates an emergent behaviour that leads to effective resource  allocation.
This  process of acquiring resource load information about all servers can take a long time in the case that no not enough shared resources for all tasks are provided.
Our approach adapts to changes in the environment but it is not evolutionary.
It is a distributed, scalable and easy-to-understand  policy for the regulation of supply and demand of resources.
In the near future we will investigate if an automatic  adaptation of the decay rate of historical information our  algorithm is possible and can improve the resource allocation performance.
Agents sense their server  environment and adopt their action to compete more efficient in the new created environment.
In the case of a server becomes  unavailable, the agents can adapt quickly to this new situation by exploring new resources or remain at the home server if an allocation is not possible.
In this situation, it is difficult for an agent to efficiently gather historical information about all remote servers.
Our self-organising resource allocation approach was  evaluated with a number of simulation experiments in a dynamic environment of agents and server resources.
In our  approach the agents compete for an allocation at one of the 0 500 1,000 1,500 2,000 Time 0 2,500 5,000 7,500 ResourceLoad (a) Total resource load  versus total shared resource  capacity 0 500 1,000 1,500 2,000 Time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 ResourceLoad (b) Resource load server 1 0 500 1,000 1,500 2,000 Time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 ResourceLoad (c) Resource load server 2 0 500 1,000 1,500 2,000 Time 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 ResourceLoad (d) Resource load server 3 Figure 5: Results of experiment 2 in a dynamic server environment averaged over 100 repetitions.
The decay rate is currently predefined and must be altered manually depending on the environment.
The evolution would be very slow and selective and will not influence the system behaviour in a short-term period that is covered by our experimental results.
Our mechanism demonstrates that resource allocation can be done by the effective  competition of individual and autonomous agents.
In the case that more resources are requested by agents than shared resources are provided by all servers, all agents will randomly explore all known servers.
In contrast, a dynamic environment with varying capacities requires more up-to-date information to make more reliable predictions.
This approach can be easily extended or supported by resource balancing/queuing mechanisms provided by  resources.
The resource allocation is a purely emergent effect.
In fact, we believe that this could further improve the system"s behaviour over a long term period and could be 80 The Sixth Intl.
This process is adaptive and has a strong feedback as allocation decisions influence  indirectly decisions of other agents.
Especially in dynamic and scalable environments such as grid systems, a robust and distributed mechanism for resource allocation is required.
In the worst case, by the time for exploring all servers, historical information of some servers could be already outdated and the exploration starts again.
There is no discovery of new strategies by the agents.
This mechanism was inspired by inductive reasoning and bounded rationality principles which enables the agents"  adaptation of their strategies to compete effectively in a  dynamic environment.
We enable agents to select the execution platform for their tasks themselves before each execution at run-time.
This issue needs more investigation in the future. 
In this paper a self-organising distributed resource  allocation technique for multi-agent systems was presented.
The presented results for this new approach for strategic migration  optimisation are very promising and justify further investigation in a real multi-agent system environment.
A large number of shared resources requires older historical information to avoid a too frequently resources exploration.
All control is implemented in the agents.
Neither do they need coordination or information from a higher authority nor is an additional direct communication between agents required.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) investigated in the future.
available shared resource.
The set of predictors stays the same over the whole life.
Joint Conf.
