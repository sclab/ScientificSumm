If a player suffers turnover, she leaves the system and is replaced with a newcomer who uses the same strategy as the exiting player.
This information consists of both her  personal observations of strategy performance and the observations of those players she interacts with.
The players use a strategy to decide how to act.
• Untraceable Defections: A peer should not be able to  determine the identity of peers who have defected on her.
Our model is designed to have the following properties that  characterize a large set of P2P systems: • Social Dilemma: Universal cooperation should result in  optimal overall utility, but individuals who exploit the  cooperation of others while not cooperating themselves (i.e.,  defecting) should benefit more than users who do cooperate.
Defection dominates cooperation (at least weakly) at the  individual level for the entity who decides whether to  cooperate or defect: (Ts ≥ Rs and Ps ≥ Ss and (Ts > Rs or Ps > Ss)) The last set of inequalities assume that clients do not incur a cost regardless of whether they cooperate or defect, and therefore clients always cooperate.
At the end of a round, a player switches to  highest rated strategy with a probability proportional to the difference in score between her current strategy and the highest rated strategy.
For example, to model a P2P application like file sharing or  overlay routing, we use the specific payoff matrix values shown in  Figure 3.
In this section, we present our assumptions about P2P systems and their users, and introduce a model that aims to capture the behavior of users in a P2P system.
2.3 Generalized Prisoner"s Dilemma The Prisoner"s Dilemma, developed by Flood, Dresher, and Tucker in 1950 [22] is a non-cooperative repeated game satisfying the  social dilemma requirement.
Request Service Don't Request 7 / -1 0 / 0 0 / 0 0 / 0 Provide Service Ignore Request Client Server Figure 3: The payoff matrix for an application like P2P file sharing or overlay routing.
1The exception is discussed in Section 4.1.1 103 Cooperate Defect Cooperate DefectClient Server sc RR / sc ST / sc PP / sc TS / Figure 2: Payoff matrix for the Generalized Prisoner"s Dilemma.
In the GPD, one player is the client and one player is the server in each game, and it is only the decision of the server that is meaningful for determining the outome of the transaction.
Each game consists of two players who can defect or cooperate.
Furthermore, one or more of the four possible actions (client  cooperate and defect, and server cooperate and defect) can be  untraceable.
In particular, we model the benefits and costs of P2P interactions (the game) and population dynamics caused by mutation, learning, and turnover.
Let s be the running  average of the performance of a player"s current strategy per round and age be the number of rounds she has been using the strategy.
Instead, we use the Generalized Prisoner"s Dilemma (GPD), which specifies the general form for an asymmetric payoff matrix that  preserves the social dilemma.
We assume that users can pollute shared history with false  recommendations (Section 4.2), switch identities at zero-cost  (Section 4.3), and spoof other users (Section 4.4).
To learn, a player collects local information about the performance of different strategies.
If one player makes an untraceable action, the other player does not know the identity of the first player.
2.1 Assumptions We assume a P2P system in which users are strategic, i.e., they act rationally to maximize their benefit.
This models the difficulty or expense of determining that a peer could have provided a service, but didn"t. For example, in the Gnutella file sharing system [21], a peer may simply ignore queries despite possessing the desired file, thus preventing the querying peer from identifying the defecting peer.
Several studies [4] [28] of repeated Prisoner"s Dilemma games use an evolutionary model [19] [34] of population dynamics.
These properties correspond to similar properties of the classic Prisoner"s Dilemma and allow any form of  asymmetric transaction while still creating a social dilemma.
Depending how each acts, the players  receive a payoff.
• Dynamic Population: Peers should be able to change their behavior and enter or leave the system independently and continuously.
For example, it may specify that a population of 5 100%  Cooperate players and 5 100% Defect players evolves into a population with 3 and 7 players, respectively.
2.2 Model To aid the development and study of the incentive schemes, in this section we present a model of the users" behaviors.
A GPD payoff  matrix must have the following properties to create a social dilemma: 1.
• Asymmetric Transactions: A peer may want service from another peer while not currently being able to provide the service that the second peer wants.
This satisfies the inequalities specified above, where only the server can choose between cooperating and defecting.
2.4 Population Dynamics A characteristic of P2P systems is that peers change their  behavior and enter or leave the system independently and continuously.
In each round, every player plays one game as a client and one game as a server.
A player can be a client in one game and a server in another.
Unfortunately, existing work either uses a specific asymmetric payoff matrix or only gives the general form for a symmetric one [4].
An  evolutionary model is not suitable for P2P systems because it only  specifies the global behavior and all changes occur at discrete times.
If she maintains her identity after switching strategies, then she is referred to as a traitor.
In addition, for this particular payoff matrix, clients are unable to trace server defections.
In our model, entities take independent and continuous actions that change the composition of the population.
At the end of a round, a player may: 1) mutate 2) learn, 3) turnover, or 4) stay the same.
Finally, we assume that all transactions incur the same cost to all servers and provide the same benefit to all clients.
However, to capture some of the real-life unpredictability in the behavior of users, we allow users to randomly change their behavior with a low probability (see Section 2.4).
If a player mutates, she switches to a randomly picked strategy.
For simplicity, we assume a homogeneous system in which all peers issue and satisfy requests at the same rate.
Furthermore, all the switching occurs at the end of a generation instead of continuously, like in a real P2P system.
If she learns, she switches to a strategy that she believes will produce a higher score (described in more  detail below).
Transactions should be able to have asymmetric payoffs.
It does not specify which specific players switched.
As a result, evolutionary population dynamics do not accurately model turnover, traitors, and strangers.
A peer can satisfy any request, and, unless otherwise specified, peers request service  uniformly at random from the population.1 .
The client and server receive the payoff from a generalized payoff matrix (Figure 2).
Mutual cooperation leads to higher payoffs than one player suckering the other (Rs + Rc > Sc + Ts and Rs + Rc > Ss + Tc).
We use the age and compute the running average before the ratio to prevent young samples (which are more likely to be outliers) from skewing the rating.
This models users communicating out-of-band about how strategies perform.
Rc, Sc, Tc, and Pc are the client"s payoff and Rs, Ss, Ts, and Ps are the server"s payoff.
This is the payoff matrix that we use in our simulation results.
Mutual cooperation leads to higher payoffs than mutual  defection (Rs + Rc > Ps + Pc).
We do not assume any centralized trust or centralized infrastructure.
A strategy"s rating is RunningAverage(s ∗ age) RunningAverage(age) .
Time consists of rounds.
T, R, P, and S stand for temptation, reward, punishment and sucker,  respectively.
