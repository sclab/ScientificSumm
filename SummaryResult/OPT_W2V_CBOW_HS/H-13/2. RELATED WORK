Most related research in the area of document summarization has focused on newspaper articles and  similar material, rather than Web pages, and has conducted  evaluations by comparing automatically generated summaries with manually generated summaries.
While commercial Web search engines have followed  similar approaches to caption display since their genesis,  relatively little research has been published about methods for generating these captions and evaluating their impact on user behavior.
2.1 Display of Web results Varadarajan and Hristidis [16] are among the few who have attempted to improve directly upon the snippets  generated by commercial search systems, without introducing additional changes to the interface.
[18] present several methods for associating queries with documents by analyzing clickthrough patterns and links  between documents.
[17] evaluated three alternatives to the  standard Web search interface: one that displays expanded  summaries on mouse hovers, one that displays a list of top  ranking sentences extracted from the results taken as a group, and one that updates this list automatically through  implicit feedback.
They evaluated their method by asking users to compare snippets from the various sources.
They generated  snippets from spanning trees of document graphs and  experimentally compared these snippets against the snippets  generated for the same documents by the Google desktop search system and MSN desktop search system.
A considerable fraction of later work may be viewed as extending and tuning this basic approach, developing  improved methods for identifying significant words and  selecting sentences.
Of particular interest to us is the work of Joachims et al.
The query-independent snippets were created by extracting the first few sentences of the articles; the query-dependent snippets were created by selecting the highest scoring  sentences under a measure biased towards sentences containing query terms.
For example, a click at position N + 1 - after skipping the result at position N - may be viewed as a preference for the result at position N+1 relative to the result at position N. These findings form the basis of the clickthrough inversion methodology we use to interpret user interactions with search results.
2.2 Document summarization Outside the narrow context of Web search considerable  related research has been undertaken on the problem of  document summarization.
2.3 Clickthroughs Queries and clickthroughs taken from the logs of  commercial Web search engines have been widely used to improve the performance of these systems and to better understand how users interact with them.
A number of other researchers have examined the value of query-dependent summarization in a non-Web context.
Their goal was to improve the ability of users to interact with a given result set, helping them to look  beyond the first page of results and to reduce the burden of query re-formulation.
At its  simplest, snippet generation for Web captions might also be viewed as following this approach, with query terms taking on the role of significant words.
Cutrell and Guan [4] conducted an eye-tracking study to investigate the influence of snippet length on Web search performance and found that the optimal snippet length  varied according to the task type, with longer snippets leading to improved performance for informational tasks and shorter snippets for navigational tasks.
For example, a recent paper by Sun et al.
In early work, Broder [3] examined the logs of the AltaVista search engine and  identified three broad categories of Web queries: informational, navigational and transactional.
In effect, they are added to the document content for indexing and ranking purposes.
[5] compared an interface typical of those used by major Web search engines with one that groups results by category, finding that users perform search tasks faster with the category interface.
interpreted caption features, clickthroughs and other user behavior as implicit feedback to learn  preferences [2] and improve ranking [1] in Web search.
They conducted eye-tracking studies and analyzed log data to determine the extent to which clickthrough data may be treated as implicit relevance judgments.
[14] describes a variant of Luhn"s algorithm that uses clickthrough data to identify significant words.
[10] used clickthrough patterns to  automatically categorize queries into one of two categories:  informational - for which multiple Websites may satisfy all or part of the user"s need - and navigational - for which users have a particular Website in mind.
Luhn"s approach uses term frequencies to identify  significant words within a document and then selects and extracts sentences that contain significant words in close proximity.
Over the years DUC has included both single-document summarization and  multidocument summarization tasks.
When query-dependent summaries were  presented, subjects were better able to identify relevant  documents without clicking through to the full text.
Given a topic and 25 documents, participants were asked to generate a 250-word summary satisfying the information need enbodied in the topic.
The majority of  participating systems use extractive summarization, but a number attempt natural language generation and other approaches.
In their system, sentences are ranked by combining statistical and linguistic features.
Each year DUC defines a methodology for one or more experimental tasks, and supplies the necessary test documents, human-created summaries, and automatically extracted baseline summaries.
Xue et al.
Queries associated with documents in this way are treated as meta-data.
We view our approach of  evaluating summarization through the analysis of Web logs as complementing the approach taken at DUC.
Agichtein et al.
Evaluation at DUC is achieved through comparison with manually generated summaries.
Tombros and Sanderson [15] compared the performance of 20 subjects searching a collection of newspaper articles when 2 duc.nist.gov guided by query-independent vs. query-dependent snippets.
Lee et al.
The basic idea of extractive  summarization - creating a summary by selecting sentences or fragments - goes back to the foundational work of Luhn [11].
Our examination of large search logs compliments their detailed analysis of a smaller number of participants. 
[12] propose an interface based on a fisheye lens, in which mouse hovers and other events cause captions to zoom and snippets to expand with additional text.
Goldstein et al.
In addition, they explored techniques that treat clicks as pairwise preferences.
Many researchers have explored alternative methods for displaying Web search results.
Paek et al.
[6] describe another extractive system for generating query-dependent summaries from newspaper  articles.
Dumais et al.
Most research on the display of Web results has proposed substantial interface changes, rather than addressing details of the existing  interfaces.
They identified a trust bias, which leads users to prefer the higher ranking result when all other factors are equal.
Rose and Levinson [13]  conducted a similar study, developing a hierarchy of query goals with three top-level categories: informational, navigational and resource.
[9] and Granka et al.
They treat the length of time that a user spends viewing a summary as an implicit indicator of  relevance.
They introduce  normalized measures of recall and precision to facilitate evaluation.
Under their taxonomy, a transactional query as defined by Broder might fall under either of their three categories, depending on details of the desired transaction.
Since 2000, the annual Document Understanding  Conference (DUC) series, conducted by the US National Institute of Standards and Technology, has provided a vehicle for evaluating much of the research in document  summarization2 .
Under their taxonomy, a transactional or resource query would be subsumed under one of these two categories.
White et al.
The main DUC 2007 task is posed as taking place in a question answering context.
