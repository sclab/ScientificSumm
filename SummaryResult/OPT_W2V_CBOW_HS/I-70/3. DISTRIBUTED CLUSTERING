Because of this, the similarity computations are done twice for each agent pair.
That is why a system like ASIUM [6] tries to soften the problem with a system-user collaboration by showing to the ontologist the created classes after each step of reasoning.
It is bootstrapped in the following way: • a TOP agent having no parent is created, it will be the root of the resulting taxonomy, • an agent is created for each term to be positioned in the  taxonomy, they all have TOP as parent.
Unfortunately, in this case, all the reasoning steps that occurred after the creation of the modified class are lost and must be recalculated by taking the  modification into account.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1287 The hierarchy resulting from algorithm 1 is always a binary tree because of the way grouping is done.
For the sake of understanding, and because of its  evaluation in section 3.1, we recall the basic centralized algorithm used for a hierarchical ascending clustering in a non metric space, when a symmetrical similarity measure is available [15] (which is the case of the measures used in our system).
Thanks to the received messages indicating the preferences of its children, P can determine three sub-groups among its children: • the child which got the most "votes" by its brothers, that is the child being the most dissimilar from the greatest number of its brothers.
The new stable state if the one of figure 7.
Finally for each run of the "while" loop, l is decreased from n to 1 which gives us t1(n) as the amount of similarity computations for algorithm 1: t1(n) = nX l=1 l × (l − 1) 2 (1) For the distributed algorithm, at a given step, each one of the l agents evaluates the similarity with its l −1 brothers.
Then, groups are created and another vote occurs with l decreased by one (since we assume worst case, only groups of size 2 or l −1 are built).
Then P receives the same kind of message from each of its children.
Figure 7: Concept agent tree after ontologist modification Then, the ontologist replaces the concept in the right branch, by affecting "ConceptAgent:8" as its new parent.
The highest degree term of this polynomial is in n2 log(n), then our distributed algorithm has a O(n2 log(n)) complexity on average.
Ak−1 Ak AnA2A1 P ...... ...... A1 Figure 2: Distributed classification: Step 1 The process first step (figure 2) is triggered when an agent (here Ak) has more than one brother (since we want to obtain a binary tree).
The second "for" loop is ran l times for i ranging from 1 to l. Then its cost is Pl i=1(l − i) which can be simplified in l×(l−1) 2 .
It happens that the similarity computations place it closer to "femme" (woman) and "chirurgien" (surgeon) than to "infection", "gastro-entérite" (gastro-enteritis) and "hépatite" (hepatitis).
Algorithm 1: Centralized hierarchical ascending clustering  algorithm Data: List L of items to organize as a hierarchy Result: Root R of the hierarchy while length(L) > 1 do max ← 0; A ← nil; B ← nil; for i ← 1 to length(L) do I ← L[i]; for j ← i + 1 to length(L) do J ← L[j]; sim ← similarity(I, J); if sim > max then max ← sim; A ← I; B ← J; end end end remove(A, L); remove(B, L); append((A, B), L); end R ← L[1]; In algorithm 1, for each clustering step, the pair of the most  similar elements is determined.
Indeed, the hierarchy created by the system is meant to be modified by the ontologist since it is the result of a statistic  computation.
In case of a draw, one of the winners is chosen randomly (here A1), • the children that allowed the "election" of the first group, that is the agents which chose their brother of the first group as being the most dissimilar one (here Ak to An), • the remaining children (here A2 to Ak−1).
It can be explained by the low probability that a data set forces the system to create only minimal groups (two items) or maximal (n − 1 elements) for each step of reasoning.
This system-user coupling is necessary to build an ontology, but no particular adjustment to the distributed algorithm principle is needed since each agent does an autonomous local processing and communicates with its neighborhood by messages.
We could conceive that an agent sends its computation result to its peer.
Then P creates a new agent P (having P as parent) and asks agents from the second group (here agents Ak to An) to make it their new parent.
the maximum sub-phrase located as tail of the term The Sixth Intl.
Figure 6: Concept agent tree after autonomous stabilization of the system In order to illustrate our claims, we present an example thanks to a few screenshots from the working prototype tested on a medical related corpus.
Since l is equal to n on first run, we obtain tdist(n) as the amount of similarity computations for the distributed algorithm: tdist(n) = nX l=1 l × (l − 1) (2) Both algorithms then have an O(n3 ) complexity.
However in a few cases we can reach a "circular conflict" in the voting procedure when for example A votes against B, B against C and C against A.
It requires to begin with a quantitative evaluation, based on its  complexity, while comparing it with the algorithm 1 from the previous section.
For algorithm 1, we note l = length(L), then the most enclosed "for" loop is run l − i times.
For the distributed algorithm, the worst case means that for each run, only a two-item group can be created.
It is executed concurrently in each of the agents of the system.
During the necessary look at the texts to examine the usage contexts of terms [2], the ontologist will be able to interpret the real content and to revise the system proposal.
Ak−1 Ak AnA2A1 P P" ...... ...... P" P" Figure 3: Distributed clustering: Step 2 Next, when P has got messages from all its children, it starts the second step (figure 3).
The communication between agents is then done by sending messages and each one keeps its decision autonomy.
In most cases, one has to find which reasoning step generated the error and to manually modify the resulting class.
And its body has the only similarity computation, so its cost is l−i.
Note that this algorithm generally converges, since the number of brothers of an agent drops.
On the contrary, it would only require to  rework the communication layer and the agent creation process since in our current implementation those are not networked. 
3.2 Qualitative Evaluation Although the quantitative results are interesting, the real  advantage of this approach comes from more qualitative characteristics that we will present in this section.
Once this basic structure is set, the algorithm runs until it reaches equilibrium and then provides the resulting taxonomy.
It results in the plots of figure 5.
When an agent has only one remaining brother, its activity stops (although it keeps processing messages coming from its children).
This gap comes from the local decision making in each agent.
But in the worst case, the distributed algorithm does twice the number of  el1288 The Sixth Intl.
Those choices have an impact on the resulting tree, but they impact neither the global execution of the algorithm nor its complexity.
In the following, this kind of message will be called a "vote".
The children rejected by P (here agent A2 to An) take its message into account and choose P as their new parent.
Its theoretical complexity is calculated for the worst case, by considering the similarity computation operation as elementary.
By using test data and letting the system work by itself, we obtain the hierarchy from figure 6 after stabilization.
But, it would simply move the problem by generating more communication in the system.
This wrong position for "lesion" is explained by the fact that without ontologist input the reasoning is only done on statistics criteria.
Under those conditions, for a given dataset of n items, we can determine the amount of similarity computations.
Then, a system modification to make it run networked would not require to adjust the algorithm.
Then it sends a message to its parent P indicating its most dissimilar brother (here A1).
In the worst case for 100 terms, the variation is of 1,960.75 for an average of 40,550.10 (around 5%) which shows the good stability of the system.
2 i.e.
Note that, in the following of this paper, we used for both  algorithms an Anderberg similarity (with α = 0.75) and an average link clustering strategy [15].
With the current system no decision can be taken.
Those two elements are grouped in a cluster, and the resulting class is appended to the list of remaining elements.
Figure 4: Distributed clustering: Step 3 Finally, step 3 (figure 4) is trivial.
The algorithm is then more  efficient on average than the centralized algorithm, and its average complexity is below the worst case.
Centralized algorithm Figure 5: Experimental results In a second step, the average complexity of the algorithm has been determined by experiments.
The name  "ConceptAgent:X" is automatically given to a concept agent that is not described by a term.
The given value is the average of  comparisons made for one hundred of runs without any user interaction.
The current procedure should be improved to address this, probably using a ranked voting method.
The main advantage to the use of a multi-agent system for a  clustering task is to introduce dynamic in such a system.
Finally, let"s note the reduced variation of the average performances with the maximum and the minimum.
It is clear that the concept described by the term "lésion" (lesion) is  misplaced.
Curve number 2 represents the logarithmic polynomial minimizing the error with curve number 1.
Moreover grouping the most similar elements is equivalent to moving them away from the least similar ones.
The ontologist can make modifications and the hierarchy adapts depending on the request.
The system reacts by itself and refines the clustering hierarchy to obtain a binary tree by creating  "ConceptAgent:11".
This section presents the distributed clustering algorithm used in Dynamo.
We now present the distributed algorithm used in our system.
Distributed algorithm (on average, with min and max) 2.
This algorithm stops when the list has only one element left.
All are advantages obtained thanks to the use of an adaptive multi-agent system.
So each steps has a l × (l − 1) cost.
The multi-agent system has been executed with randomly generated input data sets ranging from ten to one hundred terms.
The hierarchy just created a new intermediate level.
Our distributed algorithm is designed relying on those two facts.
Moreover, this algorithm can de facto be distributed on a  computer network.
It is extremely difficult to realize this with a centralized "black-box" approach.
3.1 Quantitative Evaluation Now, we evaluate the properties of our distributed algorithm.
But, the ontologist can make a mistake, and become aware of it too late.
Joint Conf.
Joint Conf.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) ementary operations done by the centralized algorithm.
It is particularly interesting in a knowledge engineering context.
Logarithmic polynomial 3.
Ak−1 Ak AnA2A1 P P" ...... ......
0 20000 40000 60000 80000 100000 120000 140000 160000 180000 10 20 30 40 50 60 70 80 90 100 Amountofcomparisons Amount of input terms 1.
