In this paper, however, we address the case in which agents are already endowed with a top-down engineered ontology (it can even be the same one), which they do not adapt or refine, but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation.
Their semantic alignment, however, will only be valid in the scope of their interaction within this particular situation or environment.
We state that these syntactic entities can be related according to the  intrinsic semantics provided by the existing relationship  between the agents" viewpoint of the environment.
First, in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents" viewpoints of the environment.
This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent, bottom-up manner, with only local interactions and no central control authority [12].
Although the conceptualisation of ‘left" and ‘right" is done in exactly the same manner by both agents, and even if both use the terms left and right in their communication, they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board.
In Section 2 we describe our formal model for Situated Semantic Alignment (SSA).
We claim that semantic alignment of ontological  terminology is ultimately relative to the particular situation in which the alignment is carried out, and that this situation should be made explicit and brought into the alignment  mechanism.
The  existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment.
Nevertheless, the techniques used by these systems to  establish the semantic relationships between ontological entities -even though applied at run-time- still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched, use previously existing external sources such as thesauri (e.g., WordNet) and upper-level ontologies (e.g., CyC or SUMO), or resort to additional background knowledge repositories or shared instances.
Multi-agent communication, peer-to-peer information sharing, and  webservice composition are all of a decentralised, dynamic, and open-ended nature, and they require ontology matching to be locally performed during run-time.
Second, in Section 2.2 we present a method by which agents obtain approximations of this distributed logic.
We do not assume any knowledge of Channel Theory; we restate basic definitions and theorems in the appendix, but any detailed exposition of the theory is outside the scope of this paper. 
Because of these differences there may be a mismatch in the meaning of the syntactic  entities by which agents describe their perceptions (and which constitute the agents" respective ontologies).
We shall therefore consider a scenario with two or more agents situated in an environment.
But the proliferation of many diverse ontologies caused by different  conceptualisations of even the same domain -and their subsequent specification using varying terminology- has highlighted the need of ontology matching techniques that are  capable of computing semantic relationships between entities of separately engineered ontologies.
As such, ontologies have been widely adopted as a key technology that may favour knowledge sharing in  distributed environments, such as multi-agent systems,  federated databases, or the Semantic Web.
This theory is  particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations -or tokens- that carry information.
In particular, we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligman"s theory of information flow [1].
Finally, an appendix summarizes the terms and theorems of Channel theory used along the paper.
[5, 11] Until recently, most ontology matching mechanisms  developed so far have taken a classical functional approach to the semantic heterogeneity problem, in which ontology matching is seen as a process taking two or more  ontologies as input and producing a semantic alignment of  ontological entities as output [3].
This sort of self-organised emergence of shared meaning is namely  ultimately grounded on the physical interaction of agents with the environment.
Analogously, the semantic alignment that will allow  information to flow ultimately will be carried by the particular situation agents are acting in.
In Section 3 we report on an application of our method.
Each agent will have its own viewpoint of the environment so that, if the  environment is in a concrete state, both agents may have different perceptions of this state.
Even two agents with identical conceptualisation  capabilities, and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperate 1278 978-81-904262-7-5 (RPS) c 2007 IFAAMAS in a concrete situation because of their differing perception of the domain.
An ontology is commonly defined as a specification of the conceptualisation of a particular domain.
These approximations gradually become more reliable as the method is applied.
It fixes the  vocabulary used by knowledge engineers to denote concepts and their relations, and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledge engineers.
The same agents situated differently may produce a different alignment.
Imagine a situation in which two agents are facing each other in front of a checker board.
This might have been successful for clearly delimited and stable domains and for closed distributed systems, but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems.
Conclusions and further work are analyzed in Section 4.
In addition, in many situations peer ontologies are not even open for inspection (e.g., when they are based on commercially confidential  information).
Certainly, there exist efforts to efficiently match  ontological entities at run-time, taking only those ontology  fragment that are necessary for the task at hand [10, 13, 9, 8].
Furthermore, matching  often has been carried out at design-time, before  integrating knowledge-based systems or making them interoperate.
Agent A1 may conceptualise a figure on the board as situated on the left margin of the board, while agent A2 may  conceptualise the same figure as situated on the right.
