In order to learn a Bayesian hierarchical model, the  system usually tries to find the most likely model parameters for the given data.
It is well known that  learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users.
One major challenge of building a recommendation or  personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small.
The proposed technique is not only well supported by theory, but also by experimental results.
Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information, thus alleviating poor initial  performance for each user[27][25].
The basic idea is that instead of  calculating the numerical solution for all the user profile parameters, we derive the analytical solution of the parameters for some feature dimensions, and at the M step use the analytical  solution instead of the numerical solution estimated at E step for those parameters.
Recent offerings such as My MSN, My Yahoo!, My Google, and Google News have attracted much attention due to their potential ability to infer a user"s interests from his/her history.
One well-received approach to improve recommendation system performance for a particular user is borrowing  information from other users through a Bayesian hierarchical modeling approach.
The effectiveness of these different approaches is mixed, due to how well the underlying model assumption fits the data.
Learning the user profiles is the core problem for these systems.
There has been much research on improving  classification accuracy when the amount of labeled training data is small.
These systems learn user-specific  profiles from user feedback so that they can recommend  information tailored to each individual user"s interest without requiring the user to make an explicit query.
The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee.
Section 4 describes how to learn the model parameters using the standard EM algorithm, along with using the new technique proposed in this paper.
This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile.
Personalization is the future of the Web, and it has achieved great success in industrial applications.
A user profile is usually a classifier that can identify whether a document is relevant to the user or not, or a regression model that tells how relevant a document is to the user.
The semi-supervised learning approach combines  unlabeled and labeled data together to achieve this goal [26].
However, a content based  recommendation system often handles documents in a very high dimensional space, in which each document is represented by a very sparse vector.
In this paper, the words filtering and recommendation are used  interchangeably.
With careful analysis of the EM algorithm in this scenario (Section 4), we find that the EM tering, or item-based collaborative filtering.
This greatly reduces the computation at a single EM iteration, and also has the benefit of  increasing the convergence speed of the learning algorithm.
The third approach is borrowing training data from other resources [5][7].
The organization of the remaining parts of this paper is as follows: Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based  recommendations.
One major personalization topic studied in the  information retrieval community is content-based personal  recommendation systems1 .
This paper modifies the standard EM algorithm to create an improved learning algorithm, which we call the Modified EM algorithm.
Another approach is using domain knowledge.
The  experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6.
We also find that updating the model parameter at each EM iteration is also expensive with  computational complexity of O(MK), where M is the number of users and K is the number of dimensions.
Researchers have modified different learning algorithms, such as  Na¨ıveBayes [17], logistic regression [7], and SVMs [22], to integrate domain knowledge into a text classifier.
A mature recommendation system  usually works for millions of users.
algorithm converges very slowly due to the sparseness of the input variables.
For example, online stores, such as Amazon and Netflix, provide customized  recommendations for additional products or services based on a user"s history.
This is known as the cold start problem.
Section 7 summarizes and offers concluding remarks. 
