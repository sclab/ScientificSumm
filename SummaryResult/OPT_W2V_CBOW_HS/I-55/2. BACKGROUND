Thus, for each agent i, there is a value function σi : Rni → R. In particular, Raiffa [17] shows how to systematically  construct an additive value function to each party involved in a negotiation.
An outcome o ∈ O is  represented by an assignment of values to the corresponding attributes in Att.
Assuming that money transfer between agents is possible, the set Att then contains three attributes: • T, taking values from the set {0, 1}, indicates whether the task T is assigned to agent B; • R, taking values from the set of non-negative integer,  indicates the amount of resource R being allocated to agent B; and • MT, taking values from R, indicates the payment p to be transferred from A to B.
, Xk(a)) denotes the consequence of the act a to the decision maker M. By definition, objectives are statements that delineate the desires of a decision maker.
Part of the solution to this problem is that M has to try to identify the Pareto frontier in the consequence space {(X1(a), .
A set of alternative outcomes O.
Agent A has a task T that needs to be done and also 100 units of a resource R. Agent B has the capacity to perform task T and would like to obtain at least 10 and at most 20 units of the resource R. Agent B is indifferent on any amount between 10 and 20 units of the resource R. The objective functions for both agents A and B are cost and revenue.
While the Pareto 1x d2 a (X (a),X (a)) d1 1 x2 2 Alternative spaceA Pareto frontier Consequence space optimal consequenc Figure 1: The Pareto frontier frontier allows M to avoid taking inefficient decisions, M still has to decide which of the efficient consequences on the Pareto frontier is most preferred by him.
(Attributes are also referred to as  issues, or decision variables.)
Consider the outcome o = [T = 1, R = k, MT = p], i.e., the task T is assigned to B, and A allocates to B with k units of the resource R, and A transfers p dollars to B.
x dominates x iff xi > xi for all i, and the inequality is strict for at least one i.
Consequences can then be ordered: if the gains in satisfaction brought about by C1 (in comparison to C2) equals to the losses in satisfaction brought about by C1 (in  comparison to C2), then the two consequences C1 and C2 are considered indifferent.
To measure how much an  outcome o fulfills an objective j to an agent i, we use objective functions: for each agent i, we define i"s interests using the objective vector function fi = [fij ] : O → Rni .
2.1 Multi-criteria decision making theory Let A denote the set of feasible alternatives available to a  decision maker M. As an act, or decision, a in A may involve  multiple aspects, we usually describe the alternatives a with a set of attributes j; (j = 1, .
The Pareto frontier in a consequence space then consists of all consequences that are not dominated by any other consequence.
There are two agents, A and B.
1 in which an alternative consists of two attributes d1 and d2 and the decision maker tries to maximise the two objectives X1 and X2.
, αm} characterising the  issues the agents are negotiating over.
Agent B obtains a revenue rB,R for each unit of the resource R while providing each unit of the resource R costs agent A cA,R.
Agents" utility: Based on the theory of multiple-criteria decision making [8], we define the agents" utility as follows: • Objectives: Agent i has a set of ni objectives, or interests; denoted by j (j = 1, .
That is, he may have to choose an act a ∈ A that does not optimise every objective.
• Utility: Now, given an outcome o ∈ O, an agent i is able to determine its value, i.e., σi(fi(o)).
Each attribute α can take a value from the set V alα; 3.
• Value functions: Instead of directly evaluating an outcome o, agent i looks at how much his objectives are fulfilled and will make a valuation based on these more basic criteria.
MCDM theorists introduce a mechanism to allow the objective components of consequences to be normalised to the payoff  valuations for the objectives.
A typical decision maker also has  several objectives X1, .
In this paper, we ignore those side-effects and assume that agent i"s utility function ui is normalised so that ui : O → [0, 1].
A set of two negotiating agents N = {1, 2}.
However, as discussed thoroughly by Keeney and Raiffa [8], it is quite likely that a decision maker"s objectives will conflict with each other in that the improved achievement with one objective can only be accomplished at the expense of another.
This is the topic of the multi-criteria decision making theory.
Thus, M wishes to  maximise his objectives.
A decision a ∈ A whose consequence does not lie on the Pareto frontier is inefficient.
Then, costA(o) = k.cA,R + p and revA(o) = rA,T ; and costB(o) = cB,T and revA(o) = j k.rB,R + p if 10 ≤ k ≤ 20 p otherwise.
Due to the conflicting nature of a decision maker"s objectives, M usually has to settle at a compromise solution.
The Sixth Intl.
The most  preferred indifference curve that intersects with the Pareto frontier is in focus: its intersection with the Pareto frontier is the sought after consequence (i.e., the optimal consequence in Fig.
Since better services can often only be attained for a price, these  objectives conflict.
Thus, a tuple (x1, .
The standard way to implement such a thing is to allow money 1 In fact, given the k-dimensional space, these should be called  indifference surfaces.
And, σi(costi(o), revi(o)) = revi(o) − costi(o), (i = A, B). 
, k), maps the alternatives to real numbers.
M can now construct the set of indifference curves1 in the consequence space (the dashed curves in Fig.
For instance, most businesses and public services have objectives like minimise cost and maximise the quality of services.
Having T done generates for A a revenue rA,T while doing T incurs a cost cB,T to B.
This might involve other mechanisms and factors/parties, e.g., a mediator, a legal institution, participation fees, etc.
, xk) be two  consequences.
However, a  negotiation infrastructure is usually required to facilitate negotiation.
We assume that Xi, (i = 1, .
2.2 A negotiation framework A multi-agent negotiation framework consists of: 1.
A set of attributes Att = {α1, .
And they both aim at minimising costs while maximising revenues.
(Dominant) Let x = (x1, .
However, we will not bog down to that level of details.
This is illustrated in Fig.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 509 and side-payments.
, xk) = (X1(a), .
, xk) and x = (x1, .
, Xk(a))}a∈A.
Joint Conf.
EXAMPLE 1.
DEFINITION 1.
