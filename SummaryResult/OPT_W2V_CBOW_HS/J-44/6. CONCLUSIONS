We also aim to extend our  formulation to other collaborative filtering algorithms, study the effect of shilling in altering rating roles, conduct field studies, and evaluate improvements in user experience by tweaking ratings based on their role values.
Finally, we plan to develop the idea of mining the evolution of rating role patterns into a reporting and tracking system for all aspects of recommender system health. 
To further recommender system acceptance and  deployment, we require new tools and methodologies to manage an installed recommender and develop insights into the roles played by ratings.
In future research, we plan to systematically study the many algorithmic parameters, tolerances, and cutoff  thresholds employed here and reason about their effects on the downstream conclusions.
Although we have presented results on only the item-based algorithm with list rank accuracy as the metric, the same approach outlined here applies to user-based algorithms and other metrics.
A fine-grained characterization in terms of rating roles such as scouts, promoters, and connectors, as done here, helps such an endeavor.
