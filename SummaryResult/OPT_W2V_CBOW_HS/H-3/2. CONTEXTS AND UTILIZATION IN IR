In these cases, contexts within query are created and can be exploited.
As found in [32], a feedback model creates a local context related to the query, while the general knowledge or the whole corpus defines a global context.
In the following discussion, we will call the topic domain of a query a context around query to contrast with another context within query that we will introduce.
It can be used in different ways.
This situation can often occur in practice as a user can search for a variety of topics outside the domains that he has previously searched in or identified.
A short-term feedback model is created for the given query from feedback documents, which has been proven to be effective to capture some aspects of the user"s intent behind the query.
In this paper, we use the same approach and we will integrate it into a more global model with other context factors.
Typically, one defines some sort of global relation between the expansion term and the whole query, which is usually a sum of its relations to every query word.
the lack of context information in term relations: by introducing stricter conditions in a relation, for example {Java, program}→computer and {algorithm, program}→computer, the applicability of the relations will be naturally restricted to correct contexts.
Knowledge and context within query Due to the unavailability of domain-specific knowledge, general knowledge resources such as Wordnet and term relations extracted automatically have been used for query expansion [27][31].
The documents (Web pages) classified in these categories are used to create a term vector, which represents the whole domains of interest of the user.
On the other hand, [9][15][26][30], as well as Google Personalized Search [12] use the documents read by the user, stored on user"s computer or extracted from user"s search history.
If a query contains term t1, then t2 is always considered as a candidate for expansion.
In all these studies, we observe that a single user profile (usually a statistical model or vector) is created for a user without distinguishing the different topic domains.
These terms are often presumed when a user issues a query such as waste cleanup in the domain.
As we mentioned earlier, we are faced with the problem of relation ambiguity: some relations apply to a query and some others should not.
For example, if the relation program→computer is strong enough, computer will have a strong global relation to the whole query TV program and it still remains as an expansion term.
The domains related to a query are then identified according to the query.
To remedy this problem, approaches have been proposed to make a selection of expansion terms after the application of relations [24][31].
Some context words are often used together with it.
Each component contextual factor will determines a different ranking score, and the final document ranking combines all of them.
However, we do not explicitly assign a meaning to a word; rather we try to make differences between word usages in different contexts.
Domain of interest and context around query A domain of interest specifies a particular background for the interpretation of a query.
However, little information is available in the relation to help us determine if an application context is appropriate.
Within query context exists in many queries.
From this point of view, our approach is more similar to word sense discrimination [27].
Although some inappropriate expansion terms can be removed because they are only weakly connected to some query terms, many others remain.
In fact, users often do not use a single ambiguous word such as Java as query (if they are aware of its ambiguity).
As the context words added into relations allow us to exploit the word context within the query, we call such factors context within query.
In order to create a good query model, such a query-specific feedback model should be integrated.
Among them, the user"s domain of interest and knowledge are considered to be among the most important ones [20][21].
There are many other contextual factors ([26]) that we do not deal with in this paper.
Domain models will also be integrated with other factors.
A similar approach is used in [8], where domain models are created using ODP categories and user queries are manually mapped to them.
If the application of a relation leads to a conflict with the query (or with other pieces of evidence), then it is not applied.
In this study, we will integrate all the above factors within a unified framework based on language modeling.
In this study, we also model topic domains.
There are many contextual factors in IR: the user"s domain of interest, knowledge about the subject, preference, document recency, and so on [2][14].
A possible solution to this problem is the creation of multiple profiles, one for a separate domain of interest.
In our earlier study [1], a simpler and more general approach is proposed to solve the problem at its source, i.e.
This principle is similar to that of [33] for word sense disambiguation.
Most often, a user profile is created to encompass all the domains of interest of a user [23].
This will enable us to use a more appropriate query-specific profile, instead of a user-centric one.
This approach is used in [18] in which ODP directories are used.
Domain model specifies yet another type of useful information: it reflects a set of specific background terms for a domain, for example pollution, rain, greenhouse, etc.
It is then useful to combine them together in a single IR model.
It is useful to add them into the query.
Query profile and other factors Many attempts have been made in IR to create query-specific profiles.
In both cases, the relations are defined between two single terms such as t1→t2.
We will carry out experiments on both automatic and manual identification of query domains.
The systematic application of the user profile can incorrectly bias the results for queries unrelated to the profile.
It is possible to integrate stronger control on the utilization of knowledge.
However, this approach requires encoding all the logical consequences including contradictions in knowledge, which is difficult to implement in practice.
For example, [17] defined strong logical relations to encode knowledge of different domains.
We can consider implicit feedback or blind feedback [7][16][29][32][35] in this family.
Both types of contexts have been proven useful [32].
It remains unclear whether domain models can be effectively used in IR.
In [5], a user profile contains a set of topic categories of ODP (Open Directory Project, http://dmoz.org) identified by the user.
However, it seems clear that many factors are complementary.
In this section, we review some of the studies in IR concerning these aspects.
As a result, computer will be used to expand queries Java program or program algorithm, but not TV program.
for the domain of Environment.
We see a clear complementarity among these factors.
For example, program→computer should not be applied to TV program even if the latter contains program.
However, only a small scale experiment has been carried out.
However, the experiments showed variable results.
This is described in the following section. 
