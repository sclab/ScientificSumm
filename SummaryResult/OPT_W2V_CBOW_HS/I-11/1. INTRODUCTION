BEE (Behavioral Evolution and Extrapolation) is a novel  approach to recognizing the rational and emotional state of multiple interacting agents based solely on their behavior, without recourse to intentional communications from them.
A central challenge in many application domains is reasoning from external observations of agent behavior to an estimate of their internal state.
Such  reasoning is motivated by a desire to predict the agent"s behavior.
Section 4 reports results from experiments with the system.
It is inspired by  techniques used to predict the behavior of nonlinear dynamical  systems, in which a representation of the system is continually fit to its recent past behavior.
In BEE, it is a set of parameters governing the behavior of software agents  representing the individuals being analyzed.
Our observations are often limited to the agent"s external behavior, which can frequently be  summarized numerically as a trajectory in space-time (perhaps  punctuated by actions from a fairly limited vocabulary).
Work to date  focuses almost entirely on recognizing the rational state (as opposed to the emotional state) of a single agent (as opposed to an  interacting community), and frequently takes advantage of explicit  communications between agents (as in managing conversational  protocols).
The current version of BEE characterizes and predicts the behavior of agents  representing soldiers engaged in urban combat [8].
Section 3  describes the architecture of BEE.
An agent"s emotional state may be at least as important as its rational state in determining its behavior.
Reasoning about agents that we observe in the world must integrate two disparate levels.
However, this behavior is driven by the agent"s internal state, which (in the case of a human) may involve high-level psychological and cognitive concepts such as intentions and emotions.
Further details that cannot be included here for the sake of space are available in an on-line technical report [16]. 
The agents often are trying to hide their intentions (and even their presence), rather than intentionally sharing information.
Section 2 reviews relevant previous work.
Domains that exhibit these constraints can often be  characterized as adversarial, and include military combat, competitive business tactics, and multi-player computer games.
Increasing the number of agents leads to a combinatorial  explosion that can swamp conventional analysis.
This problem has traditionally been addressed under the  rubric of plan recognition or plan inference.
Environmental dynamics can frustrate agent intentions.
Many realistic problems deviate from these conditions.
Section 5 concludes.
For nonlinear dynamical systems, the  representation is a closed-form mathematical equation.
