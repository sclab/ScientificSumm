2.5.1 Linear Fusion by Duplicate Photos Intuitively, the most straightforward way to factor out the uncertainties caused by the different criterion is to scale,  rel380 ative to a given center, the total scores of each unreferenced Web photo forum with respect to the reference forum.
Intuitively, if we can detect same photographers or same photographs, we can build relationships between any two photo forums and therefore can standardize the rating criterion by score  normalization and transformation.
The problem is thus how to normalize total scores in  different Web forums.
The difficulty, however, of using this normalization method is that, if there are only a few users rating an object, say a photo in a photo forum, the average score for the object is likely to be spammed or skewed.
This allows the  normaliza379 tion method on the total score or average score to be viewed as an impartial rating method between different Web  forums.
2.2 Score Normalization Since different Web (photo) forums on the Web usually have different rating criteria, it is necessary to normalize them before applying different kinds of fusion methods.
2.5.3 Performance Measure of the Fusion Results Since our objective function is to make the scores of the same Web objects (e.g.
Under the same  assumptions made in Section 2.2, we can use this method to adjust scores of the middle-level (from the mode point to the 90 % percentile).
The proposed algorithm will try to find the best ψk(k = 2, ..., K), which has certain parametric forms according to certain models.
We further use {Skl i |i = 1, ..., Ikl; k, l = 1, ..., K; k = l} to denote the set of scores for Web objects (photos) in kth Web forums that are duplicate with the lth Web forums, where Ikl is the total number of duplicate Web objects  between these two Web sites.
The underlying assumption, for  example in different photo forums, is that even the qualities of top photos in different forums may vary greatly and be less dependent on the forum quality, the distribution of photos of middle-level quality (from mode to 90% percentile) should be almost of the same quality up to the freedom which  reflects the rating criterion (strictness) of Web forums.
Although we cannot rely on this measure to evaluate our final fusion results as ranking photos by their popularity and qualities is such a subjective process that every person can have its own results, it can help us understand the  intermediate ranking results and provide insights into the final performances of different ranking methods.
Faced with the need to overcome a ranking problem, a standardized rating criterion rather than a  reasonable rating criterion is needed.
More strictly, we assume ψk has the following form ψk(Ski) = αkSki + tk, k = 2, ..., K (3) ψ1(S1i) = S1i (4) which means that the scores of k(= 1)th forum should be scaled by αk relative to the center tk 1−αk as shown in Figure 3.
Then the hash code for each photo is built as follows: each dimension is transformed to one, if the value in this dimension is greater than 0, and 0 otherwise.
The objective function described in the above Figure 1: Web community integration.
Motivated by this ranking function, we  propose this manual fusion method: For the kth Web site, we use the following formula eSki = αk · „ nk · ¯Ski nk + n∗ k + n∗ k · S∗ k nk + n∗ k « (2) to rank photos, where nk is the number of votes and n∗ k, S∗ k and αk are three parameters.
Or, in other words, whether the scores of two objects linked by the green dashed (hidden) links become more consistent?
Its  computational complexity to find all the duplicate images among n images is about O(n log n).
Though this method can achieves pretty good results after careful and thorough manual tuning on these parameters, when n  becomes increasingly large, say there are tens or hundreds of Web communities crawled and indexed, this method will  become more and more laborious and will eventually become impractical.
We therefore define the following performance  measureδ measure - to quantify the changes for scores of the same Web objects in different Web forums as δkl = Sim(Slk , Skl ) − Sim(Slk ∗ , Skl ∗ ) (10) 381 where Skl = (Skl 1 , ..., Skl Ikl )T , Skl ∗ = (eSkl 1 , ..., eSkl Ikl )T and Sim(a, b) = a · b ||a||||b|| .
duplicate photos) between a  nonreference forum and the reference forum as close as possible, it is natural to investigate how close they become to each other and how the scores of the same Web objects change between the two non-reference forums before and after score fusion.
5, we get the closed form solution as: „ αk tk « = A−1 k Lk (6) where Ak = „ P i ¯wi(Sk1 i )2 P i ¯wiSk1 iP i ¯wiSk1 i P i ¯wi « (7) Lk = „ P i ¯wiS1k i Sk1 iP i ¯wiS1k i « (8) and k = 2, ..., K. This is a linear fusion method.
δkl > 0 means after score fusion, scores on the same Web objects between kth and lth Web forum become more  consistent, which is what we expect.
Yet we can deem that scores in different  forumsexcept for the reference forum - can vary in a parametric space.
We call this kind of score as Scaled Mean Score.
Photos in the same bucket are deemed potential duplicates and are further filtered by a threshold in terms of Euclidean similarity in the visual feature space.
This ranking function first takes a balance between the original mean score ¯Ski and a reference score S∗ k to get a weighted mean score which may be more reliable than ¯Ski.
Second, the numbers of the duplicate photos from different Web forums are small relative to the whole photo sets (see Table 1).
Figure 3: Linear Fusion method 2.5.2 Nonlinear Fusion by Duplicate Photos Sometimes we want a method which can adjust scores on intervals with two endpoints unchanged.
This kind of fusion method is then much finer than the linear ones and  contains many more parameters to tune and expect to further improve the results.
The current problem can also be viewed as a rank  aggregation one [13, 14] as we deal with the problem of how to combine several rank lists.
First, we introduce a transform: ηc0,c1,α(x) = (  x−c0 c1−c0 α (c1 − c0) + c0, if x ∈ (c0, c1] x otherwise where α > 0.
We intent to finely adjust the shape of the curves in each segment.
The dashed lines are links indicating that the two linked Web objects are  actually the same.
This normalization method utilizes the mode and 90%  percentile as two reference points to align two rating systems, which makes the distributions of total scores in different  forums more consistent.
By formulating the ranking problem as an  optimization problem that attempts to make the scores of duplicate photos in non-reference forums as close as possible to those in the reference forum, we can effectively solve the ranking problem.
To make the normalization insensitive to unusual data, we propose the Mode-90% Percentile normalization method.
In another words, the top K rank lists of different Web forums are almost disjointed for a given query.
Here, the mode score represents the total score that has been assigned to more photos than any other total score.
2.3 Manual Fusion The Web movie forum, IMDB [16], proposed to use a Bayesian-ranking function to normalize rating scores within one community.
Therefore, we can take a large scale forum as the reference forum, and align other forums by taking into account duplicate Web objects  (duplicate photos in this work).
The simplest way may be normalization by the maximal and minimal scores.
Before we describe the proposed ranking algorithms, we first introduce a manually tuned method in Section 2.3, which is laborious and even impractical when the number of  communities become large.
In current settings, it is difficult or even impossible to get these datasets labelled as to their level of professionalism or  popularity, since the photos are too vague and subjective to rank.
For n Web communities, there are then about 3n  parameters in {(αk, n∗ k, S∗ k)|k = 1, ..., n} to tune.
First of all, unlike the Web pages, which can be easily and accurately detected as the same pages, detecting the same photos in different Web  forums is a non-trivial work, and can only be implemented by some delicate algorithms while with certain precision and recall.
Taken Figure 1 as an example, the proposed algorithms minimize the score differences of the same Web objects in two Web forums: the reference forum (the Web Community 1) and a non-reference forum, which corresponds to  minimizing the objective function on the red dashed (hidden) links.
This algorithm uses hash function to map a high dimensional feature to a 32 bits hash code (see below for how to construct the hash code).
That is, the same score does not mean the same quality in different forums.
paragraph can then be formulated as min {ψk|k=2,...,K} KX k=2 Ik1X i=1 ¯wk i  S1k i − ψk(Sk1 i ) 2 (1) where we use k = 1 as the reference forum and thus ψ1(S1i) = S1i.
Figure 2: Hashing procedure for duplicate photo dectection 2.5 Score Fusion In this section, we will present two solutions on score  fusion based on different parametric form assumptions of ψk in Eq.
The visual features are then transformed to a relatively low-dimensional and zero mean PCA space, or 29 dimensions in our system.
Then we will describe the two proposed methods: Linear  fusion and Non-linear fusion, and a performance measure for result evaluation in Section 2.5.
Photos of this middle-level in a Web forum usually occupy more than 70 % of total photos in that forum.
But we believe the proper use of ¯wk i , which leverages more information, can significantly improve the results.
The total score refers to the sum of the various rating scores (e.g.,  novelty rating and aesthetic rating), and the mean score refers to the mean of the various rating scores.
In addition, as there are many kinds of ratings, such as  ratings for novelty, ratings for aesthetics etc, it is reasonable to choose a common one - total score or average  scorethat can always be extracted in any Web forum or  calculated by corresponding ratings.
The more reviewers, the more popular the photo is and the larger the corresponding weight ¯wk i should be.
The proposed methods below are based on the following considerations.
Figure 2 illustrates the hashing procedure, where visual features - mean gray values - are extracted on both 6 × 6 and 7×7 grids.
Fortunately, we find that quite a number of duplicate photographs exist in various Web photo forums.
And The high percentile score (e.g.,90%) represents the total score for which the high percentile of images have a lower total score.
After the optimization, we must ask what happens to the score differences of the same Web objects in two  nonreference forums?
This can be determined by minimizing the objective function defined by the sum of squares of the score  differences.
This more complicated non-linear fusion method is  expected to achieve better results than the linear one.
In general, score fusion can be seen as the procedure of finding K transforms ψk(Ski) = eSki, k = 1, ..., K such that eSki can be used to rank Web objects from different Web sites.
In this work, we do not inspect the problem of how to choose ¯wk i and simply set them to one.
Each Web community forms a subgraph, and all communities are linked together by some hidden links (dashed lines).
We will first discuss the score normalization methods in Section 2.2, which serves as the basis for the following work.
Even there is no closed-form solution for the following optimization problem, min {αk|k∈[2,K]} KX k=2 Ik1X i=1 ¯wk i h S1k i − ηM,T,α(Ski) i2 it is not hard to get the numeric one.
It is therefore desirable to find an effective  fusion method whose parameters can be automatically  determined.
¯wk i (≥ 0) is the weight coefficient that can be set  heuristically according to the numbers of voters (reviewers or  commenters) in both the reference forum and the non-reference forum.
Under this condition, both the algorithms proposed in [13] and their measurements - Kendall tau distance or Spearman footrule distance - will degenerate to some  trivial cases.
2.4 Duplicate Photo Detection We use Dedup [10], an efficient and effective duplicate  image detection algorithm, to find duplicate photos between any two photo forums.
As illustrated in Figure 4, the method can tune scores between [C0, C1] while leaving scores C0 and C1 unchanged.
Ski and ¯Ski denote the total score and mean score of ith Web object (photo) in the kth Web site, respectively.
Ideally, the scores of duplicate photos should be equal even though they are in different forums.
Then the weighted mean score is scaled by αk to get the final score fSki.
It seems easy to fix this freedom, but detailed analysis of the data and experiments show that it is a non-trivial problem.
This fact is reasonable when  considering that photographers sometimes submit a photo to more than one forum to obtain critiques or in hopes of widespread publicity.
It enjoys simplicity and excellent performance in the following experiments.
The second kind of freedom is the varying rating criteria found in different Web forums.
Instead, the problem here is how to combine several ordered sub lists to form a total order list. 
Another category of rank fusion (aggregation) methods is based on machine learning algorithms, such as RankSVM [17, 19], RankBoost [15], and RankNet [12].
It is straightforward to normalize average scores by  linearly transforming them to a fixed interval.
(9) Figure 4: Nonlinear Fusion method.
The first kind of freedom is the rating interval or rating scale including the minimal and maximal ratings for each Web object.
Then we can utilize this nonlinear transform to adjust the scores in certain interval, say (M, T], ψk(Ski) = ηM,T,α(Ski) .
Finally, in Section 2.6 we will discuss the relationship of the proposed methods with some other related work.
1, the summation is taken on all the red dashed lines.
The low-level visual feature for each photo is extracted on k × k regular grids.
2.1 Overview The difficulty of integrating multiple Web forums is in their different rating systems, where there are generally two kinds of freedom.
2.6 Contrasts with Other Related Work We have already mentioned the differences of the proposed methods with the traditional methods, such as PageRank [22], PopRank [21], and LinkFusion [27] algorithms in  Section 1.
Based on all features extracted from the image database, a PCA model is built.
In Section 2.4, we will briefly explain how to precisely find duplicate photos between Web forums.
We will give more detailed analysis of the scores in Section 3.2.
So as to minimize the cost function defined in Eq.
In this work, we adopt an efficient duplicate photo detection algorithm [10] to find these photos.
The 85-dimensional features are transformed to a 32-dimensional vector, and the hash code is generated according to the signs.
For example, some forums use a 5-point rating scale whereas other forums use 3-point or 10-point rating scales.
(5) By solving the following set of functions, ( ∂f ∂αk = = 0 ∂f ∂tk = 0 , k = 1, ..., K where f is the objective function defined in Eq.
On the contrary, if δkl < 0, those scores become more inconsistent.
The drawback of this normalization method is it is non robust, or in other words, it is sensitive to outliers.
Total score can avoid such drawbacks that contain more information such as a Web object"s quality and popularity.
The Web Community 1 is the reference community.
However, difficulties in evaluating the rank results block us from tuning these parameters extensively.
Here, we propose a nonlinear fusion solution to satisfy such constraints.
The current  experiments in Section 3.5 do not reveal any advantages over the simple linear model.
All of these methods entail some labelled datasets to train a model.
This transform satisfies that for x ∈ [c0, c1], ηc0,c1,α(x) ∈ [c0, c1] with ηc0,c1,α(c0) = c0 and ηc0,c1,α(c1) = c1.
However, there are  fundamental differences between them.
Figure 1 illustrates the aforementioned idea.
1, we get the following objective function, min {αk,tk|k=2,...,K} KX k=2 Ik1X i=1 ¯wk i h S1k i − αkSk1 i − tk i2 .
For convenience, the following notations are employed.
Then, if we substitute above ψk to Eq.
Suppose there are a total of K Web sites.
Here, we discuss some other related works.
