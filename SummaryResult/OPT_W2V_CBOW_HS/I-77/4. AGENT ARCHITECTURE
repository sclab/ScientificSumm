We also consider needs, the variable Tα(β, a) denotes α"s estimate of the strength of β"s motivating need for the enactment of commitment a over a valuation space.
The posterior Pt+1 (φ |φ) is obtained with Equation 3 with r(μ) defined to be the normalisation of t. The valuation method: For a given φk, wexp (φk) =Pm j=1 Pt (φj|φk) · w(φj) is α"s expectation of the value of what will be observed given that β has stated that φk will be observed, for some measure w. Now suppose that, as before, α observes ϕk after agent β has stated ϕ. α revises the prior estimate of the expected valuation wexp (φk) in the light of the observation ϕk to: (wrev (φk) | (ϕk|ϕ)) = g(wexp (φk), Sim(φk, ϕ), w(φk), w(ϕ), wi(ϕk)) for some function g - the idea being, for example, that if the execution, ϕk, of the commitment, ϕ, to supply cheese was devalued then α"s expectation of the value of a commitment, φ, to supply wine should decrease.
In the not-atypical special case of multi-issue bargaining where the agents" preferences over the individual issues only are known and are complementary to each other"s, maximum entropy reasoning can be applied to estimate the probability that any multi-issue δ will be acceptable to β by enumerating the possible worlds that represent β"s limit of acceptability [6].
α may have background knowledge concerning D(ϕ |ϕ) as t → ∞,  otherwise α may assume that it has maximum entropy whilst being consistent with the data.
, φp} the set of all possible observations in the context of φ and i = 1, .
2 we obtain the method for updating a distribution Pt (ϕ |ϕ) on receipt of a message μ: Pt+1 (ϕ |ϕ) = Δi(D(ϕ |ϕ), r(μ)) (3) This procedure deals with integrity decay, and with two probabilities: first, the probability z in the utterance μ, and second the belief Rt (α, β, μ) that α attached to μ.
Pt (acc(α, β, χ, δ)) estimates the probability that α should accept proposal δ in satisfaction of her need χ, where δ = (a, b) is a pair of commitments, a for α and b for β. α will accept δ if: Pt (acc(α, β, χ, δ)) > c, for level of certainty c. This estimate is compounded from subjective and objective views of acceptability.
The relationship  strategy determines which agent to negotiate with for a given need; it uses risk management analysis to preserve a  strategic set of trading relationships for each mission-critical need - this is not detailed here.
The negotiation strategy then determines the current set of Options {δi}, and then the tactics, guided by the negotiation target, decide which, if any, of these Options to put forward and wraps them in argumentation dialogue - see Section 6.
4.3 Update of Pt (φ |φ) given ϕ The sim method: Given as above μ = illoc(α, β, ϕ, t) and the observation ϕk we define the vector t by ti = Pt (φi|φ) + (1− | Sim(ϕk, ϕ) − Sim(φi, φ) |) · Sim(ϕk, φ) with {φ1, φ2, .
arg minx P j xj log xj Pt(ϕ |ϕ)j that satisfies the constraint p(μ)k = d. Then let q(μ) be the distribution: q(μ) = Rt (α, β, μ) × p(μ) + (1 − Rt (α, β, μ)) × Pt (ϕ |ϕ) and then let: r(μ) = ( q(μ) if q(μ) is more interesting than Pt (ϕ |ϕ) Pt (ϕ |ϕ) otherwise A general measure of whether q(μ) is more interesting than Pt (ϕ |ϕ) is: K(q(μ) D(ϕ |ϕ)) > K(Pt (ϕ |ϕ) D(ϕ |ϕ)), where K(x y) = P j xj ln xj yj is the Kullback-Leibler distance  between two probability distributions x and y [11].
(1) where g ∈ [0, 1] is α"s greed, h ∈ [0, 1] is α"s degree of  altruism, and s ≈ 1 is derived from the stance8 described in Section 6.
A need may be exogenous such as a need to trade profitably and may be triggered by another agent offering to trade, or endogenous such as α deciding that it owns more wine than it requires.
In general, given a  distribution, Pt (Xi), and a decay limit distribution D(Xi), Pt (Xi) decays by: Pt+1 (Xi) = Δi(D(Xi), Pt (Xi)) (2) where Δi is the decay function for the Xi satisfying the property that limt→∞ Pt (Xi) = D(Xi).
So, α"s world model  contains probability distributions that represent its uncertain expectations of what will be observed on the basis of  utterances received.
The subjective estimate takes account of: the extent to which the enactment of δ will satisfy α"s need χ, how much δ is ‘worth" to α, and the extent to which α believes that she will be in a position to execute her  commitment a [14, 15].
Agent α acts in response to a need that is expressed in terms of the ontology.
We model the update of Pt (ϕ |ϕ) in two cases, one for observations given ϕ, second for observations given φ in the semantic neighbourhood of ϕ.
Suppose that α receives an utterance μ = illoc(α, β, ϕ, t) from agent β at time t. Suppose that α attaches an  epistemic belief Rt (α, β, μ) to μ - this probability takes account of α"s level of personal caution.
For each trading relationship this strategy generates a relationship target that is expressed in the LOGIC framework as a desired level of intimacy to be achieved in the long term.
α is interested 8 If α chooses to inflate her opening Options then this is achieved in Section 6 by increasing the value of s. If s 1 then a deal may not be possible.
For example, if β sends the message Offer(δ1) then α derives the constraint: {Pt (acc(β, α, δ1)) = 1} on the distribution Pt (β, α, δ), and if this is a counter offer to a former offer of α"s, δ0, then: {Pt (acc(β, α, δ0)) = 0}.
We estimate the posterior by applying the principle of minimum relative entropy as for Equation 3, where the distribution p(μ) = p(φ |φ) satisfies the constraint: p X j=1 p(ϕ ,ϕ)j · wi(φj) = g(wexp (φk), Sim(φk, ϕ), w(φk), w(ϕ), wi(ϕk)) 
For example, Δi could be linear: Pt+1 (Xi) = (1 − νi) × D(Xi) + νi × Pt (Xi), where νi < 1 is the decay rate for the i"th distribution.
Sα(β, a) is a random variable denoting α"s estimate of β"s subjective valuation of a over some finite, numerical evaluation space.
In the absence of in-coming utterances, the conditional probabilities, Pt (ϕ |ϕ), should tend to ignorance as  represented by a decay limit distribution D(ϕ |ϕ).
All observations about the world are received as utterances from an all-truthful  institution agent ξ.
For example, if β communicates the goal I am hungry and the subsequent negotiation terminates with β purchasing a book from α (by ξ advising α that a certain amount of money has been credited to α"s account) then α may conclude that the goal that β chose to satisfy was something other than hunger.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1033 in the degree to which an utterance accurately describes what will subsequently be observed.
This may be calculated by  introducing Lagrange multipliers λ: L(p, λ) = P j pj log pj qj + λ · g. Minimising L, { ∂L ∂λj = gj(p) = 0}, j = 1, .
The objective estimate captures whether δ is acceptable on the open market, and variable Uα(b) denotes α"s open-market valuation of the enactment of commitment b, again taken over some finite numerical  valuation space.
Then as the agents share increasing amounts of their  information about their open market valuations g gradually reduces to 0, and then as they share increasing amounts of information about their needs h increases to 1.
4.2 Update of Pt (ϕ |ϕ) given ϕ First, if ϕk is observed then α may set Pt+1 (ϕk|ϕ) to some value d where {ϕ1, ϕ2, .
We estimate the complete posterior  distribution Pt+1 (ϕ |ϕ) by applying the principle of minimum relative entropy9 as follows.
For example, if ϕ is I will deliver a bucket of fish to you tomorrow then the distribution P(ϕ |ϕ) need not be over all possible things that β might do, but could be over ontological categories that summarise β"s possible actions.
In Section 4.1 this enables us to measure the  difference between an utterance and a subsequent observation.
Then for δ = (a, b): Pt (acc(α, β, χ, δ)) = Pt „ Tα(β, a) Tα(α, b) «h × „ Sα(α, b) Sα(β, a) «g × Uα(b) Uα(a) ≥ s !
Each negotiation consists of a dialogue, Ψt , between two agents with agent α contributing utterance μ and the  part6 Each of α"s plans and reactions contain constructors for an initial world model Mt .
We represent the relationship between utterance, ϕ, and subsequent observation, ϕ , by Pt (ϕ |ϕ) ∈ Mt , where ϕ and ϕ may be ontological categories in the interest of  computational feasibility.
Each dialogue, Ψt , is evaluated using the LOGIC framework in terms of the value of Ψt to both α and β - see Section 5.2.
Agents have a probabilistic first-order internal language L used to represent a world model, Mt .
, pI ) subject to a set of J linear constraints g = {gj(p) = aj · p − cj = 0}, j = 1, .
The multiplying factor Sim(ϕ , φ) limits the variation of probability to those formulae whose  ontological context is not too far away from the observation.
, θt}, contains an agent α that interacts with other argumentation agents, βi, information providing agents, θj, and an institutional agent, ξ, that represents the institution where we assume the interactions happen [2].
, p. t is not a probability distribution.
The communication language C introduced in Section 3.2  enables us both to structure the dialogues and to structure the processing of the information gathered by agents.
Needs trigger α"s goal/plan  proactive reasoning, while other messages are dealt with by α"s reactive reasoning.6 Each plan prepares for the negotiation by assembling the contents of a ‘LOGIC briefcase" that the agent ‘carries" into the negotiation7 .
We can imagine a relationship that begins with g = 1 and h = 0.
, J (that must include the constraint P i pi − 1 = 0) is: p = arg minr P j rj log rj qj .
Pt (acc(β, α, δ)) estimates the probability that β would accept δ, by observing β"s responses.
We are unaware of any  empirical investigation of this hypothesis for autonomous agents in real trading scenarios.
Either the decay function or the decay limit distribution could also be a function of time: Δt i and Dt (Xi).
4.1 Updating the World Model Mt α"s world model consists of probability distributions that represent its uncertainty in the world state.
We now describe two of the distributions in Mt that support offer exchange.
, I leads eventually to p. Entropy-based inference is a form of Bayesian inference that is convenient when the data is sparse [5] and encapsulates common-sense reasoning [12].
, ϕm} is the set of all possible observations.
The institutional agent reports promptly and honestly on what actually occurs after an agent signs a contract, or makes some other form of  commitment.
The Sixth Intl.
7 Empirical evidence shows that in human negotiation,  better outcomes are achieved by skewing the opening Options in favour of the proposer.
Let p(μ) be the distribution: 9 Given a probability distribution q, the minimum relative entropy distribution p = (p1, .
The basis for the acceptance criterion has thus developed from equity to equality, and then to need.
, J is the set of given constraints g, and a solution to ∂L ∂pi = 0, i = 1, .
ner β contributing μ using the language described in  Section 3.2.
This illustrates the  wellknown inefficiency of bilateral bargaining established  analytically by Myerson and Satterthwaite in 1983.
Mt is then maintained from  percepts received using update functions that transform  percepts into constraints on Mt - for details, see [14, 15].
The parameters g and h are independent.
A generic information-based architecture is described in detail in [15].
A multiagent system {α, β1, .
Joint Conf.
, βn, ξ, θ1, .
The LOGIC agent architecture is shown in Figure 1.
Finally incorporating Eqn.
