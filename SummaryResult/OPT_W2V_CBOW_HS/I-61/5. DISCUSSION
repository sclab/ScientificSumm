The main contribution of this paper is to present a distributed adaptive air traffic flow management algorithm that can be readily implemented and to test that algorithm using FACET, a simulation tool widely used by the FAA, NASA and the industry.
First, we are exploring new methods of estimating agent  rewards, to further speed up the simulations.
One such  modification is to extend the definition of agents from fixes to sectors, giving agents more opportunity to control the  traffic flow, and allow them to be more efficient in eliminating congestion.
Our method is based on agents representing fixes and having each agent determine the separation between aircraft approaching its fix.
It offers the significant benefit of not requiring radical changes to the current air flow management structure and is therefore readily deployable.
Finally, in cooperation with domain experts, we are investigating different system evaluation functions, above and beyond the delay and congestion dependent G presented in this paper.
The agents use reinforcement learning to learn control policies and we explore different agent reward functions and different ways of estimating those functions.
The efficient, safe and reliable management of air traffic flow is a complex problem, requiring solutions that integrate control policies with time horizons ranging from minutes up to a year.
Second we are investigating deployment strategies and looking for  modifications that would have larger impact.
We are currently extending this work in three directions.
Acknowledgments: The authors thank Banavar  Sridhar for his invaluable help in describing both current air traffic flow management and NGATS, and Shon Grabbe for his detailed tutorials on FACET. 
