Additionally, the robots have remote subscriptions to the respective  distance events which are used to check it with the local sensor readings to validate that they really follow the guide which they detect with their local sensors.
In the case of the guide robot, this information is directly  delivered as a body event with a low latency and a high reliability over the internal network.
For the follower robot, the information comes also via an event channel but with different quality attributes.
The  unavailability of the remote events will decrease the quality of interaction and probably and slow down the robots, but will not affect safety properties.
A simple example for many important properties of the proposed system showing the coordination through the  environment and events disseminated over the network is the demo of two cooperating robots depicted in Figure 5.
The respective sentient object controlling the actuation of the robot receives as input the position and orientation of the white line to be tracked.
Thus it can see through the eye of the guide.
Each robot is equipped with smart distance sensors, speed sensors, acceleration sensors and one of the robots (the guide (KURT2) in front (Figure 5)) has a tracking camera  allowing to follow a white line.
A problem will be to receive only the events of the robot which is closest.
Because it knows the  distance to the guide and the speed as well, it can foresee the necessary movements.
For this purpose, it dynamically  subscribes to the event channel disseminating distance events from rear distance sensors of the guide(s) and compares these with the distance events from its local front sensors.
The respective reaction time can be  calculated as function of the speed and the distance of the robots and define a dynamic dissemination deadline for events.
also subscribes to the event channels of the tracking camera and the speed sensors 37 Figure 5: Cooperating robots.
COSMIC provides the event layer for seamless interaction.
All what publishers and subscribers have to know to dynamically interact in this  environment is the subject of the respective event class.
Whenever the blind robot detects (by its front distance sensors) an obstacle, it checks whether this may be the guide.
The robots form a WAN-of-CANs system in which their local CANs are interconnected via a wireless 802.11 network.
The sentient object controlling the actuation of the follower is aware of the increased latency and higher probability of omission. 
Interaction through the environment.
the follower may not crash into the guide and the guide may not loose the follower.
Rather, the position of the event generation entity which is captured in the respective attributes can be evaluated to filter the relevant event out of the event stream.
The blind robot subscribes to the events of the line tracking camera.
The  cooperation between the robots is controlled by sensing the distance between the robots.
Respectively, if the blind robot comes too close it reduces its speed.
A suitable wireless protocol which uses proximity to filter events has been proposed by Meier and Cahill [22] in the CORTEX project.
The local distance sensors produce events which are  disseminated through a low latency, highly predictable event channel.
Thus, the interaction through the  environment will secure the safety properties of the  application, i.e.
The blind robot (N.N.)
If the guide detects that the distance grows, it slows down.
Dynamic interaction of robots which is not known in advance.
to follow the guide.
If the distance is approximately the same it infers that it is really behind a guide.
In principle, any two a priori unknown robots can cooperate.
The demo application highlights the following properties of the system: 1.
These quality  attributes are reflected in the event channel description.
A robot identity does not help much to solve this problem.
Cooperative sensing.
The proposed system  provides the architectural framework for such a  cooperation.
is  searching the guide randomly.
Because there may be longer latencies and omissions, this check occasionally will not be possible.
Now N.N.
