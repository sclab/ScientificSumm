Plans (each of them having its own context) were common to the whole set of agents in the community.
Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents" behaviour (while considering them as independant entities and not  indetermined part of the environment as in level 1).
[6] introduces a  characterisation of learning in multi-agent system according to the level of awareness of the agents.
The work described here has its origin in a former work  concerning learning in an intentional multi-agent system using a BDI formalism [6].
Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).
This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as  critics.
The update process of the  community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay  masconsistent.
We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.
In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.
It leads us to define what is the mas-consistency of an agent with respect to the community.
Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.
The study of such a protocol is the  object of the present paper.
In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update  mechanism to collaborative concept learning.
Level 2 implies direct  interaction between the agents as they can exchange messages to improve their learning.
At level 1, agents learn âˆ—The primary author of this paper is a student.
Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.
In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.
However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.
in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.
However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.
This article deals with the problem of collaborative  concept learning in a multi-agent system.
Pieces of information are distributed among the agents, but can be redundant.
Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.
In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 
Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.
Moreover, we suppose that at least a part Bc of the beliefs of each agent is  common to all agents and must stay that way.
In such a case, we will say that he is a-consistent.
There is no central memory.
