The proposed method can have a real impact on Web metasearch performances since only ranks are available from most primary search engines, whereas most of the current approaches need scores to merge result lists into one single list.
In this paper, we address the rank aggregation problem where different, but not disjoint, lists of documents are to be fused.
From the  experiments, we can also conclude that in order to improve the performances, we should fuse result lists of well performing IR models, and that majoritarian data fusion methods  perform better than positional methods.
Only robust information should be used from each input ranking.
Acknowledgments The authors would like to thank Jacques Savoy for his  valuable comments on a preliminary version of this paper. 
We propose a new outranking method for rank  aggregation which is well adapted to the IR context.
the intensity of their positions difference in each input ranking and also considering the number of the input rankings that are concordant and  discordant in favor of a specific document.
Current rank aggregation methods, and especially  positional methods (e.g.
Indeed, it ranks two documents w.r.t.
This is an important feature since the absence of a document from a ranking should not be  necessarily interpreted negatively.
combSUM [15]), are not initially  designed to work with such rankings.
Experimental results show that the outranking method significantly out-performs popular classical positional data fusion methods like combSUM and combMNZ strategies.
There is also no need to make specific assumptions on the positions of the missing documents.
We noticed that the input rankings can hide ties, so they should not be considered as complete orders.
It also out-performs a good performing majoritarian methods which is the Markov chain method.
using the document scores or some combination of  document ranks and scores.
Further work involves investigating whether the  outranking approach performs well in various other contexts, e.g.
They should be adapted by considering specific working assumptions.
These results are tested against different test collections and queries.
