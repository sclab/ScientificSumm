We have shown why individuals who genuinely would like to protect their privacy may not do so because of psychological  distortions well documented in the behavioral economics  literature.
Self-regulation, even in presence of complete information and awareness, may not be trusted to work for the same reasons.
On the contrary, our results, by aiming at offering a more realistic model of user-behavior, could be of help to technologists in their  design of privacy enhancing tools.
An empirical analysis may start with the comparison of available data on the adoption rate of privacy technologies that offer immediate refuge from minor but pressing privacy concerns (for example, ‘do not call" marketing lists), with data on the adoption of privacy technologies that offer less obviously perceivable protection from more dangerous but also less visible privacy risks (for example, identity theft insurances).
Still, even from a purely  economic perspective, anecdotal evidence suggest that the costs of privacy (from spam to identity theft, lost sales, intrusions, and the like [30, 12, 17, 33, 26]) are high and increasing. 
The conclusions we have reached suggest that individuals may not be trusted to make decisions in their best interests when it comes to privacy.
However, our results also imply that technology alone or awareness alone may not address the heart of the privacy problem.
We have shown that a model of rational privacy behavior is  unrealistic, while models based on psychological distortions offer a more accurate depiction of the decision process.
Applying models of self-control bias and immediate  gratification to the study of privacy decision making may offer a new perspective on the ongoing privacy debate.
is a different question from does privacy matter?
Improved  technologies (with lower costs of adoption and protection) and more information about risks and opportunities certainly can help.
Surprisingly, we have also found that these inconsistencies may occur when individuals perceive the risks from not  protecting their privacy as significant.
This does not mean that privacy technologies are ineffective.
But the value of  privacy eventually goes beyond the realms of economic  reasoning and cost benefit analysis, and ends up relating to one"s views on society and freedom.
The psychological distortions we have discussed may be considered in the ongoing debate on how to deal with the  privacy problem: industry self-regulation, users" self protection (through technology or other strategies), or government"s  intervention.
A combination of technology, awareness, and regulative policies - calibrated to generate and enforce liabilities and incentives for the  appropriate parties - may be needed for privacy-related welfare increase (as in other areas of an economy: see on a related analysis [25]).
We have highlighted that these distortions may affect not only na¨ıve individuals but also sophisticated ones.
People may not be able to act as economically rational agents when it comes to personal privacy.
However, more fundamental human behavioral mechanisms must also be addressed.
Whether from an economic standpoint privacy ought to be protected or not, is still an open question.
And the question whether do consumers care?
However, only an experimental approach over different periods of time in a controlled environment may  allow us to disentangle the influence of several factors.
Observing that people do not want to pay for privacy or do not care about privacy, therefore, is only a half truth.
It is a question that involves defining specific contexts in which the concept of privacy is being invoked.
Surveys alone cannot suffice, since we have shown why survey-time attitudes will rarely match decision-time actions.
Additional uncertainties, risk aversion, and varying  attitudes towards losses and gains may be confounding elements in our analysis.
An  experimental verification is part of our ongoing research agenda.
Empirical validation is necessary to calibrate the effects of different factors.
