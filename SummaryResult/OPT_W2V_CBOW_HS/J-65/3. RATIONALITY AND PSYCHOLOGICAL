In general, individuals may put constraints on future  behavior that limit their own achievement of maximum utility: people may genuinely want to protect themselves, but  because of self-control bias, they will not actually take those steps, and opt for immediate gratification instead.
It also refers to the inability to process all the stochastic information related to risks and probabilities of events leading to privacy costs and benefits.
DISTORTIONS IN PRIVACY Equation 1 is a comprehensive (while intentionally generic) road-map for navigation across privacy trade-offs that no human agent would be actually able to use.
Being in a position of  information asymmetry with respect to the party with whom she is transacting, decisions must be based on stochastic  assessments, and the magnitudes of the factors that may affect the individual become very difficult to aggregate, calculate, and compare.2 Bounded rationality will affect the  calculation of the parameters in Equation 1, and in particular δ, γ, vE(), and pt().
This phenomenon may also affects privacy decisions, since the costs of privacy protection may be immediate, but the  rewards may be invisible (absence of intrusions) and spread over future periods of time.
And the distributions of some other events may be almost completely subjective - for example, the probability that a new and practical form of attack on a currently  secure cryptosystem will expose all of your encrypted personal communications a few years from now.
We hinted to some difficulties as we noted that several layers of complexities are hidden inside concepts such as the expected value of maintaining certain information private, and the probability of succeeding doing so.
Also, it is easier to deal with actions and effects that are closer to us in time.
What is her knowledge of the existence and characteristics of protective technologies?
The traditional dichotomy between attitude and behavior, observed in  several aspects of human psychology and studied in the social psychology literature since [24] and [13], may also appear in the privacy space because of these distortions.
Monetary costs may for instance  include adoption costs (which are probably fixed) and usage costs (which are variable) of protective technologies - if the individual decides to protect herself.
Likewise, the benefits from  protecting (or not protecting) personal information may also be easy to quantify in monetary terms (the discount you receive for revealing personal data) or be intangible (the feeling of protection when you send encrypted emails).
Privacy seems to be a case study encompassing many of those distortions: hyperbolic discounting, under insurance, self-control  problems, immediate gratification, and others.
Different parties involved may not have the same amount of information about the transaction and may be uncertain about some important  aspects of it [4].
The probability distributions of other events may be very  difficult to estimate because the environment is too  dynamicfor example, the probability of being subject to identity theft 5 years in the future because of certain data you are  releasing now.
[35], for instance, shows that while young  smokers appreciate the long term risks of smoking, they do not fully realize the cumulative relation between the low risks of each additional cigarette and the slow building up of a  serious danger.
2 The negative utility coming from future potential  misuses of somebody"s personal information could be a random shock whose probability and scope are extremely variable.
Hyperbolic  discounting may affect privacy decisions, for instance when we heavily discount the (low) probability of (high) future risks such as identity theft.3 Related to hyperbolic discounting is the tendency to underinsure oneself against certain risks [22].
Individuals encounter difficulties when dealing with  cumulative risks.
For example, individuals have a tendency to discount  ‘hyperbolically" future costs or benefits [31, 27].
Many of the payoffs associated with privacy protection or intrusion may be discovered or  ascertained only ex post through actual experience.
In economics, hyperbolic discounting implies inconsistency of personal  preferences over time - future events may be discounted at  different discount rates than near-term events.
A vast body of economic and psychological literature has by now confirmed the impact of several forms of psychological  distortions on individual decision making.
To summarize: whenever we face privacy sensitive  decisions, we hardly have all data necessary for an informed choice.
More precisely, an agent will face three problems when comparing the  tradeoffs implicit in Equation 1: incomplete information about all parameters; bounded power to process all available  information; no deviation from the rational path towards  utilitymaximization.
Actions and effects that are in the distant future are difficult to focus on given our limited foresight perspective.
As a result, the whole risk associated with revealing different pieces of personal information is more than the sum of the individual risks associated with each piece of data.
For instance, is she aware of privacy invasions and the associated risks?
Immaterial costs may include learning costs of a protective technology, switching costs between different applications, or social stigma when using anonymizing  technologies, and many others.
Or they may include the financial costs associated to identity theft, if the  individual"s information turns out not to have been adequately protected.
Incomplete information will affect almost all parameters in Equation 1, and in particular the estimation of costs and benefits.
Some of those distributions may be predicted after comparable data - for example, the  probability that a certain credit card transaction will result in fraud today could be calculated using existing statistics.
In our context, bounded rationality refers to the inability to calculate and compare the magnitudes of payoffs  associated with various strategies the individual may choose in privacy-sensitive situations.
Costs and benefits associated with privacy protection and privacy intrusions are both  monetary and immaterial.
Eventually, even if an individual had access to complete information and could  appropriately compute it, she still may find it difficult to  follow the rational strategy presented in Equation 1.
It is difficult for an individual to estimate all these  values.
Or is she limited by bounded rationality?
In addition, individuals suffer from optimism bias [42], the misperception that one"s risks are lower than those of other individuals under similar conditions.
And since it can be correlated to other data, the ‘anonymity sets" [32, 14] in which we wish to remain hidden get smaller.
What information has the individual access to as she prepares to take privacy sensitive decisions?
The cognitive costs involved in trying to calculate the best strategy could therefore be so high that the individual may just resort to simple heuristics.
But human agents are unable to process all information in their hands and draw accurate conclusions from it [34].
Difficulties with dealing with cumulative risks apply to privacy, because our personal information, once  released, can remain available over long periods of time.
23 In traditional economic theory, the agent is assumed to have both rationality and unbounded ‘computational" power to process information.
Economic transactions are often characterized by  incomplete or asymmetric information.
People tend to underappreciate the effects of changes in their states, and hence falsely project their current preferences over consumption onto their future preferences.
In what follows, we present a model of privacy attitudes and behavior based on some of these findings, and in particular on the plight of immediate gratification. 
For example, a small and apparently innocuous piece of  information might become a crucial asset or a dangerous  liability in the right context.
Through information technology, privacy invasions can be ubiquitous and invisible.
But even if we had, we would be likely unable to process it.
In the scenario we consider, once an individual provides personal information to other parties, she literally loses control of that information.
As the foresight changes, so does  behavior, even when preferences remain the same [20].
This leads to a related problem: bounded rationality.
Those three problems are precisely the same issues real people have to deal with on an everyday basis as they face privacy-sensitive decisions.
In addition, the calculations implicit in Equation 1 depend on incomplete information about the probability  distribution of future events.
Optimism bias may lead us to believe that we will not be subject to privacy intrusions.
Is the individual able to  calculate all the parameters relevant to her choice?
Consider, for instance, the difficulties in using privacy and encrypting technologies described in [43].
And even if we could process it, we may still end behaving against our own better judgment.
Far more than suggesting merely that people mispredict future tastes, this projection bias posits a systematic pattern in these  mispredictions which can lead to systematic errors in  dynamicchoice environments [25, p. 2].
3 A more rigorous description and application of hyperbolic discounting is provided in Section 4.
Incomplete information.
That loss of control propagates through other parties and persists for unpredictable spans of time.
Bounded rationality.
Psychological distortions.
We discuss each  problem in detail.
