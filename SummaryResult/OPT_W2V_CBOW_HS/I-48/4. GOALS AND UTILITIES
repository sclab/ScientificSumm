We make this precise in the function ui (·): ui (K) = max{j : 0 ≤ j ≤ |γi | & K |= γi [j ]} Note that using these definitions of goals and utility, it never makes sense to have a goal ϕ at index n if there is a logically weaker goal ψ at index n + k in the hierarchy: by definition of utility, it could never be n for any structure K. EXAMPLE 1.
, γn where K is a Kripke structure, and for each agent i in K, γi is a goal hierarchy over K. 4.1 The Utility of Normative Systems We can now define the utility of a Kripke structure for an agent.
Corollary 1"s first item says that an agent whose current  maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.
It follows from this that an agent with only universal goals can only gain from the imposition of normative systems η.
A particular Kripke structure K is said to satisfy a goal at  index x in goal hierarchy γ if K |= γ[x], i.e., if γ[x] is satisfied in all initial states S0 of K. An obvious potential property of goal  hierarchies is monotonicity: where goals at higher levels in the hierarchy logically imply those at lower levels in the hierarchy.
It implies ϕi 2 which expresses that there is a computation such that everywhere during it, it is possible to choose a continuation that eventually satisfies pi .
To see that ϕ2 4 = A E♦p2 is true in s for instance: note that on ever path it is always the case that there is a transition to t, in which p2 is true.
We will sometimes abuse notation and just write δi (K, η) for this, and refer to it as the benefit for agent i of implementing η in K. Note that this benefit can be negative.
Notice that since for any goal hierarchy γi we have γ[0] = , then for all Kripke structures, ui (K) is well defined, with ui (K) ≥ 2 CTL ∗ model checking is PSPACE-complete, and hence much worse (under standard complexity theoretic assumptions) than model checking CTL [8].
The simplest would be to specify goals γ for an agent as a finite, non-empty, one-to-one relation: γ ⊆ L×R.
Suppose we are given a multi-agent system M = K, γ1, .
Next, we want to be able to capture the goals that agents have, as these will drive an agent"s strategic considerations - particularly, as we will see, considerations about whether or not to comply with a normative system.
The table at the left hand in Figure 2 displays the utilities δi (K, η) of implementing η in the Kripke structure of our running example, for the normative systems η = η∅, η1, η2 and η3, introduced before.
However, our basic complexity results in the next sections would not hold for the richer language CTL ∗2 , and the price to pay for this is that we have to formulate our desired goals in a somewhat more cumbersome manner than we might ideally like.
Define each agent"s goal hierarchy as: γi = ( ϕi 0 = , ϕi 1 = E♦pi , ϕi 2 = E E♦pi , ϕi 3 = E♦E pi , ϕi 4 = A E♦pi , ϕi 5 = E♦A pi ϕi 6 = A A♦pi , ϕi 7 = A (A♦pi ∧ E pi ), ϕi 8 = A pi ) The most desired goal of agent i is to, in every computation,  always have the resource, pi (this is expressed in ϕi 8).
Suppose K1 K2, and s ∈ S. Then ∀ε ∈ Le : K1, s |= ε ⇒ K2, s |= ε ∀μ ∈ Lu : K2, s |= μ ⇒ K1, s |= μ This has the following effect on imposing a new norm: COROLLARY 1.
Let us therefore define two fragments of the language of CTL: the universal language Lu with typical element μ, and the existential fragment Le with typical element ε. μ ::= | p | ¬p | μ ∨ μ | A fμ | A μ | A(μ U μ) ε ::= | p | ¬p | ε ∨ ε | E fε | E♦ε | E(ε U ε) Let us say, for two Kripke structures K1 = S, S0 , R1, A, α, V and K2 = S, S0 , R2, A, α, V that K1 is a subsystem of K2 and K2 is a supersystem of K1, written K1 K2 iff R1 ⊆ R2.
η δ1(K, η) δ2(K, η) η∅ 0 0 η1 0 3 η2 3 0 η3 2 2 C D C (2, 2) (0, 3) D (3, 0) (0, 0) Figure 2: Benefits of implementing a normative system η (left) and pay-offs for the game ΣM .
The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.
The intended interpretation of such a goal hierarchy γi for agent i ∈ A is that the further up the  hierarchy a goal is, the more it is desired by i.
However, these observations implicitly assume that all agents in the system will comply with the norm.
Thanks to our reasonableness constraint, this goal implies ϕi 7 which says that, no matter how the computation paths evolve, it will always be that all The Sixth Intl.
We say η is individually rational for i wrt K if δi (K, η) > 0, and individually rational simpliciter if η is  individually rational for every agent.
Let K be a structure, and η a normative  system.
Formally, a goal hierarchy γ is monotonic if for all x ∈ {1, .
We assume that the x values in pairs (ϕ, x) ∈ γ are specified so that x for agent i means the same as x for agent j , and so we have cardinal utility.
Whether they will in fact do so, of course, is a strategic decision: it partly depends on what the agent thinks that other agents will do.
The idea is that the utility of a Kripke structure is the highest index of any goal that is guaranteed for that agent in the Kripke structure.
Goal ϕi 3 says that pi should be true on some branch, from some moment on.
We will model an agent"s goals as a prioritised list of CTL formulae, representing increasingly desired properties that the agent wishes to hold.
A social system now is a pair Σ = M , η where M is a multi-agent system, and η is a normative system over M .
Formally, a goal hierarchy, γ, (over a Kripke structure K) is a finite, non-empty sequence of CTL formulae γ = (ϕ0, ϕ1, .
The fact that ui (K1) > ui (K2) certainly means that i strictly prefers K1 over K2, but the fact that ui (K) > uj (K) does not mean that i values K more highly than j .
Goal ϕi 6 is a fairness  constraint implied by it.
If this value is greater than 0, then the agent would be better off if the normative system were imposed, while if it is less than 0 then the agent would be worse off if η were imposed than in the original system.
Note that we assume that if an agent can achieve a goal at a particular level in its goal hierarchy, then it is unconcerned about goals lower down the  hierarchy.
There are other representations for goals, which would allow us to define cardinal utilities.
ϕi 4 requires that in every path, there is always a continuation that eventually gives pi .
We use a natural number  indexing notation to extract the elements of a goal hierarchy, so if γ = (ϕ0, ϕ1, .
Suppose agent i"s utility ui (K † η) is n, and γi [n] is an existential formula ε.
Then, u1(K) = u2(K) = 4: goal ϕ4 is true in S0 , but ϕ5 is not.
The simplest type of monotonic goal hierarchy is where γ[x + 1] = γ[x] ∧ ψx+1 for some ψx+1, so at each successive level of the hierarchy, we add new constraints to the goal of the previous level.
This implies ϕi 1, which says that pi should at least not be impossible.
Hence, an agent with only existential goals might well fear any norm η.
Suppose agent i"s utility ui (K) is n, and γi [n] ∈ Lu , (i.e., γi [n] is a universal formula).
Note that typically K † η K. Then we have (cf.
Let γi denote a goal hierarchy for agent i.
A multi-agent system collects together a Kripke structure  (representing the basic properties of a system under consideration: its state space, and the possible state transitions that may occur in it), together with a goal hierarchy, one for each agent, representing the aspirations of the agents in the system.
The goal ϕi 5 is like the strong goal ϕi 8 but it accepts that this is only achieved in some computation, eventually.
Of course, our basic framework does not demand that goals are expressed in CTL; they could equally well be expressed in CTL ∗ or indeed ATL [2] (as in [15]).
We then define the utility for i of a Kripke structure K asui (K) = max{x : (ϕ, x) ∈ γi & K |= ϕ}.
Note that this is an ordinal utility measure: it tells us, for any given agent, the relative utility of different Kripke structures, but utility values are not on some standard system-wide scale.
ϕi 6 circumvents this: it says that, no matter where you are, there should be a future pi state.
However, this is not a proper CTL  formula.
It is in fact a formula in CTL ∗ [9], and in this logic, the two expressions would be equivalent.
The reason is that his current goal will at least remain true (in fact a goal higher up in the hierarchy may become true).
(continued) Let M = K, γ1, γ2 be the  multiagent system of Figure 1, with γ1 and γ2 as defined earlier in this example.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Keeping in mind that a norm η restricts the possible transitions of the model under consideration, we make the following  observation, borrowing from [15].
Summarising, the utility of a normative system to an agent is the difference between the utility of the Kripke structure in which the normative system was implemented and the original Kripke  structure.
Then the utility of η to agent i wrt K is δi (K, K † η).
Note that A♦pi says that every computation eventually reaches a pi state.
We remark that it may seem more natural to express a fairness constraint ϕi 6 as A ♦pi .
, ϕk ) then γ[0] = ϕ0, γ[1] = ϕ1, and so on.
Although this is a natural property of many goal hierarchies, it is not a property we demand of all goal hierarchies.
Recall that we have defined S0 as {s, t}.
, γn and an associated normative system η over K. Let for agent i, δi (K, K ) be the difference in his utility when moving from K to K : δi (K, K ) = ui (K )− ui (K).
Our next step is to show how, in much the same way, we can lift the utility function from Kripke structures to normative systems.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 883 continuations will hit a point in which pi , and, moreover, there is a continuation in which pi always holds.
Thus, it does not make sense to  compare utility values between agents, and so for example, some system wide measures of utility, (notably those measures that aggregate  individual utilities, such as social welfare), do not make sense when applied in this setting.
Then, for any normative system η, δi (K, η) ≥ 0.
If we even drop that demand, we have the trivial goal ϕi 0.
Formally, a multi-agent system, M , is an (n + 1)-tuple: M = K, γ1, .
We denote the largest index of any element in γ by |γ|.
The results of this paper in fact hold irrespective of which of these representations we actually choose; we fix upon the goal hierarchy approach in the interests of simplicity.
(continued) Suppose the agents have similar, but opposing goals: each agent i wants to keep the source as often and long as possible for himself.
Some classes of goals are monotonic or anti-monotonic with respect to adding additional constraints to a system.
, |γ|} ⊆ N, we have |= γ[x] → γ[x − 1].
, ϕk ) in which, by convention, ϕ0 = .
This may mean that after pi has  happened, it will never happen again.
This motivates us to consider normative system games. 
We  comment on the implications of alternative goal representations at the conclusion of the next section.
Then, δi (K † η, K) ≥ 0.
However, as we shall see shortly, other  measures - such as Pareto efficiency - can be usefully applied.
4.2 Universal and Existential Goals 884 The Sixth Intl.
Recall that u1(K) = u2(K) = 4.
THEOREM 1.
Joint Conf.
Joint Conf.
EXAMPLE 1.
EXAMPLE 1.
