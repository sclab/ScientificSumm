These experiments reveal that finding documents on  secondary storage dominates the total cost of generating  snippets, and so caching documents in RAM is essential for a fast snippet generation process.
In this paper we  explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets.
Finally we propose and analyse document  reordering and compaction, revealing a scheme that increases the number of document cache hits with only a marginal  affect on snippet quality.
Using simulation, we  examine snippet generation performance for different size RAM caches.
We begin by proposing and analysing a document compression method that reduces snippet generation time by 58% over a baseline using the zlib compression library.
The presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users.
This scheme effectively doubles the number of documents that can fit in a fixed size cache.
Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.3.4 [Information Storage and Retrieval]: Systems and Software-performance evaluation (efficiency and effectiveness); General Terms Algorithms, Experimentation, Measurement, Performance 
