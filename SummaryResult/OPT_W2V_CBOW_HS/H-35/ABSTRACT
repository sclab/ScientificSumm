Ideally a learning  algorithm would train a ranking model that could directly optimize the performance measures with respect to the training data.
Experimental results on four benchmark datasets show that AdaRank significantly outperforms the baseline methods of BM25, Ranking SVM, and RankBoost.
Existing methods, however, are only able to train ranking models by  minimizing loss functions loosely related to the performance measures.
We prove that the training process of AdaRank is exactly that of enhancing the  performance measure used.
Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models General Terms Algorithms, Experimentation, Theory 
In the task, a model is automatically created with some training data and then is utilized for ranking of documents.
Our algorithm,  referred to as AdaRank, repeatedly constructs â€˜weak rankers" on the basis of re-weighted training data and finally linearly combines the weak rankers for making ranking predictions.
For example, Ranking SVM and RankBoost train ranking  models by minimizing classification errors on instance pairs.
To deal with the problem, we propose a novel learning algorithm within the framework of boosting, which can minimize a loss function directly defined on the performance measures.
In this paper we address the issue of learning to rank for document retrieval.
The goodness of a model is usually evaluated with performance  measures such as MAP (Mean Average Precision) and NDCG  (Normalized Discounted Cumulative Gain).
