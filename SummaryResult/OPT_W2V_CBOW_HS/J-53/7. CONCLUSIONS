Another assumption is that users have infinite work, so the more resources they can  acquire, the better.
In addition, with a few exceptions under the finite parallelism model, the system reaches equilibrium quickly by using the best response algorithm and, when the number of users is not too small, by the greedy local  adjustment method.
For example, we assume that there is no parallelization cost, and there is no performance degradation when multiple users share the same machine.
When the job size is large enough and the degree of multiplexing is sufficiently low, we can probably ignore those effects, but those costs should be taken into account for a more realistic modeling.
One direction is to consider more realistic utility functions.
135 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 140 160 Number of Users (a) Limit: 5 machines/user Efficiency Utility uniformity Envy-freeness 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50 60 70 80 90 Number of Users (b) Limit: 20 machines/user Efficiency Utility uniformity Envy-freeness Figure 6: Efficiency, utility uniformity and envy-freeness under the finite parallelism model.
In addition to the usual  questions concerning repeated games, it would also be important to understand how users should allocate their budgets wisely over time to accomodate future needs.
Another direction is to study the dynamic properties of the system when the users" needs change over time,  according to some statistical model.
One approach to address this is to model the user"s utility  according to the time to finish a task rather than the amount of resources he receives.
While our work indicates that the price-anticipating scheme may work well for resource allocation for shared clusters, there are many interesting directions for future work.
We show that despite the worst case bounds, the system can reach a high performance level at the Nash equilibrium in terms of both efficiency and fairness metrics.
For examples, the user must copy code and data to a machine before running his application there, and there is overhead for multiplexing resources on a single  machine.
In practice, users have finite work.
This work studies the performance of a market-based  mechanism for distributed shared clusters using both analyatical and simulation methods.
In practice, both assumptions may not be correct.
n = 100. 
