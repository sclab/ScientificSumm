3.1.3 System 3: QueryDestination QueryDestination uses an interface similar t However, instead of showing query refinemen query, QueryDestination suggests up to six des visited by other users who submitted queries s one, and computed as described in the previous shows the position of the destination suggestio page.
To motivate the subjects during their searches, we allowed them to select two known-item and two exploratory tasks at the beginning of the experiment from the six possibilities for each category, before seeing any of the systems or having the study described to them.
To examine the usefulness of destinations, we con study investigating the perceptions and performance on four Web search systems, two with destination sug 3.1 Systems Four systems were used in this study: a baseline Web with no explicit support for query refinement (Base system with a query suggestion method that recomme queries (QuerySuggestion), and two systems that aug Web search with destination suggestions using either query trails (QueryDestination), or end-points of (SessionDestination).
Next n that allows the user ithin the destination a separate list, rather they may topically focusing on related s).
After completing the tasks on the four systems, subjects answered a final questionnaire comparing their experiences on the systems.
Suggestions were offered in a box positioned on the t result page, adjacent to the search results.
Subjects were given an overview of the study in written form that was read aloud to them by the experimenter.
All are familiar with Web search, and conduct 7.5 searches per day on average (SD=4.1).
3.2 Research Questions We were interested in determining the value of p To do this we attempt to answer the following re 3 To improve reliability, in a similar way to QueryS are only shown if their popularity exceeds a frequen med suggestions QuerySuggestion.
RQ1: Are popular destinations preferable and more effective than query refinement suggestions and unaided Web search for: a. Searches that are well-defined (known-item tasks)?
3.1.1 System 1: Baseline To establish baseline performance against which othe be compared, we developed a masked interface to a p engine without additional support in formulating q system presented the user-constructed query to the and returned ten top-ranking documents retrieved by t remove potential bias that may have been caused by perceptions, we removed all identifying information engine logos and distinguishing interface features.
Each moothed overall he target query Based on these .
If fewer than rformed using imilar strategy top-right of the 1a shows the hows a zoomed he suggestions of each query (a) Position of suggestions (b) Zoo Figure 1.
3.1.2 System 2: QuerySuggestion In addition to the basic search functionality offered QuerySuggestion provides suggestions about f refinements that searchers can make following an submission.
One set is com most frequent such queries, while the second set cont frequent queries that followed the target query in que candidate query is then scored by multiplying its sm frequency by its smoothed frequency of following th in past search sessions, using Laplacian smoothing.
Subjects were instructed to attempt the task on the assigned system searching the Web, and were allotted up to 10 minutes to do so.
We show destinations as a than increasing their search result rank, since deviate from the original query (e.g., those topics or not containing the original query terms 3.1.4 System 4: SessionDestination The interface functionality in SessionDestinat QueryDestination.
The only difference between the definition of trail end-points for queries use destinations.
The known-item search tasks required search for particular items of information (e.g., activities, discoveries, names) for which the target was  welldefined.
QueryDestination directs users to end up at for the active or similar que SessionDestination directs users to the domains the end of the search session that follows th queries.
Prior to the experiment all tasks were pilot tested with a small number of different subjects to help ensure that they were comparable in difficulty and selectability (i.e., the likelihood that a task would be chosen given the alternatives).
Figure position of the suggestions on the page.
These tasks generally required subjects to gather background information on a topic or gather sufficient information to make an informed decision.
Figure 2b shows a zoomed view of the p page destinations suggested for the query [hubb (a) Position of destinations (b) Zoo Figure 2.
Tasks were taken and adapted from the Text Retrieval Conference (TREC) Interactive Track [7], and questions posed on question-answering communities (Yahoo!
Post-hoc analysis of the distribution of tasks selected by subjects during the full study showed no preference for any task in either category.
Destination presentation in Que To keep the interface uncluttered, the page title is shown on hover over the page URL (shown to the destination name, there is a clickable icon to execute a search for the current query wi domain displayed.
To subjects" prior such as search d by Baseline, further query n initial query ng the search eneration.
Thirty-one subjects (86.1%) reported general awareness of the query refinements offered by commercial Web search engines.
This downgrades the effect of multi (i.e., we only care where users end up after sub rather than directing searchers to potentially irre may precede a query reformulation.
b. Searches that are ill-defined (exploratory tasks)?
Subjects completed a demographic questionnaire focusing on aspects of search experience.
While prediction task ults of the user hat this simple nducted a user of 36 subjects ggestions.
A similar task classification has been used successfully in previous work [21].
nts for the submitted stinations frequently imilar to the current s section.3 Figure 2a ons on search results portion of the results le telescope].
You want to learn more about VoIP technology and providers that offer the service, and select the provider and telephone that best suits you.
These suggestions are computed usin engine query log over the timeframe used for trail ge each target query, we retrieve two sets of candidate su contain the target query as a substring.
In contrast, s other users visit at he active or similar iple query iterations bmitting all queries), elevant domains that popular destinations.
We constructed six known-item tasks and six open-ended, exploratory tasks that were rotated between systems and subjects as described in the next section.
Examples of known-item and exploratory tasks.
six suggestions are found, iterative backoff is per progressively longer suffixes of the target query; a si is described in [10].
Subjects were tested independently and each experimental session lasted for up to one hour.
RQ2: Should popular destinations be taken from the end of query trails or the end of session trails?
In the next section we present the findings of this study. 
Upon arrival, subjects were asked to select two known-item and two exploratory tasks from the six tasks of each type.
Subjects were given an explanation of interface functionality lasting around 2 minutes.
Query suggestion presentation in suggestion is an icon similar to a progress b normalized popularity.
search system line), a search ends additional gment baseline r end-points of session trails er systems can popular search queries.
Exploratory tasks were phrased as simulated work task situations [5], i.e., short search scenarios that were designed to reflect real-life information needs.
3.3 Subjects 36 subjects (26 males and 10 females) participated in our study.
System had four levels (corresponding to the four experimental systems) and search tasks had two levels (corresponding to the two task types).
For each of the four interface conditions: a.
3.4 Tasks Since the search task may influence information-seeking behavior [4], we made task type an independent variable in the study.
B scores, six top-ranked query suggestions are returned.
bar that encodes its retrieves new search to QuerySuggestion.
Clicking a suggestion r results for that query.
c. Upon completion of the task, subjects were asked to complete a post-search questionnaire.
The average age of subjects was 34.9 years (max=62, min=27, SD=6.2).
This search engine the engine.
System and task-type order were counterbalanced according to a Graeco-Latin square design.
3.5 Design and Methodology The study used a within-subjects experimental design.
Figure 1b sh view of the portion of the results page containing th offered for the query [hubble telescope].
They were recruited through an email announcement within our organization where they hold a range of positions in different divisions.
esearch questions: Suggestion, destinations ncy threshold.
Figure 3 shows examples of the two task types.
Known-item task Identify three tropical storms (hurricanes and typhoons) that have caused property damage and/or loss of life.
tion is analogous to n the two systems is ed in computing top the domains others ries.
Exploratory task You are considering purchasing a Voice Over Internet Protocol (VoIP) telephone.
e of each destination in Figure 2b).
Subjects were thanked and compensated.
med destinations eryDestination.
For uggestions that mposed of 100 tains 100 most ery logs.
To the left o nd , are ery- and  userctively.
We adhered to the following procedure: 1.
Answers, Google Answers, and Windows Live QnA).
Figure 3.
