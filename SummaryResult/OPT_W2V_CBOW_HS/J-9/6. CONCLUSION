A more satisfying approach would be to  assume only rationality and solve for the resulting  gametheoretic solution strategy, either in our current  computational model or another model of an information market.
Within this model, we prove several results characterizing precisely what the market can compute and how quickly.
We prove that the process whereby agents reveal their  information over time and learn from the resulting announced prices takes at most n rounds to converge to the correct full-information price in the worst case.
Specifically, we show that the market is guaranteed to converge to the true rational expectations equilibrium if and only if the  security payoff function is a weighted threshold function.
We show that this bound is tight within a factor of two.
Some  interesting and important next steps include gaining a better understanding of the following: • The effect of price accuracy and precision: We have  assumed that the clearing price is known with unlimited precision; in practice, this will not be true.
For example, can we find a good distributed-computational model of a decentralized market?
In a sense, some of the computation  itself is distributed among the participating agents, but can the market computation also be distributed?
We have developed a simplified model of an information  market that we believe captures many of the important aspects of real agent interaction in an information market.
• Incremental updates: If the agents have computed the value of the function and a small number of input bits are switched, can the new value of the function be computed incrementally and quickly?
What is the minimum number of threshold securities required to implement a given function?
6.2 Future work We view this paper as a first step towards understanding the computational power of information markets.
What configuration of  securities can best approximate a given function?
• Strategic market models: For reasons of simplicity and tractability, we have directly assumed that agents bid truthfully.
Are there ways to define and configure securities to speed up convergence to equilibrium?
It is interesting to ask what  aggregates can be computed even in the presence of noisy prices.
• Information market design: Non-threshold functions can be implemented by layering two or more  threshold functions together.
• The common-prior assumption: Can we say anything about the market behavior when agents" priors are only approximately the same or when they differ  greatly?
6.1 Summary We have framed the process of information aggregation in markets as a computation on distributed information.
It is interesting to ask whether we would get very different results for generic prior distributions.
• Distributed computation: In our model, distributed  information is aggregated through a centralized market 163 computation.
Further, we have neglected influences on the market price other than from rational traders; the market price may also be influenced by other factors such as misinformed or irrational traders.
• Average-case analysis: Our negative results (Theorems 3 and 5) examine worst-case scenarios, and thus  involve very specific prior probability distributions.
• Agents" computation: We have not accounted for the complexity of the computations that agents must do to accurately update their beliefs after each round.
This is exactly the problem of minimizing the size of a neural network, a well-studied problem known to be NP-hard [15].
What is the  relationship between machine learning (e.g., neural-network learning) and information-market design?
Acknowledgments We thank Joe Kilian for many helpful discussions.
We thank Robin Hanson and the anonymous reviewers for useful  insights and pointers. 
