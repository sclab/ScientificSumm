Our experiments also show that we can do fairly well on dependencies using only surface-features such as  cosinesimilarity and time-stamps of news stories as long as true events are provided to the system.
Any opinions, findings and conclusions or recommendations expressed in this material are the authors" and do not necessarily reflect those of the sponsor. 
As part of our future work, we plan to investigate further into the data and discover new features that influence clustering as well as dependencies.
We also hope to devise an iterative algorithm which can improve clustering and dependency performance alternately as suggested by one of the reviewers.
In this paper, we also proposed a few approaches for both clustering stories into events and constructing dependencies among them.
Hence, we should focus not only on improving dependencies but also on clustering at the same time.
We developed a  timedecay based clustering approach that takes advantage of  temporallocalization of news stories on the same event and showed that it performs significantly better than the baseline approach based on cosine similarity.
We also hope to expand our labeled corpus further to include more diverse news sources and larger and more complex event structures.
Our results indicate modeling dependencies can be a very hard problem especially when the clustering performance is below ideal level.
Acknowledgments We would like to thank the three anonymous reviewers for their valuable comments.
In this paper, we have presented a new perspective of modeling news topics.
Errors in clustering have a magnifying effect on errors in  dependencies as we have seen in our experiments.
Contrary to the TDT view of topics as flat  collection of news stories, we view a news topic as a relational structure of events interconnected by dependencies.
This work was supported in part by the Center 452 Model Cluster T Dep.
And for modeling dependencies, a probabilistic framework should be a better choice since there is no definite  answer of yes/no for the causal relations among some events.
However, the performance deteriorates rapidly if the system has to discover the events by itself.
Despite that discouraging result, we have shown that our combined  algorithms perform significantly better than the baselines.
T CP CR CF DP DR DF JF P-value cos+TD+Nearest-Parent 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19  0.27cos+TD+Best-Similarity 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23  0.32cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25  0.33cos+TD+Simple-Thresholding 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Complete-link) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30  0.33Table 6: Combined results on the training set Model CP CR CF DP DR DF JF P-value cos+TD+Nearest Parent 0.57 0.50 0.50 0.27 0.19 0.21  0.30cos+TD+Best Similarity 0.48 0.70 0.54 0.31 0.27 0.26  0.35cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28  0.37cos+TD+Simple Thresholding 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Complete-link) 0.66 0.27 0.36 0.30 0.72 0.43  0.39Table 7: Combined results on the test set for Intelligent Information Retrieval and in part by  SPAWARSYSCENSD grant number N66001-02-1-8903.
