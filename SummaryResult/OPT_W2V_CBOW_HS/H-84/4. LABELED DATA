If the topic contained more than 30 CNN stories, we picked only the first 30 stories to keep the topic short enough for  annotators.
The annotator was also encouraged to avoid singleton events, events that contain a single news story, if possible.
We supervised the annotator on a set of three topics that we did our own annotations on and then asked her to annotate the 28 topics from TDT2 and 25 topics from TDT3.
Annotation includes defining the event membership for each story and also the  dependencies.
The reason for choosing only CNN as the source is that the stories from this source tend to be short and precise and do not tend to digress or drift too far away from the central theme.
Each event could have single,  multiple or no parents.
From the annotated topics, we created a training set of 26 topics and a test set of 27 topics by merging the 28 topics from TDT2 and 25 from TDT3 and splitting them randomly.
The criterion we used for selecting a topic is that it should contain at least 15 on-topic stories from CNN headline news.
topics 26 27 Avg.
The annotator was encouraged to merge two events A and B into a single event C if any of the  stories discusses both A and B.
64.60 64.04 Avg.
As part of the guidelines, we instructed the annotator to assign titles to all the events in each topic.
In identifying events in a topic, the annotator was asked to broadly follow the TDT definition of an event, i.e., ‘something that happens at a specific time and location".
We picked 28 topics from the TDT2 corpus and 25 topics from the TDT3 corpus.
This is to satisfy our assumption that each story corresponds to a unique event.
Days/Topic 30.65 34.48 Table 1: Statistics of annotated data 
The annotator was however instructed to assign a  dependency from event A to event B if and only if the occurrence of B is ‘either causally influenced by A or is closely related to A and follows A in time".
Table 1 shows that the training and test sets have fairly similar statistics.
We realized from our own experience that people differ in their perception of an event especially when the number of stories in that event is small.
Further, the graph could have cycles or  orphannodes.
We believe modeling such stories would be a useful first step before dealing with more complex data sets.
Feature Training set Test set Num.
In defining dependencies between events, we imposed no  restrictions on the graph structure.
We hired an annotator to create truth data.
Dependencies/Topic 3.07 2.92 Avg.
We however, do not use or model these titles in our algorithms.
We believe that this would help make her understanding of the events more concrete.
Events/Topic 5.07 4.29 Avg.
Stories/Event 5.65 6.22 Avg.
Stories/Topic 28.69 26.74 Avg.
Dependencies/Event 0.61 0.68 Avg.
