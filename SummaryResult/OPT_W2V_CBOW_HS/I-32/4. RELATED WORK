The Mâˆ— algorithm presented by Carmel and Markovitch [2] showed a method of incorporating  opponent models into adversary search, while in [3] they used learning to provide a more accurate opponent model in a  2player repeated game environment, where agents" strategies were modeled as finite automata.
As far as we know, our model is the first to provide a formalized model for explicit adversarial environments and agents" behavior in it.
However, the basic limitations of those search methods still apply; our model tries to overcome those  limitations by presenting a formal model for a new, mental state-based adversarial specification. 
The classical Min-Max adversarial search algorithm was the first attempt to integrate the opponent into the search space with a weak assumption of an optimally playing  opponent.
That work shows the importance of opponent modeling and the ability to exploit it to an agent"s advantage.
The research mentioned above dealt with adversarial search and the integration of opponent models into classical  utilitybased search methods.
[13], which  provided an adversarial planning approach to the game of GO.
Since then, much effort has gone into integrating the opponent model into the decision procedure to predict future behavior.
Much research deals with the axiomatization of teamwork and mental states of individuals: some models use  knowledge and belief [10], others have models of goals and  intentions [8, 4].
However, all these formal theories deal with agent teamwork and cooperation.
Additional Adversarial planning work was done by Willmott et al.
