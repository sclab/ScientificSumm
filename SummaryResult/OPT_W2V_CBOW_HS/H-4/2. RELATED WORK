A second difficulty in performing PIM laboratory  studies is creating tasks for participants to perform that can be solved by searching a shared or personal collection.
This presents a serious problem - how can researchers  devise tasks that correspond to private collections without an understanding of the kinds of tasks people perform or  jeopardising the privacy of study participants?
Unfortunately, it has also been shown that there are difficulties involved in performing this type of evaluation - it is difficult to source collections and to devise tasks that correspond to private collections, while at the same time protect the  privacy of the study participants.
However, a shared collection would be unsuitable for user studies because it would not be  possible to incorporate the personal aspects of PIM while using a common, unfamiliar collection.
Consequently, it is difficult to devise simulated work task situations for PIM.
Laboratory-based studies simulate users" real world environment in the controlled setting of the laboratory,  offering the ability to study issues that are tightly defined and narrow in scope.
For example, [20] studied email search by asking participants to re-find emails that had been sent to every member in a department; allowing the same tasks to be used for all of the study participants.
In section 5 we build on this work by examining methods for creating tasks that do not compromise the privacy of participants and discuss how our work can facilitate task-based PIM user evaluations.
Further, if time is utilised by a system or interface being tested the approach is unsuitable because all of the objects found in the first session will have been accessed within the same time period.
Our review of evaluation approaches motivates a  requirement for controlled laboratory experiments that allow tightly defined aspects of systems or interfaces to be tested.
Another solution is to use the entire web as a collection when studying web page re-finding [4].
This may be appropriate for studying web page re-finding because previous studies have shown that people often use web search engines for this purpose [5].
This reveals a need to complement naturalistic studies with controlled experiments where the experimenter can  relate the behaviour of study participants to goals associated with known search tasks.
A large body of work has been carried out to understand the nature of tasks and how the type of task influences user information seeking behaviour.
We show that by collecting tasks using electronic diaries, not only can we learn about the tasks that cause people to re-find personal information, but we can learn about the contents of private collections without compromising the privacy of the participants.
Systems can then be compared across task types for different users [11].
The limitations of this technique are that it does not allow participants to  exploit any personal connections with the information because the information they are looking for may not correspond to any other aspect of their lives.
Further, caution must be taken when analysing logs, as the captured data shows  nothing about the goals and intentions that the user had at the time.
This approach makes use of logging software that captures a broad sampling of user activities in the context of natural use of a system.
In the following section we present a diary study of  refinding tasks for email and web pages.
Further, other types of object are more sensitive to privacy than photographs; it is unlikely that participants would be as content to allow researchers to browse their email  collections to create tasks as they were with photographs in [11].
For example, [5] asked participants to classify tasks based on how frequently they perform the task type in their daily life and how familiar they were with the location of the sought after information and several scholars have classified information objects by the frequency of their use e.g.
Other previous work has provided methodologies that allow the simulation of tasks when studying information seeking behaviour [2].
These approaches allow researchers to overcome many of the difficulties caused by the personal nature of PIM.
However, little is known about the kinds of tasks that cause people to search their personal stores or re-find information that they have seen before.
Log file analysis is a  powerful methodology as it allows the capture of a large quantity of detailed information about how users behave with the system without the expense and distracting influence of an observer.
Firstly, evaluation in this way is expensive; taking long time periods to study small numbers of participants and these small samples may not be representative of the behaviour of larger populations.
In section 4 we show that people perform a wider range of email re-finding tasks than this.
As the tasks performed are real and not simulated, the participants can utilise their own experiences, previous knowledge and information collections to complete the tasks.
Both ethnographic and fieldwork methods require the presence of an experimenter to assess how PIM is performed, which raises a number of issues.
For  example, tasks have been categorised in terms of increasing complexity [3] and task complexity has been suggested to affect how searchers perceive their information needs [25] and how they try to find information [3].
In [9] a novel PIM search tool was deployed to 234 users and the log data provided detailed information about the nature of user queries, interactions with the query interface and about properties of the items retrieved.
A benefit of the approach is that data can be captured continuously over extended time periods and  measurements can be taken at fixed points in time within these [15].
Tasks relate to the activity that results in a need for information [14] and are acknowledged to be important in determining user behaviour [26].
This  approach has been applied to study the re-finding of personal photographs [11], email messages [20], and web-bookmarks [21].
This knowledge can then be used to construct tasks for use in PIM evaluations. 
The  exception is the study of personal photograph management, where Rodden"s work on categorising personal photograph search tasks has facilitated the creation of simulated work task  situations [22].
In the first session, participants were asked to complete work tasks that involved finding some unknown information.
The outcome is a classification of tasks similar to that devised by Rodden for personal photographs [22].
In [4], generic search tasks were artificially created by running evaluations over two sessions.
One alternative approach is to ask users to provide their own information collections to simulate familiar environments within the lab.
There have been other suggestions as to how to classify PIM tasks.
While these are interesting properties that may affect how a task will be performed, they do not give experimenters enough scope to devise tasks.
Firstly, to attain useful results, the deployed prototype must be something that people would use i.e.
Naturalistic approaches study participants performing  naturally, completing their own tasks as they occur, within  familiar environments.
it has to be a fully functional piece of software that offers improvement on the systems ordinarily available to participants.
This approach ensured that privacy issues were avoided and participants could use things that they remember to complete tasks.
A variety of approaches are available to study PIM.
Kelly [16]  proposes the introduction of a shared test collection that would provide sharable, reusable data sets, tasks and metrics for those interested in conducting PIM research.
One difficulty in performing this kind of evaluation is sourcing collections to evaluate.
Nevertheless, the systems were only tested using one type of task - participants were asked to find single emails, each of which shared common properties.
Personal collections are one reason why task creation is so difficult.
Rodden"s photo task taxonomy provides a solution here because it allows tasks, tailored to private collections to be categorised.
In the second session, participants completed the same tasks again, which  naturally involved some re-finding behaviour.
The usefulness of this approach depends on how easy it is to transfer the collection or gain remote access.
This may be useful for testing algorithms in a way similar to TREC in mainstream IR [13].
Secondly, because  participants cannot be continually observed, experimenters must choose when to observe and this may affect the findings.
Developing a research prototype to this standard is beyond the resources of many researchers.
An alternative strategy to conducting naturalistic  evaluations is to utilise log file analysis.
It is, therefore, difficult to make any concrete  statements about the reasons for the behaviour depicted in the logs.
Unfortunately, no  equivalent taxonomy exists for other types of information object.
A few methods have been proposed.
Nevertheless, there are limitations to this  strategy.
Naturalistic approaches can be applied by  conducting fieldwork [17, 8], ethnographic methods as suggested by [15] or via log file analysis [9, 7].
