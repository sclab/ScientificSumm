It was also decided to categorise these as lookup tasks because in all cases these were logged by participants as email searches and, within this context, what they were looking for was information within an email.
From the descriptions supplied by the participants, we found similar features in the recorded tasks for both email and web re-finding.
We also investigated whether the type of task or the length of time between accessing and re-accessing made a task more difficult.
Some recorded examples of item tasks were: • I1: Looking for SIGIR 2002 paper to give to another student • I2: Find the receipt of an online airline purchase required to claim expenses • I3: I need the peer evaluation forms for the MIA class E sent me them by email To clarify, lookup tasks differ from item tasks in two ways - in the quantity of information required and in what the user knows about what they are looking for.
Although no evidence was found that web or email tasks were more difficult, there was some evidence showing that the time between accessing and re-accessing affected how  difficult the participants perceived tasks to be.
We examined the types of task that caused the participants to search their personal stores and found three main categories of task: tasks where the user requires specific information from within a single  resource, tasks where a single resource is required, and tasks that require information to be recovered from multiple  resources.
Another distinction was the number of recorded multi-item tasks for web and email.
For example, consider the following recorded task: • LU4: re-find AS"s paper on graded relevance assessments  because I want to see how she presented her results for a paper I am writing This task actually consists of two sub-tasks: 1 item  task(refind the paper) and 1 lookup task (look for specific  information within the paper).
Figure 1: Difficulty ratings for task types From figure 1, it does not appear that any particular task type was perceived as difficult with respect to the others, although there is a suggestion that lookup tasks were  perceived more difficult when looking for cold information than hot and item tasks were perceived more difficult for warm information than hot.
Decided to use some other means Such tasks were labelled as U for unclassifiable.
For the item task data, there was evidence that hot and cold tasks were rated differently (p=0.024), but no evidence to distinguish between hot and warm tasks(p=0.05) or warm and cold tasks(p=0.272).
Several analyses were performed on the captured data.
Information that had been seen less than a day or less than a week  before the task were defined as hot, information that had been seen less than a month before the task as warm, and  information that had been seen less than a year or more than a year before the task as cold.
To assess the relationship between information temperature and the perceived difficulty, we used Mood"s median tests to determine whether the rank of difficulty scores was in agreement for the information temperatures being compared (p<0.05).
Email 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) All 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Table 1: The distribution of task types In addition to the three-way classification described above, the recorded tasks were classified with respect to the  temperature metaphor proposed by [24], which classifies  information as one of three temperatures: hot, warm and cold.
Email 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) All 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Table 2: The distribution of temperatures Most of the tasks that caused people to re-find web pages (42.75%) and email messages (33.33%) involved searching for information that has been accessed in the last week.
However there were also a number of re-finding tasks that  involved searching for older information: 23.30% of the tasks recorded (24.00% for email and 22.90% for web) involved searching for information accessed in the last month and 18.69% of the tasks recorded (24.67% for email and 15.27% for web) were looking for even older information.
Next, we consider the distribution of tasks - which kinds of tasks were  performed most often by participants.
These tests confirm that the length of time between  accessing and re-accessing the sought after information indeed influenced how difficult participants perceived the task to be.
Multi-item tasks were tasks that required information that was contained within numerous web pages or email  messages.
Often these tasks required the user to process or collate the information in order to solve the task.
For the look-up task data, there was evidence that hot tasks were perceived easier than cold (p=0.0001) and that warm tasks were  perceived easier than cold tasks(p=0.0041), but there was no evidence to distinguish between the difficulty ratings of hot and warm tasks(p=0.593).
I think he sent me in it an email Item tasks involve looking for a particular email or web page, perhaps to pass on to someone else or when the entire contents are needed to complete the task.
We classified the tasks using the form data.
Firstly, we  examine the kinds of re-finding tasks that were performed both when searching on email and on the web.
We looked for patterns in the recorded data to determine if certain tasks were perceived as more difficult than  others.
The majority of email tasks (60%) involved  looking for information within an email (lookup), in contrast to web tasks where the majority of tasks (52.67%) involved looking for a single web page (item).
Overall, lookup and item tasks were the most common, with  multiitem tasks only representing 8.98% of those recorded.
Nevertheless, the large number of tasks of all types and temperatures rated by participants as easy i.e.
150 (36.41%) of these tasks were email based, 262 (63.59%) were  webbased.
This means that users may find searching for older information more difficult or perhaps alter their  seeking strategy when looking for hot, warm or cold information.
The distribution of the task types was different for web and email re-finding.
For example, we examined whether the media type  affected how difficult the participants perceived the task to be.
For example: • MI4: re-find Kelkoo website so that I can re-check the prices of hair-straighteners for my girlfriend A second source of ambiguity came from tasks such as finding an email containing a URL as a means of re-accessing a web page.
More web tasks (median=5,IQR=7.5) were recorded than email tasks (median=3, IQR=3).
Another problem was that some of the logs lacked the detail required to perform a categorisation e.g.
As with most diary studies, the number of tasks recorded varied extensively between particpants.
4.2 What tasks are difficult?
It was decided to treat this as a lookup task because the user"s ultimate goal was to access and use the information within the resource.
Multi-item tasks were very rare for email re-finding (only 2.67% of email tasks involved searching for multiple resources), but comparatively common for web re-finding (12.6%).
The tasks were classified as one of three types: lookup tasks, item tasks and multi-item tasks.
This means that on average each participant recorded  approximately one task every two days.
Lastly, we explore the kinds of re-finding tasks that participants perceived as  difficult.
Lookup tasks involve searching for specific information from within a  resource, for example an email or a web page, where the  resource may or may not be known.
There were a number of examples of combined tasks, mainly of the form item then lookup, but there were also examples of item then multi-item.
The  median number of tasks per participant was 8 (interquartile range (IQR)=9.5).
In item tasks the user knows exactly the resource they are looking for and needs the entire contents of that resource.
Some recorded examples of lookup tasks were: • LU1: Looking for the course code for a class - it"s used in a script that is run to set up a practical.
4.1 Nature of Web and Email Re-finding Tasks During the study 412 tasks were recorded.
There was no evidence that participants found either email (median=2 IQR=2) or web (median=2 IQR=2) tasks more difficult.
Looking to build a GUI within Eclipse • MI3: I am trying to file my emails regarding IPM and I am looking for any emails from or about this journal There were a number of tasks that were difficult to classify.
Unfortunately, a technical  difficulty with the form only allowed 335(81.3%) of the tasks to be classified.
The agreement between the results of the two analyses was largely consistent (96.8%).
To verify the consistency of the taxonomy, the tasks were  recategorised by the same researcher after a delay of two weeks.
It was discovered that look-up and item tasks were recorded with greater frequency than multi-item tasks.
Lookup tasks involve a need for a small piece of information e.g.
We feel that this high agreement on a large  number of tasks by more than one researcher provides evidence for the reliability of the classification scheme.
Further, we asked a researcher with no knowledge of the project or the field to classify a sample of 50 tasks.
< 3, suggests that there are other factors that influence how difficult a task is perceived to be.
A cross-tabulation of task types and temperatures is shown in table 2.
These findings have implications for evaluating PIM behaviour at the task level.
4.3 Summary In the first part of this paper, we described a diary study of web and email re-finding tasks.
This is  important with respect to evaluation because there is  psychological evidence suggesting that people remember less over time e.g.
Some recorded examples were: • MI1: Looking for obituaries and other material on the novelist John Fowles, who died at the weekend.
Based on this observation a joint  classification scheme was devised, encompassing both email and web tasks.
This is in an email somewhere • LU3: Looking for description of log format from system R developed for student project.
The distribution of task types is shown in table 1.
Accessed the online Guradian and IMES • MI2: Trying to find details on Piccolo graphics framework.
a phone number or an ingredient, and the user may or may not know exactly the resource that contains this information.
To learn about these factors would  require the kind of user evaluations proposed by [16, 6] - the kind of evaluations facilitated by our work.
I"d previously obtained this about 3 weeks ago from our website.
Hot Warm Cold Unclass.
The remainder of this paper concentrates on this,  discussing what the findings mean with respect to performing task-based PIM user evaluations. 
Lookup Item Multi-item Unclass.
• U1: searching for how to retrieve user"s selection from a  message box.
The second researcher achieved a 90% agreement.
Remind myself of what it is and what it does.
The remainder were defined as U for  unclassifiable.
• LU2: I am trying to determine the date by which I step down as an External Examiner.
The following sections present the findings.
Figure 1 shows this information  graphically.
