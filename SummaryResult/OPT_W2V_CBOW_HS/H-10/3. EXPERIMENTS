3.2 Evaluation Metrics In the experiments, we set the number of clusters equal to the true number of classes C for all the clustering  algorithms.
(31) is used as a performance measure for the given clustering result.
Our CLGR method outperforms all other document clustering methods in most of the datasets; 2.
In this section, experiments are conducted to empirically compare the clustering results of CLGR with other 8  representitive document clustering algorithms on 5 datasets.
In all our experiments, we first select the top 1000 words by mutual information with class labels.
The final  discretization method adopted in these two methods is the same as in [26], since our experiments show that using such method can achieve better results than using kmeans based methods as in [20].
For computational efficiency, in the implementation of CPLR and our CLGR algorithm, we have set all the local regularization parameters {λi}n i=1 to be identical, which is set by grid search from {0.1, 1, 10}.
Given a clustering result, the NMI in Eq.
(24)), and the clustering results can be obtained by doing eigenvalue decomposition on matrix (I − P)T (I − P) with some proper discretization methods.
For document clustering, the Spherical k-means method usually outperforms the traditional k-means clustering method, and the GMM method can achieve  competitive results compared to the Spherical k-means method; 3.
There are mainly two sets of parameters in our CLGR algorithm, the local and global regularization parameters ({λi}n i=1 and λ, as we have said in section 3.3, we have set all λi"s to be identical to λ∗ in our experiments), and the size of the neighborhoods.
Fixing the local and global regularization parameters, and testing the clustering performance with different −5 −4.5 −4 −3.5 −3 −5 −4.5 −4 −3.5 −3 0.35 0.4 0.45 0.5 0.55 local regularization para (log 2 value) global regularization para (log 2 value) clusteringaccuracy Figure 1: Parameter sensibility testing results on the WebACE dataset with the neighborhood size fixed to 20, and the x-axis and y-axis represents the log2 value of λ∗ and λ. sizes of neighborhoods.
In this set of experiments, we find that the neighborhood with a too large or too small size will all deteriorate the final clustering results.
These documents are divided into 20 classes.
This can be easily understood since when the neighborhood size is very small, then the data points used for training the local classifiers may not be sufficient; when the neighborhood size is very large, the trained classifiers will tend to be global and  cannot capture the typical local characteristics.
5 http://people.csail.mit.edu/jrennie/20Newsgroups/ To pre-process the datasets, we remove the stop words using a standard stop list, all HTML tags are skipped and all header fields except subject and organization of the posted articles are ignored.
(30) is estimated as NMI = C k=1 C m=1 nk,mlog n·nk,m nk ˆnm C k=1 nklog nk n C m=1 ˆnmlog ˆnm n , (31) where nk denotes the number of data contained in the cluster Ck (1 k C), ˆnm is the number of data belonging to the m-th class (1 m C), and nk,m denotes the number of data that are in the intersection between the cluster Ck and the m-th class.
4 Here an indication matrix T is a n×c matrix with its (i,  j)th entry Tij ∈ {0, 1} such that for each row of Q∗ there is only one 1.
Clustering accuracy can be computed as: Acc = 1 N max   Ck,Lm T(Ck, Lm)   , (29) where Ck denotes the k-th cluster in the final results, and Lm is the true m-th class.
Among these 7 categories, student, faculty, course and project are four most populous entity-representing categories.
For two random variable X and Y, the NMI is defined as: NMI(X, Y) = I(X, Y) H(X)H(Y) , (30) where I(X, Y) is the mutual information between X and Y, while H(X) and H(Y) are the entropies of X and Y respectively.
To evaluate their performance, we compare the clusters generated by these algorithms with the true classes by computing the following two performance measures.
The experimental comparisons empirically verify the equivalence between NMF and Spectral Clustering, which Table 3: Clustering accuracies of the various  methods CSTR WebKB4 Reuters WebACE News4 KM 0.4256 0.3888 0.4448 0.4001 0.3527 SKM 0.4690 0.4318 0.5025 0.4458 0.3912 GMM 0.4487 0.4271 0.4897 0.4521 0.3844 NMF 0.5713 0.4418 0.4947 0.4761 0.4213 Ncut 0.5435 0.4521 0.4896 0.4513 0.4189 ASI 0.5621 0.4752 0.5235 0.4823 0.4335 TNMF 0.6040 0.4832 0.5541 0.5102 0.4613 CPLR 0.5974 0.5020 0.4832 0.5213 0.4890 CLGR 0.6235 0.5228 0.5341 0.5376 0.5102 Table 4: Normalized mutual information results of the various methods CSTR WebKB4 Reuters WebACE News4 KM 0.3675 0.3023 0.4012 0.3864 0.3318 SKM 0.4027 0.4155 0.4587 0.4003 0.4085 GMM 0.4034 0.4093 0.4356 0.4209 0.3994 NMF 0.5235 0.4517 0.4402 0.4359 0.4130 Ncut 0.4833 0.4497 0.4392 0.4289 0.4231 ASI 0.5008 0.4833 0.4769 0.4817 0.4503 TNMF 0.5724 0.5011 0.5132 0.5328 0.4749 CPLR 0.5695 0.5231 0.4402 0.5543 0.4690 CLGR 0.6012 0.5434 0.4935 0.5390 0.4908 has been proved theoretically in [10].
The first performance  measure is the Clustering Accuracy, which discovers the  one-toone relationship between clusters and classes and measures the extent to which each cluster contained data points from the corresponding class.
In our experiments, we use a subset of the data collection which includes the 10 most frequent categories among the 135 topics and we call it Reuters-top 10.
For the CLGR method, its global regularization parameter is set by grid search from {0.1, 1, 10}.
Since these methods perform an implicit feature selection at each iteration, provide an adaptive metric for measuring the  neighborhood, and thus tend to yield better clustering results.
The algorithms that we evaluated are listed below.
Table 1: Clustering with Local and Global  Regularization (CLGR) Input: 1.
In this set of experiments, we find that our CLGR algorithm can achieve good results when the two regularization parameters are neither too large nor too small.
The implementation is based on [9].
It can be  observed from the tables that NMF and Spectral  Clustering usually lead to similar clustering results.
The implementation is based on [26], and the variance of the Gaussian similarity is determined by Local Scaling [30].
The News4 dataset used in our experiments are selected from the famous 20-newsgroups dataset5 .
3.3 Comparisons We have conducted comprehensive performance  evaluations by testing our method and comparing it with 8 other representative data clustering methods using the same data corpora.
The results achieved from CPLR are usually better than the results achieved from Spectral Clustering, which supports Vapnik"s theory [24] that sometimes local learning algorithms can obtain better results than global learning algorithms.
Do eigenvalue decomposition on M, and construct the matrix Q∗ according to Eq.
The WebACE dataset was from WebACE project and has been used for document clustering [17][5].
In this method we just minimize Jl (defined in Eq.
The results achieved from the k-means and GMM type algorithms are usually worse than the results achieved from Spectral Clustering.
The topic rec containing autos, motorcycles, baseball and hockey was selected from the version 20news-18828.
T(Ck, Lm) is the number of entities which belong to class m are assigned to cluster k.  Accuracy computes the maximum sum of T(Ck, Lm) for all pairs of clusters and classes, and these pairs have no overlaps.
Therefore we have also done two sets of experiments: 1.
Fixing the size of the neighborhoods, and testing the clustering performance with varying λ∗ and λ.
There are about 8280 documents and they are divided into 7  categories: student, faculty, staff, course, project, department and other.
Therefore, we can see that our CLGR algorithm (1) can achieve satisfactory results and (2) is not very sensitive to the choice of parameters, which makes it practical in real world applications. 
Table 2: Descriptions of the document datasets Datasets Number of documents Number of classes CSTR 476 4 WebKB4 4199 4 Reuters 2900 10 WebACE 2340 20 Newsgroup4 3970 4 CSTR.
Output the cluster assignments of each data point by properly discretize Q∗ .
3.4 Experimental Results The clustering accuracies comparison results are shown in table 3, and the normalized mutual information comparison results are summarized in table 4.
Since Spectral Clustering can be viewed as a weighted version of kernel k-means, it can obtain good results the data clusters are arbitrarily shaped.
The larger this value, the better the clustering performance.
When constructing the global regularizer, we have adopted the local scaling method [30] to construct the Laplacian matrix.
The  implementation is based on [27].
3.1 Datasets We use a variety of datasets, most of which are frequently used in the information retrieval research.
Clustering using Pure Local Regularization (CPLR).
Another  evaluation metric we adopt here is the Normalized Mutual  Information NMI [23], which is widely used for determining the quality of clusters.
Global regularization parameter λ; Output: The cluster membership of each data point.
Besides the above comparison experiments, we also test the parameter sensibility of our method.
This corroborates that the documents vectors are not regularly distributed (spherical or elliptical).
The News4 dataset contains 3970 document vectors.
Note that the criterion that Ncut aims to  minimize is just the global regularizer in our CLGR  algorithm except that Ncut used the normalized Laplacian.
From the two tables we mainly observe that: 1.
Number of clusters C; 3.
The implementation is based on [15].
The co-clustering based methods (TNMF and ASI) can usually achieve better results than traditional purely document vector based methods.
Figure 1 shows us such a  testing example on the WebACE dataset.
This is the dataset of the abstracts of technical reports published in the Department of Computer Science at a university.
The  implementation is based on [14].
Spectral Clustering with Normalized Cuts (Ncut).
Table 2  summarizes the characteristics of the datasets.
Typically our method can achieve good results when λ∗ and λ are around 0.1.
The Reuters-21578 Text Categorization Test collection contains documents collected from the Reuters newswire in 1987.
The implementation is based on [16].
Construct the K nearest neighborhoods for each data point; 2.
First we will introduce the basic informations of those datasets.
The greater clustering accuracy means the better clustering performance.
The dataset contained 476 abstracts, which were divided into four research areas: Natural Language Processing(NLP), Robotics/Vision, Systems, and Theory.
Figure 2 shows us a testing example on the WebACE dataset.
The size of the k-nearest neighborhoods is set by grid search from {20, 40, 80}.
It is a standard text categorization  benchmark and contains 135 categories.
The  associated subset is typically called WebKB4.
The  WebACE dataset contains 2340 documents consisting news  articles from Reuters new service via the Web in October 1997.
It sums up the whole matching  degree between all pair class-clusters.
Then the xi can be assigned to the j-th cluster such that j = argjQ∗ ij = 1.
Adaptive Subspace Iteration (ASI).
Size of the neighborhood K; 4.
The raw text is about 27MB.
Traditional k-means (KM).
One can see that NMI(X, X) = 1, which is the maximal possible value of NMI.
Clustering Accuracy (Acc).
Construct the Laplacian matrix L using Eq.
Construct the matrix M = (P − I)T (P − I) + λL; 5.
The WebKB dataset contains webpages  gathered from university computer science departments.
Tri-Factorization Nonnegative Matrix Factorization (TNMF) [12].
The value calculated in Eq.
Local regularization parameters {λi}n i=1; 5.
Gaussian Mixture Model (GMM).
Nonnegative Matrix Factorization (NMF).
Spherical k-means (SKM).
Construct the matrix P using Eq.
Normalized Mutual Information (NMI).
Dataset X = {xi}n i=1; 2.
Procedure: 1.
(28); 6.
(12); 3.
(16); 4.
