3.1 Problem Definition In order to provide the most benefit to the user, a system would not only detect the document, but it would also indicate the specific sentences in the e-mail which contain the action-items.
Once trained,  applying the resulting classifiers to sentence detection is now  straightforward, but in order to apply the classifiers to document  detection and document ranking, the individual predictions over each sentence must be aggregated in order to make a document-level prediction.
For example, if the classifier predicts a document contains an action-item, then areas of the document that contain a high-concentration of words which the model weights heavily in favor of action-items can be indicated.
In addition, for the sentence-level classifiers that use  ngrams, we additionally code for each sentence a binary encoding of the position of the sentence relative to the document.
Since the  segmentation is fixed, an overly long prediction would be predicting yes for many no instances since presumably the extra length corresponds to additional segmented sentences all of which do not contain 30% of action-item.
3.2 Approach As mentioned above, the labeled data can come in one of two forms: a document-labeling provides a yes/no label for each  document as to whether it contains an action-item; a phrase-labeling provides only a yes label for the specific items of interest.
In order to apply it to sentence detection, one must make additional steps.
When using n-grams, if we find an n-gram of size 4 in a segment of text, we can represent the text as just one occurrence of the  ngram or as one occurrence of the n-gram and an occurrence of each smaller n-gram contained by it.
We do not address how to use a document-level classifier to make predictions at the sentence-level.
Additionally, we consider multiple standard text classification approaches and analyze both the quantitative and qualitative differences that arise from taking a document-level vs. a sentence-level approach to  classification.
where s is a sentence in document d, π is the classifier"s 1/0  prediction, ψ is the score the classifier assigns as its confidence that π(s) = 1, and n(d) is the greater of 1 and the number of (unigram) tokens in the document.
Since sentence-ending punctuation can provide information, we retain the terminating punctuation token when it is identifiable.
Since the phrase-labeling provided by the user may not coincide with the automatic segmentation, we must determine what label to assign a partially overlapping  sentence when converting it to a learning instance.
Therefore, in order to consider the prediction to be too short, there will be an additional  preceding/following sentence that is an action-item where we incorrectly predicted no.
We use the simple policy of predicting positive when any of the sentences is predicted positive.
Once a sentence-level classifier has made a prediction for each sentence, we must combine these predictions to make both a  document-level prediction and a document-level score.
Each of these phrases consists of common words that occur in many e-mails.
Since the automatically segmented sentences may not correspond directly with the phrase-level  boundaries, we treat any sentence that contains at least 30% of a marked action-item segment as an action-item.
Document ranking: Rank the documents such that all  documents containing action-items occur as high as possible in the ranking.
In contrast to previous work, we explicitly focus on the benefits that finer-grained, more costly, sentence-level human judgments  offer over coarse-grained document-level judgments.
The obvious benefit of the document-level approach is that training set collection costs are lower since the user only has to specify whether or not an e-mail contains an action-item and not the specific sentences.
If multiple  segmentation systems were under evaluation, one would need to use a metric that matched predicted positive sentences to phrases labeled positive.
Assuming proper punctuation, these extra tokens are unnecessary, but often e-mail lacks proper  punctuation.
Applying a document-level classifier to document detection and ranking is straightforward.
We choose the second of these alternatives since this will allow the algorithm itself to smoothly back-off in terms of recall.
In other words, when any sentence is  predicted positive, the document score is the length normalized sum of the sentence scores above threshold.
Likewise, a too short prediction must correspond to a small sentence included in the action-item but not constituting all of the action-item.
In order to automatically segment the text of the e-mail, we use the RASP statistical parser [4].
This approach has the potential to benefit from  morespecific labels that enable the learner to focus attention on the key sentences instead of having to learn based on data that the majority of the words in the e-mail provide no or little information about class membership.
Because of this, we posit that n-grams play a larger role in this problem than is typical of problems like topic  classification.
When no sentence is predicted positive, the document score is the maximum sentence score  normalized by length.
We term the human judgments a phrase-labeling since the user"s view of the action-item may not correspond with actual sentence boundaries or predicted sentence boundaries.
In order to produce a document score for  ranking, the confidence that the document contains an action-item is: ψ(d) = 1 n(d) s∈d|π(s)=1 ψ(s) if for any s ∈ d, π(s) = 1 1 n(d) maxs∈d ψ(s) o.w.
The document-level view treats each e-mail as a learning instance with an associated class-label.
To train classifiers for this task, we can take several viewpoints related to both the basic problems we have enumerated and the form of the labeled data.
In the sentence-level view, each e-mail is automatically segmented into sentences, and each sentence is treated as a learning instance with an associated class-label.
Additionally, we add a beginning-of-sentence and end-of-sentence  token in order to capture patterns that are often indicators at the  beginning or end of a sentence.
As in most Information Retrieval tasks, the weight the  evaluation metric should give to precision and recall depends on the  nature of the application.
As in other text problems, we are more likely to emit false positives for documents with more words or sentences.
In situations where a user will eventually read all received messages, ranking (e.g., via precision at recall of 1) may be most important since this will help encourage shorter  delays in communications between users.
Sentence detection: Classify each sentence in a document as to whether or not it is an action-item.
Then, the  document can be converted to a feature-value vector and learning  progresses as usual.
Since we are not evaluating multiple segmentation approaches, this does not bias any of the methods.
Document detection: Classify a document as to whether or not it contains an action-item.
In contrast, high-precision detection at low recall will be of increasing importance when the user is under severe time-pressure and therefore will likely not read all mail.
Finally, sentence detection plays a role in both  timepressure situations and simply to alleviate the user"s required time to gist the message.
However, when they occur in the same sentence, they are far more indicative of an action-item.
When evaluating  sentencedetection for the sentence-level system, we use these class labels as ground truth.
3.2.2 Implementation Details In order to compare the document-level to the sentence-level  approach, we compare predictions at the document-level.
contains the sentence.
The metric would need to punish overly long true  predictions as well as too short predictions.
Obviously, it is straightforward to generate a document-labeling consistent with a phrase-labeling by labeling a document yes if and only if it contains at least one phrase labeled yes.
Methods such as na¨ıve Bayes may be hurt by such a representation because of double-counting.
3.2.1 Features Consider some of the phrases that might constitute part of an action item: would like to know, let me know, as soon as possible, have you.
Our criteria for converting to labeled instances implicitly includes both criteria.
Finally, we focus on the representation necessary to achieve the most competitive performance.
This  encoding has eight associated features that represent which octile (the first eighth, second eighth, etc.)
Therefore, we consider all n-grams up to size 4.
Thus we include a length normalization factor. 
Additionally, order can be important: consider have you versus you have.
This can be the case for crisis managers during disaster management.
Therefore, there are three basic problems: 1.
