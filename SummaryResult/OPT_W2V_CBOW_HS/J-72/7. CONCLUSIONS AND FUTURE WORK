At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries,  specialized to the problem of preference elicitation.
Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.
This is the  preference elicitation problem.
Finally, it would be useful to determine whether the ORâˆ— bidding language [11] can be efficiently learned (and hence elicited), given this language"s expressiveness and  succinctness for a wide variety of valuation classes.
In the learning setting, we usually assume that oracles will provide honest responses to queries; in the  elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.
A learning approach to elicitation also motivates a  different approach to designing elicitation algorithms that  decomposes neatly across agent types.
If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents"  valuations and integrate them into an elicitation scheme.
We have shown that exact learning algorithms with  membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand  queries.
We also plan to implement the algorithms for learning  polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].
It would be interesting to find  examples of valuation classes for which elicitation is easier than learning.
[5] provide such an example when considering membership/value queries only (Theorem 4).
In future work we plan to address the issue of  incentives when converting learning algorithms to elicitation  algorithms.
Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning  algorithms" complexity.
We do not require that agent valuations can be learned with value and demand queries.
The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the  original learning algorithms are efficient.
Acknowledgements We would like to thank Debasis Mishra for helpful  discussions.
Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.
This work is supported in part by NSF grant  IIS0238147. 
An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?
We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence  queries.
Blum et al.
