For learning from  communication, an agent engages into arguing with other agents in  order to contrast its individual hypotheses and receive  counterexamples; the argumentation process improves their learning scope and individual performance.
In this paper we will present an argumentation framework for  learning agents (AMAL) designed for two purposes: (1) for joint  deliberation, and (2) for learning from communication.
We experimentally show that the argumentation among committees of agents improves both the individual and joint performance.
The AMAL  framework is completely based on learning from examples: the argument preference relation, the argument generation policy, and the  counterargument generation policy are case-based techniques.
For join deliberation, learning agents share their experience by forming a committee to decide upon some joint decision.
Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning; I.2.11 [Artificial  Intelligence]: Distributed Artificial Intelligence-Multiagent systems, Intelligent Agents 
