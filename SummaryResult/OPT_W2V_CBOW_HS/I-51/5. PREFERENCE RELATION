Specifically, to assess the confidence of a justified prediction α, an agent obtains the set of cases in its individual case base that are subsumed by α.D.
Figure 2 illustrates the individual evaluation of the confidence of an argument, in particular, three  endorsing cases and one counterexample are found in the case base of agents Ai, giving an estimated confidence of 0.6 Moreover, we can also define the joint confidence of an argument α as the confidence computed using the cases present in the case bases of all the agents in the group: C(α) = i Y Ai α 1 + i Y Ai α + NAi α Notice that, to collaboratively compute the joint confidence, the agents only have to make public the aye and nay values locally computed for a given argument.
With them, an agent Ai obtains the Y (aye) and N (nay) values: • Y Ai α = |{c ∈ Ci| α.D c.P ∧ α.S = c.S}| is the number of cases in the agent"s case base subsumed by the justification α.D that belong to the solution class α.S, • NAi α = |{c ∈ Ci| α.D c.P ∧ α.S = c.S}| is the number of cases in the agent"s case base subsumed by justification α.D that do not belong to that solution class.
Basically, we will define a confidence measure for each justified prediction (that takes into account the cases owned by each agent), and the justified prediction with the highest confidence will be the preferred one.
The idea behind case-based confidence is to count how many of the cases in an individual case base endorse a justified prediction, and how many of them are counterexamples of it.
the confidence on a justified prediction is the number of  endorsing cases divided by the number of endorsing cases plus  counterexamples.
The more the endorsing cases, the higher the confidence; and the more the  counterexamples, the lower the confidence.
In our framework, agents use this joint confidence as the  preference relation: a justified prediction α is preferred over another one β if C(α) ≥ C(β). 
For that reason, we are going to define a preference relation over contradicting justified predictions based on cases.
Notice that we add 1 to the denominator, this is to avoid giving excessively high confidences to justified predictions whose confidence has been computed using a small number of cases.
A specific argument provided by an agent might not be consistent with the information known to other agents (or even to some of the information known by the agent that has generated the justification due to noise in training data).
Notice that this correction follows the same idea than the Laplace  correction to estimate probabilities.
on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 977 + + + + + +   - - + Figure 2: Confidence of arguments is evaluated by contrasting them against the case bases of the agents.
An agent estimates the confidence of an argument as: CAi (α) = Y Ai α 1 + Y Ai α + NAi α i.e.
The Sixth Intl.
Joint Conf.
