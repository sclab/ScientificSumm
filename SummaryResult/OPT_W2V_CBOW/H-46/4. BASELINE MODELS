(5) The probability of a query given a document is estimated by  inferring a document language model θd for each document d in a similar manner as the candidate model was inferred: p(t|θd) = (1 − λ)p(t|d) + λp(t), (6) where p(t|d) is the probability of the term in the document.
By using KL divergence instead of the  probability of a candidate given the topic model p(ca|θk), we avoid normalization problems.
Using the associations between a candidate and a document , the probability p ( t|ca ) can be approximated by : p ( t|ca ) 