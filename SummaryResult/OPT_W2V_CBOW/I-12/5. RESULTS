Since all simulation runs used for generating Figure 6 are based on the same seed, the performance of the self-learning mechanism is constant regardless of the number of types in the environment.
Finally, we measured the effect of the number of types in the environment.
Last, despite the difference in their overall distribution function, agents of type IV and V exhibit similar performance because the relevant portion of their distribution functions (i.e., the effective parts that affect the RV calculation as explained in Figure 1) is identical.
For the Figure 4 environment , average-all is a good strategy for agents 