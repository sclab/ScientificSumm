This algorithm is based on the combination of a classical heuristic search algorithm, Aâˆ— and decentralized control theory.
[4] approximate POSGs as a series of one-step Bayesian games using heuristics to approximate future value,  trading off limited lookahead for computational efficiency, resulting in locally optimal policies (with respect to the selected heuristic).
This paper presents four algorithms SPIDER, SPIDER-ABS, PAX and VAX that provide a novel combination of features for  policy search in distributed POMDPs: (i) exploiting agent interaction structure given a network of agents (i.e.
easier scale-up to larger number of agents ) ; ( ii ) using branch 