, ωn ∈ Ω is the observation received in state s. This implies that each agent"s observation depends only on the  unaffectable state, its local action and on its resulting local state.
An ND-POMDP is similar to an n-ary Distributed Constraint Optimization Problem (DCOP)[8, 12] where the variable at each node represents the policy selected by an individual agent, πi with the domain of the variable being the set of all local policies, Πi.
, sn, su is the world state that results from the agents  performing a = a1, .
Ω = ×1≤i≤nΩi is the set of joint observations where 