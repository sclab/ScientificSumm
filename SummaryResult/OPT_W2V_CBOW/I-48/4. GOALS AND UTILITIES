Corollary 1"s first item says that an agent whose current  maximal goal in a system is a universal formula, need never fear the imposition of a new norm η.
The opposite is true for existential goals, according to the second item of the corollary: it can never be bad for an agent to undo a norm η.
We make this precise in the function ui ( · ) : ui ( K ) = max { j : 0 ≤ j ≤ |γi | & K |= γi [ j ] } Note that using these definitions of 