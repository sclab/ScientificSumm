Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by  performance.
Evaluation of information retrieval systems is one of the core tasks in information retrieval.
When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.
Our focus is on zero-judgment  performance prediction of individual retrievals.
Problems include the  inability to exhaustively label all documents for a topic,  nongeneralizability from a small number of topics, and  incorporating the variability of retrieval systems.
We find that the low correlation 