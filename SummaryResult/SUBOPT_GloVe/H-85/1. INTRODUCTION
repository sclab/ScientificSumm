By using the aggregated behavior of large numbers of users (and not treating each user as an individual expert) we can correct for the noise inherent in individual interactions, and generate relevance judgments that are more accurate than techniques not specifically designed for the web search setting.
Recently, automatic or implicit relevance feedback has developed into an active area of research in the information retrieval community, at least in part due to an increase in available resources and to the rising popularity of web search.
We present techniques to automatically interpret the collective behavior of users interacting with a web 