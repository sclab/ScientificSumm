OC-DEC-MDP is able to scale up to such domains mainly because instead of searching for the globally optimal solution, it carries out a series of policy iterations; in each iteration it performs a value iteration that reuses the data computed during the previous policy iteration.
In this context, we present VFP (= Value Function P ropagation), an efficient solution technique for the DEC-MDP model with  temporal constraints and uncertain method execution durations, that builds on the success of OC-DEC-MDP.
Additionally , OC-DEC-MDP is unique in its ability to address both temporal constraints and uncertain method execution durations , which is an 