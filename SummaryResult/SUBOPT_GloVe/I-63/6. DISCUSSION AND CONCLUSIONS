The optimization procedure  discussed in this paper was developed in the context of  cooperative agents, but it can also be used to design a  mechanism for scheduling resources among self-interested agents.
Relaxing the assumption about deterministic arrival and departure times of the agents is a focus of our future work.
We used a reward model where agents" rewards depend only on the time horizon of their MDPs and not the global start time.
This is a consequence of our MDP-augmentation procedure from Section 4.1.
â€¢ Indifference to start time.
In fact , all the results of [ 7 ] 