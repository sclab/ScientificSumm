[9] shows experimentally that most of the terms (words) in a collection are distributed according to a low dimension n-Poisson model.
We use in our paper a different notion of noise: we consider a frequency-based noise that corresponds to the document frequency, and we consider a term noise that is based on the independence of document events.
The probability of being  informative defined in our paper can be viewed as the probability of the disjoint terms in the term space of [12].
The relationship between frequencies, probabilities and information theory (entropy) has been the focus of many researchers.
Entropy is 