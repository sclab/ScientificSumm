3.3 Agent Learning The objective of each agent is to learn the best values of d that will lead to the best system performance, G. In this paper we assume that each agent will have a reward  function and will aim to maximize its reward using its own  reinforcement learner [15] (though alternatives such as  evolving neuro-controllers are also effective [1]).
In many situations it is possible to use a ci that is  equivalent to taking agent i out of the system.
The first and most direct approach is to let each agent receive the system performance as its reward 