Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.
Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.
Let S be a similarity matrix.
A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function : 