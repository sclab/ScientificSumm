This paper presents a formal Adversarial Environment model for bounded  rational agents operating in a zero-sum environment.
We then present behavioral axioms that are intended to serve as  design principles for building such adversarial agents.
We define an Adversarial Environment by describing the mental states of an agent in such an environment.
In such environments, attempts to use classical utility-based search methods can raise a variety of difficulties (e.g., implicitly modeling the opponent as an omniscient utility maximizer, rather than leveraging a more nuanced, explicit opponent model).
We explore the application of our approach by analyzing log files of completed 