Since many text classification tasks often have very little training data, we focus on parametric methods.
After this, we  describe two specific asymmetric models and, using two standard text classifiers, na¨ıve Bayes and SVMs, demonstrate how they can be efficiently used to recalibrate poor probability estimates or produce high quality probability estimates from raw scores.
Additionally, probability estimates are often used as the basis of deciding which document"s label to request next during active learning [17, 23].
Parametric models generally use assumptions that the data conform to the model to trade-off flexibility with the ability to estimate the 