In future work we plan to address the issue of  incentives when converting learning algorithms to elicitation  algorithms.
Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.
A learning approach to elicitation also motivates a  different approach to designing elicitation algorithms that  decomposes neatly across agent types.
We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence  queries.
Theorem 1 implies that elicitation with value and demand queries is no harder than learning 