This assumption is fundamental to our solution method.
This is a consequence of our MDP-augmentation procedure from Section 4.1.
• Indifference to start time.
In summary, we have presented an MILP formulation for the combinatorial resource-scheduling problem where agents" values for possible resource assignments are defined by  finitehorizon MDPs.
This result extends previous work ([6, 7]) on static one-shot resource allocation under MDP-induced preferences to resource-scheduling problems with a temporal aspect.
Finally, we have assumed that agents" arrival and  departure times (τa m and τd m) are deterministic and known a priori.
We used a reward model where 