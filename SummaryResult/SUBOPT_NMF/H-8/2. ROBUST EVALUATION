This means the same probability estimates can tell us about average precision as well as precision, recall, bpref, etc.
The task therefore becomes the imputation of the missing values of relevance.
We can then compute e.g.
This random variable has an  expectation, a variance, confidence intervals, and a certain probability of being less than or equal to a given value.
This is known as the principle of maximum entropy [13].
The following theorem shows the utility of a maximum entropy distribution for relevance when estimating confidence.
Suppose we have a set of m relevance judgments xm = { x1 , 