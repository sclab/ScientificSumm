The primary hypothesis we are concerned with is that n-grams are critical for this task; if this is true, we expect to see a significant gap in performance between the document-level classifiers that use n-grams (denoted Document Ngram) and those using only unigram features (denoted Document Unigram).
4.5 Results The results for document-level classification are given in Table 3.
Na¨ıve Bayes poor performance with the n-gram representation is not surprising since the bag-of-n-grams causes excessive doublecounting as mentioned in Section 3.2.1 ; however , na¨ıve Bayes is not hurt at the sentence-level because the sparse examples provide few chances for 