We believe it is likely that any reasonably effective baseline feedback algorithm would benefit from our approach.
Our results on standard TREC collections show that our framework  improves the robustness of a strong baseline feedback method across a variety of collections, without sacrificing average precision.
In future work, we envision an investigation into how varying the set of sampling methods used and the number of samples controls the trade-off between  robustness, accuracy, and efficiency.
While our study uses the language modeling approach as a framework for experiments, we make few assumptions about the actual workings of the feedback algorithm.
Acknowledgements 