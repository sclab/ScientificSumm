, xn)}, but rather one that satisfies a relaxed requirement that the margin be maximized over the examples { x(n−p+1), .
In this case, the original  softmargin SVM is computed by maximizing at example n: W (α) = nX i=1 αi − 1 2 nX i,j=1 αiαjyiyj < xi, xj >, subject to the previous constraints [23]: ∀i ∈ {1, .
3.2 Reducing Number of Updates As noted before, the KKT conditions show that a well classified example will not change the hypothesis; thus it is not necessary to re-train when we encounter such an  example.
Formally , the optimization problem is now defined most 