Most AF methods have pre-specified parameters that may influence the performance significantly and that must be determined before the test process starts.
We argue that robustness is an important measure for evaluating and comparing AF methods.
Notice that the validation-set topics often do not overlap with the test-set topics, thus the parameter optimization is performed under the tough condition that the validation data and the test data may be quite different from each other.
Rocchio-style classifiers have been popular in AF , with good performance in benchmark evaluations ( TREC and TDT ) if appropriate parameters were used and if 