More elaborate methods include probabilistic threshold calibration which converts the non-probabilistic similarity scores to probabilities (i.e., )|( dTP r ) for utility optimization [9][13], and margin-based local regression for risk reduction [11].
The simplest is to use a universal threshold for all topics, tuned on a validation set and fixed during the testing phase.
Given a training set of labeled documents { } ) , ( , ) , , ( 11 nn yxyxD r L r = , the standard regression problem is defined as to find the maximum likelihood estimates of the regression coefficients ( the model parameters ) 